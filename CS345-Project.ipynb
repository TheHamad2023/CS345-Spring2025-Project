{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e86e4561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: Read with tabs\n",
      "y: Read with commas\n",
      "Null found\n",
      "X: Read with tabs\n",
      "y: Read with commas\n",
      "Null found\n"
     ]
    }
   ],
   "source": [
    "#Understanding the data set\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def inspect_x_test(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"Read with commas\")\n",
    "    except pd.errors.ParserError:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, delimiter='\\t')\n",
    "            print(\"Read with tabs\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading the .txt file: {e}\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the file: {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"Data Preview:\")\n",
    "    print(f\"Number of rows (samples): {df.shape[0]}\")\n",
    "    print(f\"Number of columns (features): {df.shape[1]}\")\n",
    "    print(\"\\nColumn names:\")\n",
    "    print(df.columns.tolist())\n",
    "\n",
    "# inspect_x_test(\"Data/x_test.txt\")\n",
    "# inspect_x_test(\"Data/y_test.txt\")\n",
    "\n",
    "\n",
    "def preview_large_csv(file_path, num_lines=20, delimiter=','):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, delimiter=delimiter, nrows=num_lines)\n",
    "        print(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading preview: {e}\")\n",
    "\n",
    "# preview_large_csv(\"Data/x_test.txt\", delimiter='\\t')\n",
    "\n",
    "def check_nulls_in_data(x_file_path, y_file_path):\n",
    "    def read_file_smart(path, label):\n",
    "        try:\n",
    "            df = pd.read_csv(path)\n",
    "            print(f\"{label}: Read with commas\")\n",
    "        except pd.errors.ParserError:\n",
    "            try:\n",
    "                df = pd.read_csv(path, delimiter='\\t')\n",
    "                print(f\"{label}: Read with tabs\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading the {label} file: {e}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading the {label} file: {e}\")\n",
    "            return None\n",
    "        return df\n",
    "\n",
    "    X = read_file_smart(x_file_path, \"X\")\n",
    "    y = read_file_smart(y_file_path, \"y\")\n",
    "\n",
    "    if X is None or y is None:\n",
    "        return\n",
    "\n",
    "    if X.isnull().values.any() or y.isnull().values.any():\n",
    "        print(\"Null found\")\n",
    "    else:\n",
    "        print(\"No nulls found\")\n",
    "\n",
    "check_nulls_in_data('Data/x_test.txt', 'Data/y_test.txt')\n",
    "check_nulls_in_data('Data/x_train.txt', 'Data/y_train.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257857a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to preprocess the data\n",
    "def preprocessXandY(X, y):\n",
    "    lang_codes = ['ita', 'fra', 'eng', 'ind', 'spa'] #lang codes of what we will use Italian, French, English, Indonesian, Spanish\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7602a789-a084-4f24-b977-47df8039c2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/x_train.txt: Read each line into row\n",
      "Data/y_train.txt: Read each line into row\n",
      "(117500, 2)\n",
      "(117000, 2)\n",
      "(2500, 2)\n",
      "Data/x_test.txt: Read each line into row\n",
      "Data/y_test.txt: Read each line into row\n",
      "(117500, 2)\n",
      "(117000, 2)\n",
      "(2500, 2)\n",
      "(2500,) (2500,)\n",
      "(5000,) (5000,)\n"
     ]
    }
   ],
   "source": [
    "#Understanding the data set\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def file_to_np_array(path, label):\n",
    "    try:\n",
    "        df = pd.read_csv(path, sep='<NonExistenceSeparator>', header=None, engine='python')\n",
    "        print(f\"{label}: Read each line into row\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the {label} file: {e}\")\n",
    "        return None\n",
    "    return df.to_numpy()\n",
    "\n",
    "\n",
    "def clean_np_data(X, y):\n",
    "    stacked = np.hstack((y, X)) # Stack y and X side by side\n",
    "    print(stacked.shape)\n",
    "    clean_stacked = stacked[~np.any(pd.isna(stacked), axis=1), :] # Remove empty values\n",
    "    print(clean_stacked.shape)\n",
    "    lang_codes = ['ita', 'fra', 'eng', 'ind', 'spa']\n",
    "    true_clean = clean_stacked[np.isin(clean_stacked[:,0], lang_codes),:] # Remove all rows that aren't our target languages\n",
    "    print(true_clean.shape)\n",
    "    return true_clean[:,1], true_clean[:,0] # Return cleaned as X and y split again\n",
    "\n",
    "def clean_filter_and_stack(X1_file, y1_file, X2_file, y2_file):\n",
    "    X1_clean, y1_clean = clean_np_data(file_to_np_array(X1_file, X1_file), \n",
    "                                       file_to_np_array(y1_file, y1_file))\n",
    "    X2_clean, y2_clean = clean_np_data(file_to_np_array(X2_file, X2_file), \n",
    "                                       file_to_np_array(y2_file, y2_file))\n",
    "    return np.hstack((X1_clean, X2_clean)), np.hstack((y1_clean, y2_clean))\n",
    "\n",
    "X_all, y_all = clean_filter_and_stack(\"Data/x_train.txt\", \n",
    "                                      \"Data/y_train.txt\", \n",
    "                                      \"Data/x_test.txt\", \n",
    "                                      \"Data/y_test.txt\")\n",
    "\n",
    "print(X_all.shape, y_all.shape)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60b758fc-1a04-4cc4-8c94-9c6034e4ca00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X_all, y_all, test_size=0.3, random_state=17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5925257-f51e-452b-be5b-7a4dede72735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
