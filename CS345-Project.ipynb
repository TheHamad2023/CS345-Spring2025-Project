{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4315aa3e",
   "metadata": {},
   "source": [
    "# CS345 Project\n",
    "\n",
    "## Team Members\n",
    "1. Hamad Alyami\n",
    "2. Benito Encarnacion\n",
    "\n",
    "## Dataset\n",
    "Our dataset was from Kaggle by a user called Mexwell. The data is paragraphs scraped from wikipedia in 2018 in 235 languages.\n",
    "\n",
    "The dataset contains 235,000 datasets with balance between language proportions and a test and train split provided.\n",
    "\n",
    "The downloaded folder from Kaggle contains:\n",
    "- labels.csv: A file containing the language name, 2-3 letter code, German name, and language family of all the languages present in the dataset.\n",
    "- README.txt: A file explaining the folder contents.\n",
    "- urls.txt: A file containing the urls of where the paragraphs were found.\n",
    "- x_test.txt: The testing data samples, paragraphs in multiple languages.\n",
    "- x_train.txt: The training data samples, paragraphs in multiple langauges\n",
    "- y_test.txt: The labels for the testing dataset, using the 2-3 letter codes found in labels.csv.\n",
    "- y_train.txt: The labels for the training dataset, using the 2-3 letter codes found in labels.csv\n",
    "\n",
    "\n",
    "## Project\n",
    "Our project is to train and compare two ML models on the Latin Alphabet languages present in the dataset and compare their performance.\n",
    "\n",
    "## Motivation\n",
    "We decided to do this project because it allows us to explore practical applications of natural language processing and machine learning by working with real-world multilingual data. Language identification is an important task in many systems and applications like search engines, translation tools, and content moderation. Working with such a dataset gives us the opportunity to apply classification techniques in a meaningful way. By focusing on languages that use the Latin alphabet, we avoid complications from different writing systems while still working with a variety of languages.\n",
    "\n",
    "## Models\n",
    "The models we decided to work with in this project are:\n",
    "- Multinomial Naive-Bayes (MNB): Uses word frequencies in each class, langauges in our case, to guess the most likely class for text it has not seen.\n",
    "\n",
    "- Feed Forward Neural Network (FNN): An artificial Neural Network where information moves from input to output without looping back. It uses neurons, connected nodes, to learn patterns and make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1704ce66",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "We will begin by reading the data from the files then:\n",
    "1. Remove Null Values\n",
    "2. Filter to keep texts of languages we want using the 2-3 letter codes\n",
    "3. Return both samples from x_test and x_train and labels from y_test and y_train stacked into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7602a789-a084-4f24-b977-47df8039c2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/x_train.txt: Read!\n",
      "Data/y_train.txt: Read!\n",
      "Data/x_test.txt: Read!\n",
      "Data/y_test.txt: Read!\n",
      "(5000,) (5000,)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Understanding the data set\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "            #Italina, French, Spanish, Portugese, English, German, Dutch, Indonesian, Finnish, Hausa\n",
    "lang_codes = ['ita', 'fra', 'spa', 'eng', 'ind']\n",
    "langs = ['Italian', 'French', 'Spanish', 'English', 'Indonesian']\n",
    "\n",
    "def file_to_np_array(path, label):\n",
    "    try:\n",
    "        df = pd.read_csv(path, sep='<NonExistenceSeparator>', header=None, engine='python')\n",
    "        print(f\"{label}: Read!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the {label} file: {e}\")\n",
    "        return None\n",
    "    return df.to_numpy()\n",
    "\n",
    "\n",
    "def clean_np_data(X, y):\n",
    "    stacked = np.hstack((y, X)) # Stack y and X side by side\n",
    "    # print(stacked.shape)\n",
    "    clean_stacked = stacked[~np.any(pd.isna(stacked), axis=1), :] # Remove empty values\n",
    "    # print(clean_stacked.shape)\n",
    "    true_clean = clean_stacked[np.isin(clean_stacked[:,0], lang_codes),:] # Remove all rows that aren't our target languages\n",
    "    # print(true_clean.shape)\n",
    "    return true_clean[:,1], true_clean[:,0] # Return cleaned as X and y split again\n",
    "\n",
    "def clean_filter_and_stack(X_train_file, y_train_file, X_test_file, y_test_file):\n",
    "    X_train_clean, y_train_clean = clean_np_data(file_to_np_array(X_train_file, X_train_file), \n",
    "                                       file_to_np_array(y_train_file, y_train_file))\n",
    "    X_test_clean, y_test_clean = clean_np_data(file_to_np_array(X_test_file, X_test_file), \n",
    "                                       file_to_np_array(y_test_file, y_test_file))\n",
    "    return np.hstack((X_train_clean, X_test_clean)).astype(str), np.hstack((y_train_clean, y_test_clean)).astype(str)\n",
    "\n",
    "X, y = clean_filter_and_stack(\"Data/x_train.txt\", \n",
    "                                      \"Data/y_train.txt\", \n",
    "                                      \"Data/x_test.txt\", \n",
    "                                      \"Data/y_test.txt\")\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b5f87e",
   "metadata": {},
   "source": [
    "#### Data Discovery\n",
    "This code is to find what is the sample distribution between languages and average word count of each sample of each language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d27cb38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Percent of Dataset (%)</th>\n",
       "      <th>Average Word Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italian</td>\n",
       "      <td>20.0</td>\n",
       "      <td>68.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>French</td>\n",
       "      <td>20.0</td>\n",
       "      <td>67.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>20.0</td>\n",
       "      <td>67.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>English</td>\n",
       "      <td>20.0</td>\n",
       "      <td>70.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indonesian</td>\n",
       "      <td>20.0</td>\n",
       "      <td>57.147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Language  Percent of Dataset (%)  Average Word Count\n",
       "0     Italian                    20.0              68.192\n",
       "1      French                    20.0              67.707\n",
       "2     Spanish                    20.0              67.295\n",
       "3     English                    20.0              70.455\n",
       "4  Indonesian                    20.0              57.147"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def avg_words(filtered_X):\n",
    "    total = 0\n",
    "    for text in filtered_X:\n",
    "        words = str(text).split()\n",
    "        total += len(words)\n",
    "\n",
    "    return total / len(filtered_X)\n",
    "\n",
    "def word_count_perlang(X, y):\n",
    "    avg_word_count = []\n",
    "    for lang in lang_codes:\n",
    "        filtered_X = X[y == lang]\n",
    "        avg_word_count.append(avg_words(filtered_X))\n",
    "    \n",
    "    return avg_word_count\n",
    "\n",
    "def lang_perc(y):\n",
    "    lang_perc = []\n",
    "    total = len(y)\n",
    "    for lang in lang_codes:\n",
    "        count = (y == lang).sum()\n",
    "        percent = (count / total) * 100\n",
    "        lang_perc.append(percent)\n",
    "    return lang_perc\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Language': langs,\n",
    "    'Percent of Dataset (%)': lang_perc(y),\n",
    "    'Average Word Count': word_count_perlang(X, y)\n",
    "})\n",
    "\n",
    "display(df)\n",
    "\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# model = MultinomialNB()\n",
    "# model.fit(X_train_vectors, y_train)\n",
    "# print(\"Done training MNB\")\n",
    "\n",
    "# y_pred = model.predict(X_test_vectors)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Overall accuracy of MNB: \" + str(accuracy * 100) + \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a7d528",
   "metadata": {},
   "source": [
    "#### Data Split\n",
    "Here we use Sklearn train_test_split to split our data into 70/30 train and test splits, respectively, after shuffling them randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60b758fc-1a04-4cc4-8c94-9c6034e4ca00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500,) (3500,)\n",
      "(1500,) (1500,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=17)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad363514",
   "metadata": {},
   "source": [
    "And then vectorize our dataset for the MNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5925257-f51e-452b-be5b-7a4dede72735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done vectorizing\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(strip_accents='unicode')\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "X_test_vectors = vectorizer.transform(X_test)\n",
    "print(\"Done vectorizing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7602be5a",
   "metadata": {},
   "source": [
    "We train our MNB using the MultinomialNB() function from sklearn on X_train which is 70% of our dataset.\n",
    "\n",
    "### MNB\n",
    "The sklearn MNB implementation has two main hyperparameters, alpha and fit_prior.\n",
    "\n",
    "- alpha is used to smooth the data, so the model doesn’t get confused if a word doesn’t appear in some languages. This helps prevent errors, especially when some words are rare. The default value alpha=1.0 usually works well for text data like ours.\n",
    "\n",
    "- fit_prior decides whether the model should learn how common each language is from the training data. Since all our language samples are balanced (equal amounts), the default setting (True) works fine.\n",
    "\n",
    "So, for our language detection project, we don’t need to change these settings — the defaults are already a good fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb703257-141d-403f-a819-31553f0ccde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training MNB\n",
      "Overall accuracy of MNB: 98.93333333333332%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vectors, y_train)\n",
    "print(\"Done training MNB\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test_vectors)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Overall accuracy of MNB: \" + str(accuracy * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9e0933",
   "metadata": {},
   "source": [
    "Considering our MNB accuracy is unexpectadly hard, we decided to add 5 more languages; Hausa, Portugese, Finnish, German, and Dutch. This is to introduce more languages that are similar like German and Dutch and Spanish and Portugese but at the same time some that are different like Hausa from all the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d83ac461",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_codes = ['ita', 'fra', 'spa', 'por', 'eng', 'deu', 'nld', 'ind', 'fin', 'hau']\n",
    "langs = ['Italian', 'French', 'Spanish', 'Portuguese', 'English', 'German', 'Dutch', 'Indonesian', 'Finnish', 'Hausa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d85a5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/x_train.txt: Read!\n",
      "Data/y_train.txt: Read!\n",
      "Data/x_test.txt: Read!\n",
      "Data/y_test.txt: Read!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Percent of Dataset (%)</th>\n",
       "      <th>Average Word Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italian</td>\n",
       "      <td>10.0</td>\n",
       "      <td>68.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>French</td>\n",
       "      <td>10.0</td>\n",
       "      <td>67.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>10.0</td>\n",
       "      <td>67.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Portuguese</td>\n",
       "      <td>10.0</td>\n",
       "      <td>66.184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>German</td>\n",
       "      <td>10.0</td>\n",
       "      <td>59.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dutch</td>\n",
       "      <td>10.0</td>\n",
       "      <td>55.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indonesian</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Finnish</td>\n",
       "      <td>10.0</td>\n",
       "      <td>48.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hausa</td>\n",
       "      <td>10.0</td>\n",
       "      <td>75.802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Language  Percent of Dataset (%)  Average Word Count\n",
       "0     Italian                    10.0              68.192\n",
       "1      French                    10.0              67.707\n",
       "2     Spanish                    10.0              67.295\n",
       "3  Portuguese                    10.0              66.184\n",
       "4     English                    10.0              70.455\n",
       "5      German                    10.0              59.762\n",
       "6       Dutch                    10.0              55.657\n",
       "7  Indonesian                    10.0              57.147\n",
       "8     Finnish                    10.0              48.431\n",
       "9       Hausa                    10.0              75.802"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = clean_filter_and_stack(\"Data/x_train.txt\", \n",
    "                                      \"Data/y_train.txt\", \n",
    "                                      \"Data/x_test.txt\", \n",
    "                                      \"Data/y_test.txt\")\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Language': langs,\n",
    "    'Percent of Dataset (%)': lang_perc(y),\n",
    "    'Average Word Count': word_count_perlang(X, y)\n",
    "})\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d7cc54",
   "metadata": {},
   "source": [
    "We can still see that the data is still equally distributed, with each language being 10% of the data set. We do see a discrepency however in the average word count of the samples for each langugae, with overall average being around 65. We see that Finnish has an average of 48 words, the lowest, and Haussa has the highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8c72ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000,) (7000,)\n",
      "(3000,) (3000,)\n",
      "Done vectorizing\n",
      "Done training MNB\n",
      "Overall accuracy of MNB: 98.1%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=17)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "vectorizer = CountVectorizer(strip_accents='unicode')\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "X_test_vectors = vectorizer.transform(X_test)\n",
    "print(\"Done vectorizing\")\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vectors, y_train)\n",
    "print(\"Done training MNB\")\n",
    "\n",
    "y_pred = model.predict(X_test_vectors)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Overall accuracy of MNB: \" + str(accuracy * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29400367",
   "metadata": {},
   "source": [
    "The overall accuracy is still really good, much more than what we anticipated or expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6603099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Accuracy of MNB/language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italian</td>\n",
       "      <td>96.855346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>French</td>\n",
       "      <td>99.335548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>97.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Portuguese</td>\n",
       "      <td>93.728223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>German</td>\n",
       "      <td>97.569444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dutch</td>\n",
       "      <td>98.275862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indonesian</td>\n",
       "      <td>98.615917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Finnish</td>\n",
       "      <td>99.315068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hausa</td>\n",
       "      <td>99.662162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Language  Accuracy of MNB/language\n",
       "0     Italian                 96.855346\n",
       "1      French                 99.335548\n",
       "2     Spanish                 97.647059\n",
       "3  Portuguese                 93.728223\n",
       "4     English                100.000000\n",
       "5      German                 97.569444\n",
       "6       Dutch                 98.275862\n",
       "7  Indonesian                 98.615917\n",
       "8     Finnish                 99.315068\n",
       "9       Hausa                 99.662162"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_lang_accuracies(y_true, y_pred):\n",
    "    df = pd.DataFrame({'language': y_true, 'pred': y_pred})\n",
    "    accuracies = []\n",
    "\n",
    "    for lang in lang_codes:\n",
    "        lang_group = df[df['language'] == lang]\n",
    "        if len(lang_group) > 0:\n",
    "            acc = accuracy_score(lang_group['language'], lang_group['pred'])\n",
    "        else:\n",
    "            acc = 0\n",
    "        accuracies.append(acc)\n",
    "    \n",
    "    percent_accuracies = [x * 100 for x in accuracies]\n",
    "    df = None\n",
    "    return percent_accuracies\n",
    "\n",
    "df_MNB_lang = pd.DataFrame({\n",
    "    'Language': langs,\n",
    "    'Accuracy of MNB/language': get_lang_accuracies(y_test, y_pred)\n",
    "})\n",
    "\n",
    "display(df_MNB_lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3a03ac",
   "metadata": {},
   "source": [
    "#### Accuracy\n",
    "We see that the over all accuracy is 98.1 which is still very high and didn't expect. More so, we see that English has a 100% accuracy. We would like to also note how Portugese is the lowest with 93.7% and Finnish is the second best with an almost perfect accuracy of 99.3%.\n",
    "\n",
    "We will attempt to explore the model more and theorize why we ended up with such results down below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b894d5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Top words per lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italian</td>\n",
       "      <td>[di, il, la, in, del]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>French</td>\n",
       "      <td>[de, la, le, en, et]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>[de, la, en, el, que]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Portuguese</td>\n",
       "      <td>[de, em, do, que, da]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English</td>\n",
       "      <td>[the, of, in, and, to]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>German</td>\n",
       "      <td>[der, die, und, in, von]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dutch</td>\n",
       "      <td>[de, van, in, het, een]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indonesian</td>\n",
       "      <td>[yang, dan, di, pada, dari]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Finnish</td>\n",
       "      <td>[ja, on, oli, han, vuonna]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hausa</td>\n",
       "      <td>[da, ta, ya, na, ne]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Language           Top words per lang\n",
       "0     Italian        [di, il, la, in, del]\n",
       "1      French         [de, la, le, en, et]\n",
       "2     Spanish        [de, la, en, el, que]\n",
       "3  Portuguese        [de, em, do, que, da]\n",
       "4     English       [the, of, in, and, to]\n",
       "5      German     [der, die, und, in, von]\n",
       "6       Dutch      [de, van, in, het, een]\n",
       "7  Indonesian  [yang, dan, di, pada, dari]\n",
       "8     Finnish   [ja, on, oli, han, vuonna]\n",
       "9       Hausa         [da, ta, ya, na, ne]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def top_words_per_lang(model, vectorizer, top_n=5):\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    log_probs = model.feature_log_prob_\n",
    "    class_indices = {label: i for i, label in enumerate(model.classes_)}\n",
    "    \n",
    "    return [\n",
    "        [feature_names[i] for i in log_probs[class_indices[lang]].argsort()[::-1][:top_n]]\n",
    "        for lang in lang_codes\n",
    "    ]\n",
    "\n",
    "df_top_words_MNB = pd.DataFrame({\n",
    "    'Language': langs,\n",
    "    'Top words per lang' :top_words_per_lang(model, vectorizer, 5)\n",
    "})\n",
    "\n",
    "pd.set_option('display.max_colwidth', None) \n",
    "\n",
    "display(df_top_words_MNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3514c2b2",
   "metadata": {},
   "source": [
    "We used this function to identify what are the top 5 words that the model, MultinomialNB(), found to be the most indicative of a class. To do this, we used MultinomialNB()'s **feature_log_prob_ variable**, which stores the log-probability of each word (feature) given each class (language). This means it tells us how strongly each word is associated with each language according to the model.\n",
    "\n",
    "The shape of this variable is **(n_classes, n_features)**, where n_classes is the number of languages and n_features is the number of unique words in the vocabulary. Each row shows the log-probabilities for one class, and each column represents a word. The higher the value, the more important that word is for predicting that class.\n",
    "\n",
    "We collected the top 5 because it provides a good balance between being explanatory and concise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36c9597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overlap_matrix(top_words_list):\n",
    "    n = len(lang_codes)\n",
    "    matrix = []\n",
    "\n",
    "    for i in range(n):\n",
    "        row = []\n",
    "        for j in range(n):\n",
    "            overlap = len(set(top_words_list[i]).intersection(top_words_list[j]))\n",
    "            row.append(overlap)\n",
    "        matrix.append(row)\n",
    "\n",
    "    return pd.DataFrame(matrix, index=lang_codes, columns=lang_codes)\n",
    "\n",
    "top_words_list = top_words_per_lang(model, vectorizer, 5)\n",
    "overlap_df = compute_overlap_matrix(top_words_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9879ab0c",
   "metadata": {},
   "source": [
    "#### Top Words in all Languages\n",
    "In the cell below we find the top 5 words that appear in all languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "807ac56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words appearing in more than one language, top 5: ['di', 'la', 'in', 'de', 'en', 'que', 'da']\n"
     ]
    }
   ],
   "source": [
    "def find_shared_words(word_lists):\n",
    "    word_counts = {}\n",
    "    \n",
    "    for word_list in word_lists:\n",
    "        for word in word_list:\n",
    "            if word in word_counts:\n",
    "                word_counts[word] += 1\n",
    "            else:\n",
    "                word_counts[word] = 1\n",
    "\n",
    "    shared = []\n",
    "    for word, count in word_counts.items():\n",
    "        if count > 1:\n",
    "            shared.append(word)\n",
    "\n",
    "    return shared\n",
    "\n",
    "shared_words = find_shared_words(top_words_list)\n",
    "print(\"Words appearing in more than one language, top 5:\", shared_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6962847a",
   "metadata": {},
   "source": [
    "#### Heat-map of Words Correlation between Languages\n",
    "Here we use a matplot to give a colored heat-map of how many words of our top 5 from each language meet between each language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "446fe6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAu8AAAKoCAYAAADH3hGFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB7MklEQVR4nO3dd3gU5fr/8c8mkNACKRBDJzSpgUgU6XAEEWxUjwgiiKCgVBFElKJoFAWxgYIcEEVAETgqyBcLRWlSIiUgvbcQkhCFECCZ3x/82OOSAMmS3clk3i+uuS722Zmd+97Z2dx58swzDsMwDAEAAADI9XzMDgAAAABA1lC8AwAAABZB8Q4AAABYBMU7AAAAYBEU7wAAAIBFULwDAAAAFkHxDgAAAFgExTsAAABgERTvAAAAgEVQvCPXWLdunTp37qySJUvKz89PYWFh6tSpk9auXWtqXDNnzpTD4dDBgwdNjeNm5s2bp5o1a6pgwYJyOBz6448/MqxToUIFORyOmy4zZ870eLzNmzfPdN/33XffDbdLS0tTYGCg2rRpk+G5d999Vw6HQ126dMnw3GuvvSaHw6GtW7fmWA6ZqVChgnr06HHLr7NixYoM701QUJDq16+vzz77zO3X/fLLLzVp0qRbji+3OnjwoBwOh9555x2zQwEAj8hndgCAJH3wwQcaNGiQ7rrrLo0fP17ly5fX4cOH9dFHH6lx48Z677339Nxzz5kdZq51+vRpPf7447rvvvs0efJk+fv7q2rVqhnWW7hwoVJTU52PP/30U02fPl1Lly5VsWLFnO2VKlXyStwVK1bU7NmzXdoCAwNvuI2vr6+aNGmiFStW6PLly8qX739fYytWrFDhwoW1fPnyDNutWLFCISEhql27do7E7i1vvPGGWrRoIUmKj4/XrFmz1KNHDyUnJ6t///7Zfr0vv/xS27dv16BBg3I4UgCAN1C8w3SrV6/WoEGD1LZtWy1cuNClGHv00UfVvn17DRw4UJGRkWrUqJHX4kpJSVGBAgW8tr9bsXv3bl26dEndunVTs2bNrrteZGSky+OlS5dKkurVq6fixYt7NMbMFCxYUHfffXe2t2vRooW+//57bdy40bl9enq6fv31V/Xt21fvvPOOdu7cqerVq0uSLl68qLVr16pt27ZyOBy3FPP58+dVqFChW3qN7KhSpYrLe9S2bVtt2LBBc+bMcat4BwBYG8NmYLro6Gg5HA5NmTLFpXCXpHz58mny5MlyOBx68803JUmLFi2Sw+HQzz//nOG1pkyZkmFoxMaNG/XQQw8pODhYBQoUUGRkpL766iuX7a4OjVm2bJmefPJJlShRQoUKFXLppf6nH3/8UQ8//LDKlCmjAgUKqHLlynr66acVHx/vst6YMWPkcDgUExOjDh06qGjRoipWrJi6deum06dPZ+n9+fbbb9WgQQMVKlRIAQEBatWqlctQoh49eqhx48aSpH//+99yOBxq3rx5ll47MxcuXNCIESMUHh4uPz8/lS5dWs8++6ySkpJc1qtQoYIeeOABLVy4UBERESpQoIAqVqyo999/3+19Z9XVnugVK1Y427Zs2aLExET16dNHJUuWdOl9X79+vVJSUpzbSTd/X6X/Hb/NmzerU6dOCgoKcv5V4tKlSxo2bJjCwsJUqFAhNW7cWL///nuGWM+fP6+hQ4cqPDxcBQoUUHBwsKKiojRnzhy3cvfx8VGRIkWUP39+l3bDMDR58mTVrVtXBQsWVFBQkDp16qT9+/c712nevLkWL16sQ4cOuQzHkaQ777xT999/v8tr1q5dWw6HQxs2bHC2LViwQA6HQ9u2bXO27dmzR4899phCQ0Pl7++v6tWr66OPPsoQe3JysvO9uPrZGjRokM6dO+eynsPh0HPPPafPP/9c1atXV6FChVSnTh19//33br1nmfnoo4/UtGlThYaGqnDhwqpdu7bGjx+vS5cuuazXvHlz1apVSxs2bFCTJk1UqFAhVaxYUW+++abS09Nd1o2NjdW9996rQoUKqUSJEnr22We1ePFiORwOl8/q9YZWNW/e3OXcvXDhgp5//nnVrVtXxYoVU3BwsBo0aKD//ve/GbZNSkpSr169FBwcrCJFiuj+++/X/v375XA4NGbMGJd1s3K80tPTNW7cON1+++0qWLCgAgMDFRERoffeey9rbzAAj6F4h6nS0tK0fPlyRUVFqUyZMpmuU7ZsWdWrV0+//PKL0tLS9MADDyg0NFQzZszIsO7MmTN1xx13KCIiQpK0fPlyNWrUSElJSfr444/13//+V3Xr1tW///3vTMd1P/nkk8qfP78+//xzzZ8/P0OBdNW+ffvUoEEDTZkyRcuWLdOoUaO0fv16NW7cOMMPf0lq3769KleurPnz52vMmDFatGiRWrdunem6//Tll1/q4YcfVtGiRTVnzhxNnz5diYmJat68uX777TdJ0iuvvOL8wfvGG29o7dq1mjx58g1f93oMw1C7du30zjvv6PHHH9fixYs1ZMgQffbZZ/rXv/6V4ZeZP/74Q4MGDdLgwYO1cOFCNWzYUAMHDszyeON9+/YpODhY+fLlU6VKlTRy5EilpKTcdLs6deooKCjIpUBfvny5SpYsqSpVqqhp06YuxdLV9a4W71l5X/+pQ4cOqly5sr7++mt9/PHHkqTevXvrnXfeUffu3fXf//5XHTt2VIcOHZSYmOiy7ZAhQzRlyhQNGDBAS5cu1eeff67OnTvrzJkzWXqP0tPTdfnyZV2+fFmnTp3Sm2++qe3bt6tbt24u6z399NMaNGiQWrZsqUWLFmny5MmKjY1Vw4YNderUKUnS5MmT1ahRI4WFhWnt2rXORZJatmypVatWOT+Tp06d0vbt21WwYEH9+OOPzv389NNPuu2225zDj3bs2KE777xT27dv14QJE/T999/r/vvv14ABAzR27FjndufPn1ezZs302WefacCAAfrhhx80fPhwzZw5Uw899JAMw3DJZ/Hixfrwww/16quv6ptvvlFwcLDat2/v8svIrdi3b58ee+wxff755/r+++/Vq1cvvf3223r66aczrHvy5El17dpV3bp107fffqs2bdpoxIgR+uKLL5zrnDhxQs2aNdOuXbs0ZcoUzZo1S3/99dctDfdLTU1VQkKChg4dqkWLFmnOnDlq3LixOnTooFmzZjnXS09P14MPPqgvv/xSw4cP18KFC1W/fv1Mrx/J6vEaP368xowZoy5dumjx4sWaN2+eevXqleGXeAAmMAATnTx50pBkPProozdc79///rchyTh16pRhGIYxZMgQo2DBgkZSUpJznR07dhiSjA8++MDZVq1aNSMyMtK4dOmSy+s98MADRsmSJY20tDTDMAxjxowZhiSje/fuGfZ99bkDBw5kGlt6erpx6dIl49ChQ4Yk47///a/zudGjRxuSjMGDB7tsM3v2bEOS8cUXX1w357S0NKNUqVJG7dq1nXEahmH89ddfRmhoqNGwYUNn2/Llyw1Jxtdff33d18vM1fhOnz5tGIZhLF261JBkjB8/3mW9efPmGZKMqVOnOtvKly9vOBwO448//nBZt1WrVkbRokWNc+fO3XDfI0eONCZPnmz88ssvxuLFi43nnnvOyJcvn9G0aVOXfK+nXbt2RuHChZ3H9sEHH3R+jiZPnmyUKFHCSE9PNwzDMFq0aGGEhoYahpG99/Xq+zNq1CiXfe/cufOGx/WJJ55wttWqVcto167dTfO51tVjeu3i4+NjjBw50mXdtWvXGpKMCRMmuLQfOXLEKFiwoDFs2DBn2/3332+UL18+w/5++uknQ5KxatUqwzAM44svvjACAgKMfv36GS1atHCuV6VKFeOxxx5zPm7durVRpkwZ4+zZsy6v99xzzxkFChQwEhISDMMwjOjoaMPHx8fYsGGDy3rz5883JBlLlixxtkkybrvtNiM5OdnZdvLkScPHx8eIjo6+4ft24MABQ5Lx9ttv33C9f0pLSzMuXbpkzJo1y/D19XXGbBiG0axZM0OSsX79epdtatSoYbRu3dr5+IUXXjAcDocRGxvrsl7r1q0NScby5cudbeXLl3f5jPxzX82aNbtunJcvXzYuXbpk9OrVy4iMjHS2L1682JBkTJkyxWX96OhoQ5IxevRol3iycrweeOABo27duteNBYB56HmHJRj/v1fu6p/4n3zySaWkpGjevHnOdWbMmCF/f3899thjkqS9e/fqzz//VNeuXSXJ2Xt5+fJltW3bVidOnNCuXbtc9tOxY8csxRMXF6dnnnlGZcuWVb58+ZQ/f36VL19ekrRz584M61+N4apHHnlE+fLly/TCyqt27dql48eP6/HHH5ePz/9O1SJFiqhjx45at26dzp8/n6V4s+qXX36RpAx/0u/cubMKFy6cYahSzZo1VadOHZe2xx57TMnJydq8efMN9zVu3Dj17dtXLVq0UNu2bfXBBx/ozTff1KpVqzIdFnCtFi1a6Ny5c9qwYYNzvPvVIQfNmjXT6dOnFRsbq9TUVK1bt87Z6+7O+3rt5+Lqcbvecf2nu+66Sz/88INefPFFrVixIkt/Wfint956Sxs2bNCGDRv0448/atiwYXrzzTf1wgsvONf5/vvv5XA41K1bN5fPeVhYmOrUqePyV4jradSokQoUKKCffvpJ0pWhYc2bN9d9992nNWvW6Pz58zpy5Ij27Nmjli1bSroyrOPnn39W+/btVahQoQzn2IULF7Ru3TpnjLVq1VLdunVd1mvdunWGYSXSleMbEBDgfHzbbbcpNDRUhw4dytb7dz0xMTF66KGHFBISIl9fX+XPn1/du3dXWlqadu/e7bJuWFiY7rrrLpe2iIgIl1hWrlypWrVqqUaNGi7rZTbzUXZ8/fXXatSokYoUKeL8rpk+fbrL98zKlSslXfn83Wjf2Tled911l7Zs2aJ+/frp//7v/5ScnHxLeQDIORTvMFXx4sVVqFAhHThw4IbrHTx4UIUKFVJwcLCkK0XjnXfe6Rw6k5aWpi+++EIPP/ywc52rQwWGDh2q/Pnzuyz9+vWTpAxj1EuWLHnTmNPT03XvvfdqwYIFGjZsmH7++Wf9/vvvzh96mRVnYWFhLo/z5cunkJCQGw6duPpcZjGVKlVK6enpGYZo3KozZ84oX758KlGihEu7w+FQWFhYhnivzeufbVkdFvJPV4eCXH0vb+RqMb58+XLFxMQoKSnJebFujRo1VKJECa1YsULr1q1zGe/uzvt67bpXX+N6x/Wf3n//fQ0fPlyLFi1SixYtFBwcrHbt2mnPnj03zVG6MiNPVFSUoqKi1LJlS0VHR+upp57ShAkT9Oeff0q68lk3DEO33XZbhs/6unXrMnzOM1OgQAE1atTIWbz//PPPatWqlZo3b660tDT9+uuvzuEzV4v3M2fO6PLly/rggw8y7Ldt27aS/neOnTp1Slu3bs2wXkBAgAzDyBDjte+jJPn7+2f7l5/MHD58WE2aNNGxY8f03nvv6ddff9WGDRucw8+u3UdWYjlz5oxuu+22DOtl1pZVCxYs0COPPKLSpUvriy++0Nq1a7VhwwY9+eSTunDhgsu+8+XL5/zuu96+s3O8RowYoXfeeUfr1q1TmzZtFBISonvuuUcbN250Ox8AOYPZZmAqX19ftWjRQkuXLtXRo0czHfd+9OhRbdq0SW3atJGvr6+zvWfPnurXr5927typ/fv368SJE+rZs6fz+auzp4wYMUIdOnTIdP+33367y+OszESyfft2bdmyRTNnztQTTzzhbN+7d+91tzl58qRKly7tfHz58mWdOXMm06LgqqvPnThxIsNzx48fl4+Pj4KCgm4ab3aEhITo8uXLOn36tEsBbxiGTp48qTvvvNNl/ZMnT2Z4jattN8rtZv7ZI349tWrVchbo/v7+uu2221StWjXn802bNtXy5cudhfbV4t2d9/Xaz8XV17jecf2nwoULa+zYsRo7dqxOnTrl7IV/8MEHncV3dkVERMgwDG3dulXVqlVT8eLF5XA49Ouvv8rf3z/D+pm1Zeaee+7RqFGj9Pvvv+vo0aNq1aqVAgICdOedd+rHH3/U8ePHVbVqVZUtW1aSFBQUJF9fXz3++ON69tlnM33N8PBwSVfOx4IFC+o///lPput5c7ajRYsW6dy5c1qwYIHzL2aSMr03QlaFhIQ4Owz+KbNzpECBApleDB8fH+/yPnzxxRcKDw/XvHnzXD6D12579bxNSEhwKeCv3Xd2jle+fPk0ZMgQDRkyRElJSfrpp5/00ksvqXXr1jpy5IhXZ1wC4Iqed5huxIgRMgxD/fr1U1pamstzaWlp6tu3rwzD0IgRI1ye69KliwoUKKCZM2dq5syZKl26tO69917n87fffruqVKmiLVu2OHsur13++Wf5rLr6Q/TaguiTTz657jbXzmX+1Vdf6fLlyzecFeb2229X6dKl9eWXX7pczHfu3Dl98803zplSctI999wjSS4X4knSN998o3Pnzjmfvyo2NlZbtmxxafvyyy8VEBCgO+64I9v7v3rzoaxMH+lwONSsWTOtWbNGP/74Y4YpMps1a6aVK1dq+fLlKlWqlHPe+5x4X68et+sd1+u57bbb1KNHD3Xp0kW7du1ye9jT1SIzNDRUkvTAAw/IMAwdO3Ys08/5P+e2v1HvdcuWLXX58mW98sorKlOmjPOXoZYtW+qnn37SL7/84ux1l6RChQqpRYsWiomJUURERKb7vvqLzgMPPKB9+/YpJCQk0/UqVKjg1nvhjszOYcMwNG3aNLdfs1mzZtq+fbt27Njh0j537twM61aoUCHDzcJ2796dYRifw+GQn5+fS+F+8uTJDMPKrn72/zmMMLN9Z+d4/VNgYKA6deqkZ599VgkJCbn+hnVAXkfPO0zXqFEjTZo0SYMGDVLjxo313HPPqVy5cs6bNK1fv16TJk1Sw4YNXbYLDAxU+/btNXPmTCUlJWno0KEZemw/+eQTtWnTRq1bt1aPHj1UunRpJSQkaOfOndq8ebO+/vrrbMdbrVo1VapUSS+++KIMw1BwcLC+++47lxk5rrVgwQLly5dPrVq1UmxsrF555RXVqVMnwxjVf/Lx8dH48ePVtWtXPfDAA3r66aeVmpqqt99+W0lJSc6pM3NSq1at1Lp1aw0fPlzJyclq1KiRtm7dqtGjRysyMlKPP/64y/qlSpXSQw89pDFjxqhkyZL64osv9OOPP+qtt966YQH866+/6vXXX1f79u1VsWJFXbhwQT/88IOmTp2qf/3rX3rwwQezFG+LFi00f/58LVu2TB9++KHLc82aNdOZM2e0atUq53UQUs68r9WrV1e3bt00adIk5c+fXy1bttT27dv1zjvvqGjRoi7r1q9fXw888IAiIiIUFBSknTt36vPPP8/yL1979uxxDiM6e/asfvrpJ02fPl1RUVFq0qSJpCvnUJ8+fdSzZ09t3LhRTZs2VeHChXXixAn99ttvql27tvr27SvpyvSPCxYs0JQpU1SvXj35+PgoKipK0pX5/oOCgrRs2TKXv2K1bNlSr732mvP///Tee++pcePGatKkifr27asKFSror7/+0t69e/Xdd985r6MYNGiQvvnmGzVt2lSDBw9WRESE0tPTdfjwYS1btkzPP/+86tevf9P3I6u2bdum+fPnZ2i/88471apVK/n5+alLly4aNmyYLly4oClTptzSMLRBgwbpP//5j9q0aaNXX31Vt912m7788kvnX1f++d30+OOPq1u3burXr586duyoQ4cOafz48RmGqz3wwANasGCB+vXrp06dOunIkSN67bXXVLJkSZdhV/fdd58aNWqk559/XsnJyapXr57Wrl3rnJHmn/vO6vF68MEHVatWLUVFRalEiRI6dOiQJk2apPLly6tKlSpuv08AcoA518kCGa1du9bo1KmTcdtttxn58uUzQkNDjQ4dOhhr1qy57jbLli1zzsKxe/fuTNfZsmWL8cgjjxihoaFG/vz5jbCwMONf//qX8fHHHzvXuTqjzLUzYfzzuX/ONrNjxw6jVatWRkBAgBEUFGR07tzZOHz4cIaZHa7OVrJp0ybjwQcfNIoUKWIEBAQYXbp0cc6cczOLFi0y6tevbxQoUMAoXLiwcc899xirV692WSenZpsxDMNISUkxhg8fbpQvX97Inz+/UbJkSaNv375GYmKiy7bly5c37r//fmP+/PlGzZo1DT8/P6NChQrGxIkTb7rfPXv2GG3btjVKly5t+Pv7GwUKFDBq165tvP7668aFCxeyHP/VGYYkGdu3b3d5Lj093QgODjYkGdOmTcuwbVbe18zen6tSU1ON559/3ggNDTUKFChg3H333cbatWszzCTy4osvGlFRUUZQUJDh7+9vVKxY0Rg8eLARHx9/w9wym22mcOHCRo0aNYzRo0dnmC3EMAzjP//5j1G/fn2jcOHCRsGCBY1KlSoZ3bt3NzZu3OhcJyEhwejUqZMRGBhoOBwO49ofA+3btzckGbNnz3a2Xbx40ShcuLDh4+OT4XNgGFdmeHnyySeN0qVLG/nz5zdKlChhNGzY0Bg3bpzLen///bfx8ssvG7fffrvh5+dnFCtWzKhdu7YxePBg4+TJk871JBnPPvtshv1cb5aWa2O59n375zJjxgzDMAzju+++M+rUqWMUKFDAKF26tPHCCy8YP/zwQ4aZYZo1a2bUrFkzw36eeOKJDLP2bN++3WjZsqVRoEABIzg42OjVq5fx2WefGZKMLVu2ONdLT083xo8fb1SsWNEoUKCAERUVZfzyyy+Zzjbz5ptvGhUqVDD8/f2N6tWrG9OmTXN+Lv8pISHB6NmzpxEYGGgUKlTIaNWqlbFu3TpDkvHee+9leI9udrwmTJhgNGzY0ChevLjh5+dnlCtXzujVq5dx8ODBG77/ADzPYRjXTK4LIMeMGTNGY8eO1enTp025g6knVahQQbVq1crRG+cAeU2fPn00Z84cnTlzRn5+fl7d95dffqmuXbtq9erVGf5yCcC6GDYDAEAOePXVV1WqVClVrFhRf//9t77//nt9+umnevnllz1euM+ZM0fHjh1T7dq15ePjo3Xr1untt99W06ZNKdyBPIbiHQCAHJA/f369/fbbOnr0qC5fvqwqVapo4sSJGjhwoMf3HRAQoLlz52rcuHE6d+6cSpYsqR49emjcuHEe3zcA72LYDAAAAGARTBUJAAAAeMGYMWPkcDhclsxueHgjDJsBAAAAvKRmzZrOu1lLcrkBZVZQvAMAAABeki9fvmz3tv8Tw2YAAAAAN6Wmpio5OdllSU1Nve76e/bsUalSpRQeHq5HH31U+/fvz9b+cs0FqwXLdTE7BFNs3trV7BDgRdUDq5odgil2Ju02OwQAHmLX7zX7yp3H28w6cviTt2vs2LEubaNHj9aYMWMyrPvDDz/o/Pnzqlq1qk6dOqVx48bpzz//VGxsrEJCQrK0P4p3k1G824tdf8hRvAN5l12/1+wrdx5vM+vIpD0zM/S0+/v7y9/f/6bbnjt3TpUqVdKwYcM0ZMiQLO2PMe8AAACAm7JaqGemcOHCql27tvbs2ZPlbSjeAQAAYGkOhzUv40xNTdXOnTvVpEmTLG9jzUwBAAAAixk6dKhWrlypAwcOaP369erUqZOSk5P1xBNPZPk16HkHAACApTks0h999OhRdenSRfHx8SpRooTuvvturVu3TuXLl8/ya1C8AwAAAF4wd+7cW34NincAAABYmlXHvLvDPpkCAAAAFkfxDgAAAFgEw2YAAABgaQybAQAAAJDr0PMOAAAAS3M4HGaH4DX0vAMAAAAWQfEOAAAAWATDZgAAAGBx9umPtk+mAAAAgMXR8w4AAABLY6pIAAAAALkOxTsAAABgEQybAQAAgKUxbAYAAABArkPPOwAAACzNYaP+aPtkCgAAAFgcPe8AAACwNDuNebdl8T5ycEe9PLiTS9vJuCSFR/U1KSLviY3Zp4VfrNC+P48qMT5ZL47vobub1TY7LI+za96SNHv2Yk2fvkCnTyeqSpVyeuml3oqKqml2WB5l1+NN3uRth7wle36vSfbNG67c/jVlw4YNGjZsmB599FF16NDBZbGC2F1HVKHeM87lznuHmR2SV1xIuajwKqXUZ2h7s0PxKrvmvWTJr4qO/lR9+z6iRYveU716NdW79xgdPx5ndmgeZdfjTd7kbQd2/V6za97IyK2e97lz56p79+6699579eOPP+ree+/Vnj17dPLkSbVvb40vkcuX03Tq9Fmzw/C6eg2rq17D6maH4XV2zXvGjEXq2LGVOnduLUkaObK3fvtts+bM+UHPP/+EydF5jl2PN3nbi13ztuv3ml3zzio7DZtxK9M33nhD7777rr7//nv5+fnpvffe086dO/XII4+oXLlyOR2jR1QOD9P+DZO187f3NOvD/qpQLtTskIAcdfHiJcXG7lXjxpEu7Y0aRSomZqdJUQGA++z6vWbXvJE5t4r3ffv26f7775ck+fv769y5c3I4HBo8eLCmTp2aowF6woaYvXpq8BQ92C1a/V6cpttKBGr5grEKDixidmhAjklMTFZaWrpCQgJd2osXD9Tp00mmxAQAt8Ku32t2zTs7HA4f0xZvc2vYTHBwsP766y9JUunSpbV9+3bVrl1bSUlJOn/+/E23T01NVWpqqkubYaTJ4fB1J5xsW7Zii/P/sbuOaP2mPYr9dZK6dWqq9z9d4pUYAG9xOBwujw3D0DVNAGApdv1es2vecOXWrwtNmjTRjz/+KEl65JFHNHDgQPXu3VtdunTRPffcc9Pto6OjVaxYMZflcvIOd0LJEedTUhW764gqhYeZFgOQ04KCisrX10fx8Yku7WfOnFXx4oHmBAUAt8Cu32t2zRuZc6t4//DDD/Xoo49KkkaMGKGhQ4fq1KlT6tChg6ZPn37T7UeMGKGzZ8+6LPmK1nAnlBzh55dP1SqX0sm4JNNiAHKan19+1axZWatXx7i0r1nzhyIj7XeRGwDrs+v3ml3zzg6Hif+8ze1hM1f5+Pho2LBhGjYs61Mt+vv7y9/f36XNW0NmJCl6ZFct/mmzjhyPV2hIUQ0f0F4BRQpq9vxVXovBLCnnU3XiaLzzcdzxBO3ffUwBRQupRFiQiZF5ll3z7tmznYYNm6hataooMrKa5s1bqhMnTuvRR9uYHZpH2fV4k/cV5J2387br95pd80ZGDsMwjOxu5OvrqxMnTig01HWGljNnzig0NFRpaWnZDqRguS7Z3sZdsz7sr8b1qyskKEDxCcn6ffMejZ3wtf7cc8xrMVy1eWtXr+5v26a9eqXflAztLe6P0sBR3jsG3pZb8q4eWNVr+7rq6k094uISVLVqeY0Y8ZTuvLOWV2PYmbTbq/vLLcfb28jbFXl7h12/18yQO/L2/vHOitBqz5u277g/J3h1f24V7z4+Pjp58mSG4v348eOqVKmSUlJSsh2IN4v33MTbxTvMZcYPudzA28U7AO+x6/eafeXO422n4j1bw2bef/99SVeudv70009VpMj/plZMS0vTqlWrVK1atZyNEAAAALgBO92kKVvF+7vvvivpytREH3/8sXx9/zdO3c/PTxUqVNDHH3+csxECAAAAkJTN4v3AgQOSpBYtWmjhwoUKDAz0REwAAAAAMpHl4n3IkCF67bXXVLhwYdWtW1evvvrqddedOHFijgQHAAAA3AzDZjIRExOjS5cuSZL++OOP66537d2/AAAAAOSMLBfvy5cvz/T/AAAAgLns0/Nun0wBAAAAi6N4BwAAACwiW7PNAAAAALmNnS5YtU+mAAAAgMXR8w4AAABLo+cdAAAAQK5DzzsAAAAszWGj/mj7ZAoAAABYHMU7AAAAYBEMmwEAAIClccEqAAAAgFyHnncAAABYmsPhMDsEr6HnHQAAALAIincAAADAIhg2AwAAAEvjglUAAAAAuQ497wAAALA07rAKAAAAINeh5x0AAACWxph3AAAAALlOrul537y1q9khmOKOiNlmh2CKMiP7mh2CKb79926zQzBF9cCqZocAL9qZxOccADwl1xTvAAAAgDsYNgMAAAAg16HnHQAAAJbGVJEAAAAAch2KdwAAAMAiGDYDAAAAa+OCVQAAAAC5DT3vAAAAsDSmigQAAACQ69DzDgAAAEtzOBxmh+A19LwDAAAAFkHxDgAAAFgEw2YAAABgadxhFQAAAECuQ887AAAALI2pIgEAAADkOhTvAAAAgEUwbAYAAADWxjzvAAAAAHIbet4BAABgbTbqjrZRqgAAAIC10fMOAAAAa7PRmPdbKt5TUlJ06dIll7aiRYveUkAAAAAAMpftYTPnz5/Xc889p9DQUBUpUkRBQUEuCwAAAADPyHbP+wsvvKDly5dr8uTJ6t69uz766CMdO3ZMn3zyid58801PxOgRsTH7tPCLFdr351ElxifrxfE9dHez2maH5VEjB3fUy4M7ubSdjEtSeFRfkyLyjsdqlFSXGiVVJqCAJGlP4nl9uOmQVh1JNDkyz7Pj5/yq2bMXa/r0BTp9OlFVqpTTSy/1VlRUTbPD8jg75s3n3F7HWyJvu+WdJTYaNpPtnvfvvvtOkydPVqdOnZQvXz41adJEL7/8st544w3Nnj3bEzF6xIWUiwqvUkp9hrY3OxSvit11RBXqPeNc7rx3mNkhedzJc6l6Z/0BtV8Qo/YLYrT2WJKmtK6pykGFzA7N4+z6OV+y5FdFR3+qvn0f0aJF76levZrq3XuMjh+PMzs0j7Jr3nzO7XW8ydteeSOjbBfvCQkJCg8Pl3RlfHtCQoIkqXHjxlq1alXORudB9RpWV9dn2qhBiwizQ/Gqy5fTdOr0WecSn/CX2SF53C+HErTySKIOnk3RwbMpenfDQZ2/lKa6oXn/+gy7fs5nzFikjh1bqXPn1qpUqaxGjuytsLDimjPnB7ND8yi75s3n3F7Hm7ztlXeW+Zi4eFm2d1mxYkUdPHhQklSjRg199dVXkq70yAcGBuZkbPCAyuFh2r9hsnb+9p5mfdhfFcqFmh2SV/k4pPsrlVCh/L7641Sy2eHAAy5evKTY2L1q3DjSpb1Ro0jFxOw0KSrPs2vedmXX403e9sobmcv2mPeePXtqy5YtatasmUaMGKH7779fH3zwgS5fvqyJEyd6IkbkkA0xe/XU4Cnas/+EQksU04v922v5grGq1/IFJST9bXZ4HlU1uJC+ahcpf18fnb+Upn7/F6u9SefNDgsekJiYrLS0dIWEBLq0Fy8eqNOnk0yJyRvsmrdd2fV4k3egS3tezxuZy3bxPnjwYOf/W7RooT///FMbN25UpUqVVKdOnSy9RmpqqlJTU13aLqZekp9//uyGg2xYtmKL8/+xu45o/aY9iv11krp1aqr3P11iYmSedyApRQ/N36SifvnUumJxjW9xu7p+u5UCPg9zXHPxkmEYtrieya5525Vdjzd5X2GXvLPCsNEbka1hM5cuXVKLFi20e/duZ1u5cuXUoUOHLBfukhQdHa1ixYq5LFPf/To7oSAHnE9JVeyuI6oUHmZ2KB53Kd3Q4eQL2h7/tyb8flA7z5zTE7VLmx0WPCAoqKh8fX0UH+86m9CZM2dVvHigOUF5gV3ztiu7Hm/ytlfeyFy2ivf8+fNr+/btGX7zy64RI0bo7NmzLkufwZ1v6TWRfX5++VStcimdjEsyOxSvczgkP1/7/JZuJ35++VWzZmWtXh3j0r5mzR+KjKxuUlSeZ9e87cqux5u87ZV3tjhMXLws28NmunfvrunTp9/SnO7+/v7y9/d3afNL9+6QmZTzqTpxNN75OO54gvbvPqaAooVUIixv3mwqemRXLf5ps44cj1doSFENH9BeAUUKavZ868wS5I4hd1XQqsMJOvF3qgr7+er+SqGqXzJQvZZsMzs0j7Pj51ySevZsp2HDJqpWrSqKjKymefOW6sSJ03r00TZmh+ZRds2bz7m9jjd52ytvZJTt4v3ixYv69NNP9eOPPyoqKkqFCxd2ed4qF63u3XlEr/Sb4nz8n0nfSpJa3B+lgaO6mBWWR5UuGaxZH/ZXSFCA4hOS9fvmPWrWbpQOH4u/+cYWVrygn97+VzWFFvLTXxcv688z59RryTatPpZkdmgeZ8fPuSS1bdtEiYnJmjx5ruLiElS1anlNnTpapUvn7dmV7Jo3n3N7HW/ytlfeyMhhGIZxs5W2bt2qWrVqycfHRy1atLj+izkc+uWXX9wKZGfS925tZ3V3RFjnxlY5qczIvH1X1+v59t/2nJ6yemBVs0OAF+1M2n3zlfIgPuewh9z5Oa/SfKpp+96zoo9X95elnvfIyEidOHFCoaGhOnTokDZs2KCQkBBPxwYAAADgH7J0wWpgYKAOHDggSTp48KDS09M9GhQAAACQZQ6HeYuXZannvWPHjmrWrJlKliwph8OhqKgo+fr6Zrru/v37czRAAAAAAFdkqXifOnWqOnTooL1792rAgAHq3bu3AgICPB0bAAAAcHM2mv05y7PN3HfffZKkTZs2aeDAgRTvAAAAgJdle6rIGTNmeCIOAAAAADeR7eIdAAAAyFV87DNuJkuzzQAAAAAwHz3vAAAAsDYTpmw0Cz3vAAAAgEVQvAMAAAAWwbAZAAAAWJt9Rs3Q8w4AAABYBT3vAAAAsDamigQAAACQ29DzDgAAAGuzT8c7Pe8AAACAVVC8AwAAABbBsBkAAABYmsEdVgEAAADkNvS8AwAAwNqYKhIAAACAJ0VHR8vhcGjQoEFZ3obiHQAAAPCyDRs2aOrUqYqIiMjWdhTvAAAAsDaHiYsb/v77b3Xt2lXTpk1TUFBQtraleAcAAADclJqaquTkZJclNTX1hts8++yzuv/++9WyZcts748LVk1WZmRfs0MwxdHXp5gdgimm1+1tdgimeKe+2REAAPI0E6eKjI6O1tixY13aRo8erTFjxmS6/ty5c7V582Zt2LDBrf1RvAMAAABuGjFihIYMGeLS5u/vn+m6R44c0cCBA7Vs2TIVKFDArf1RvAMAAMDaTJwq0t/f/7rF+rU2bdqkuLg41atXz9mWlpamVatW6cMPP1Rqaqp8fX1v+BoU7wAAAIAX3HPPPdq2bZtLW8+ePVWtWjUNHz78poW7RPEOAAAAeEVAQIBq1arl0la4cGGFhIRkaL8eincAAABYm31usErxDgAAAJhlxYoV2Vqf4h0AAADWZuJUkd7GTZoAAAAAi6B4BwAAACyCYTMAAACwNobNAAAAAMht6HkHAACAtdmoO9pGqQIAAADWRs87AAAArI0x7wAAAAByG4p3AAAAwCIYNgMAAABrs8+oGXreAQAAAKug5x0AAACWZvjYp+udnncAAADAIijeAQAAAIu4pWEzO3bs0OHDh3Xx4kWX9oceeuiWggIAAACyzEbzvLtVvO/fv1/t27fXtm3b5HA4ZBiGJMnx/9+4tLS0nIsQAAAAgCQ3h80MHDhQ4eHhOnXqlAoVKqTY2FitWrVKUVFRWrFiRQ6HCAAAANyAw8TFy9zqeV+7dq1++eUXlShRQj4+PvLx8VHjxo0VHR2tAQMGKCYmJqfjzHGxMfu08IsV2vfnUSXGJ+vF8T10d7PaZoflUY/VKKkuNUqqTEABSdKexPP6cNMhrTqSaHJknjVycEe9PLiTS9vJuCSFR/U1KSLv2PPdUp3Y+If+PnFSvvnzK6hKJdX4dzsVKRlmdmheMXv2Yk2fvkCnTyeqSpVyeuml3oqKqml2WB5nx7zt+H1+lR2Pt0TedssbrtzqeU9LS1ORIkUkScWLF9fx48clSeXLl9euXbtyLjoPupByUeFVSqnP0PZmh+I1J8+l6p31B9R+QYzaL4jR2mNJmtK6pioHFTI7NI+L3XVEFeo941zuvHeY2SF53Jk/9yi8ZTM1GTVMdw8fKCMtTevGf6DLqalmh+ZxS5b8qujoT9W37yNatOg91atXU717j9Hx43Fmh+ZRds3bjt/nkn2PN3nbK+8s83GYt3g7VXc2qlWrlrZu3SpJql+/vsaPH6/Vq1fr1VdfVcWKFXM0QE+p17C6uj7TRg1aRJgditf8cihBK48k6uDZFB08m6J3NxzU+Utpqhta1OzQPO7y5TSdOn3WucQn/GV2SB539wv9VbZJAwWUKaVi5cqobu/uSjmToLMHDpsdmsfNmLFIHTu2UufOrVWpUlmNHNlbYWHFNWfOD2aH5lF2zduO3+eSfY83edsrb2TkVvH+8ssvKz09XZI0btw4HTp0SE2aNNGSJUv0/vvv52iA8Awfh3R/pRIqlN9Xf5xKNjscj6scHqb9GyZr52/vadaH/VWhXKjZIXnd5ZQUSVL+Inn7Ly0XL15SbOxeNW4c6dLeqFGkYmJ2mhSV59k1b7uy6/Emb3vljcy5Nea9devWzv9XrFhRO3bsUEJCgoKCgpwzziB3qhpcSF+1i5S/r4/OX0pTv/+L1d6k82aH5VEbYvbqqcFTtGf/CYWWKKYX+7fX8gVjVa/lC0pI+tvs8LzCMAzFfjlfwVUrqWiZ0maH41GJiclKS0tXSEigS3vx4oE6fTrJlJi8wa5525Vdjzd5B7q05/W8s8VG9ectzfMuSUeOHJHD4VCZMmWyvE1qaqpSrxl3ezH1kvz8899qOLiJA0kpemj+JhX1y6fWFYtrfIvb1fXbrXm6gF+2Yovz/7G7jmj9pj2K/XWSunVqqvc/XWJiZN6zfdZcJR85pkYvDzU7FK+5tiPBMAxbfLfbNW+7suvxJu8r7JI3XLk1bOby5ct65ZVXVKxYMVWoUEHly5dXsWLF9PLLL+vSpUs33T46OlrFihVzWaa++7U7oSCbLqUbOpx8Qdvj/9aE3w9q55lzeqJ23u6Jvdb5lFTF7jqiSuH2mHVl26x5OhmzTQ1HDFbB4CCzw/G4oKCi8vX1UXy86yxKZ86cVfHigeYE5QV2zduu7Hq8ydteeWeLjaaKdKt4f+655zR16lSNHz9eMTExiomJ0fjx4zV9+nT179//ptuPGDFCZ8+edVn6DO7sTii4RQ6H5Odrr1/b/fzyqVrlUjoZl2R2KB5lGIa2zZqrk5ti1ODFQSpUorjZIXmFn19+1axZWatXu05Zu2bNH4qMrG5SVJ5n17ztyq7Hm7ztlTcy59awmTlz5mju3Llq06aNsy0iIkLlypXTo48+qo8//viG2/v7+8vf39+lzS/du0NmUs6n6sTReOfjuOMJ2r/7mAKKFlKJsLzZOznkrgpadThBJ/5OVWE/X91fKVT1Swaq15JtZofmUdEju2rxT5t15Hi8QkOKaviA9gooUlCz568yOzSP2vbZXB1bt0F3DnpG+Qr460LSWUlS/kIF5evnZ3J0ntWzZzsNGzZRtWpVUWRkNc2bt1QnTpzWo4+2ufnGFmbXvO34fS7Z93iTt73yRkZuFe8FChRQhQoVMrRXqFBBfhYpCvbuPKJX+k1xPv7PpG8lSS3uj9LAUV3MCsujihf009v/qqbQQn766+Jl/XnmnHot2abVx5LMDs2jSpcM1qwP+yskKEDxCcn6ffMeNWs3SoePxd98Yws79MuVX07WvvGuS3vd3t1VtkkDM0LymrZtmygxMVmTJ89VXFyCqlYtr6lTR6t06bw9y5Bd87bj97lk3+NN3vbKO8tMmG/dLA7DMIzsbvTqq6/qzz//1IwZM5w96KmpqerVq5eqVKmi0aNHZzuQnUnfZ3ubvOCheXl/jvXMHH19ys1XyoOe/bq32SGY4p36Wb+gHda3M2m32SGYonpgVbNDALwgd37OK/X8yrR975vxiFf351bPe0xMjH7++WeVKVNGderUkSRt2bJFFy9e1D333KMOHTo4112wYEHORAoAAABkxkY9724V74GBgerYsaNLW9myZXMkIAAAAACZc6t4nzx5stLT01W4cGFJ0sGDB7Vo0SJVr17d5QZOAAAAgKcZ9ul4d2+qyIcffliff/65JCkpKUl33323JkyYoHbt2mnKFHuOZQYAAAA8za3iffPmzWrSpIkkaf78+brtttt06NAhzZo1S++//36OBggAAADgCreGzZw/f14BAQGSpGXLlqlDhw7y8fHR3XffrUOHDuVogAAAAMAN2eiCVbd63itXrqxFixbpyJEj+r//+z/de++9kqS4uDgVLWrPqQ8BAAAAT3OreB81apSGDh2qChUqqH79+mrQ4MoNX5YtW6bIyMgcDRAAAAC4IYfDvMXL3Bo206lTJzVu3FgnTpxwzvMuSffcc4/at2+fY8EBAAAA+B+3indJCgsLU1hYmEvbXXfddcsBAQAAAMic28U7AAAAkCtwwSoAAACA3IaedwAAAFibjbqjbZQqAAAAYG0U7wAAAIBFMGwGAAAA1mbCfOtmoecdAAAAsAh63gEAAGBtTBUJAAAAILeh5x0AAACWZjDmHQAAAEBuQ/EOAAAAWATDZgAAAGBtNuqOtlGqAAAAgLXR8w4AAABrY6pIAAAAALlNrul5rx5Y1ewQTPHtv3ebHYIpptftbXYIpvio8zSzQzDFO4fHmh0CAOSonUn2/Plt13otN8k1xTsAAADgFuZ5BwAAAJDb0PMOAAAAa+OCVQAAAAC5DT3vAAAAsDb7dLzT8w4AAABYBcU7AAAAYBEMmwEAAIClGVywCgAAACC3oecdAAAA1kbPOwAAAIDchuIdAAAAsAiGzQAAAMDaHAybAQAAAJDL0PMOAAAAa7NRd7SNUgUAAACsjZ53AAAAWBtj3gEAAADkNhTvAAAAgEUwbAYAAADWxh1Wr88wDB06dEgpKSmeiAcAAADAdbhVvFepUkVHjx71RDwAAABA9vg4zFu8nWq2N/DxUZUqVXTmzBlPxAMAAADgOty6YHX8+PF64YUXtH379pyOBwAAAMB1uHXBardu3XT+/HnVqVNHfn5+KliwoMvzCQkJORKcp82evVjTpy/Q6dOJqlKlnF56qbeiomqaHZZHxcbs08IvVmjfn0eVGJ+sF8f30N3Napsdlkft+W6pTmz8Q3+fOCnf/PkVVKWSavy7nYqUDDM7NI8aObijXh7cyaXtZFySwqP6mhSRd9nx/Jbsmbcdv9eusuPxluyZt50/51lh2Gied7eK90mTJuVwGN63ZMmvio7+VKNHP6M77qihuXOXqnfvMVq8+COVKhVqdngecyHlosKrlNI9D9ypt178zOxwvOLMn3sU3rKZAsPLKz09XX9+/V+tG/+Bmr85Svn8/c0Oz6Nidx3R/Y+97nyclpZuYjTeY9fz26552/F7TbLv8bZr3nb9nCMjt4r3J554Iqfj8LoZMxapY8dW6ty5tSRp5Mje+u23zZoz5wc9/7z187ueeg2rq17D6maH4VV3v9Df5XHd3t217LlhOnvgsEKqVTEpKu+4fDlNp06fNTsMr7Pr+W3XvO34vSbZ93jbNW+7fs6zzEZ3LnI71bS0NH3zzTcaN26cXn/9dS1cuFBpaWk5GZvHXLx4SbGxe9W4caRLe6NGkYqJ2WlSVPCWy/9/mtP8RQqZHInnVQ4P0/4Nk7Xzt/c068P+qlAu7/ZKXWXX89uueduVXY+3XfMG/smtnve9e/eqbdu2OnbsmG6//XYZhqHdu3erbNmyWrx4sSpVqpTTceaoxMRkpaWlKyQk0KW9ePFAnT6dZEpM8A7DMBT75XwFV62komVKmx2OR22I2aunBk/Rnv0nFFqimF7s317LF4xVvZYvKCHpb7PD8xi7nt92zduu7Hq87Zo3ssBGY97d6nkfMGCAKlWqpCNHjmjz5s2KiYnR4cOHFR4ergEDBtx0+9TUVCUnJ7ssqakX3QnlljiuOdCGYdjp2NvS9llzlXzkmO7o18vsUDxu2YotWvTD74rddUTLf9uu9j3GS5K6dWpqcmTeYdfz265525Vdj7dd8wYkN4v3lStXavz48QoODna2hYSE6M0339TKlStvun10dLSKFSvmskRHf+JOKG4JCioqX18fxccnurSfOXNWxYsHei0OeNe2WfN0MmabGo4YrILBQWaH43XnU1IVu+uIKoXn7Vl27Hp+2zVvu7Lr8bZr3sA/uVW8+/v766+//srQ/vfff8vPz++m248YMUJnz551WUaMeNqdUNzi55dfNWtW1urVMS7ta9b8ochILgbJawzD0LZZc3VyU4wavDhIhUoUNzskU/j55VO1yqV0Mi7J7FA8yq7nt13ztiu7Hm+75o0ssNEdVt0a8/7AAw+oT58+mj59uu666y5J0vr16/XMM8/ooYceuun2/v7+8s8wRd/Ni/6c1LNnOw0bNlG1alVRZGQ1zZu3VCdOnNajj7bxahzelnI+VSeOxjsfxx1P0P7dxxRQtJBKhOXN3uhtn83VsXUbdOegZ5SvgL8uJF2ZfSV/oYLyzcIvm1YVPbKrFv+0WUeOxys0pKiGD2ivgCIFNXv+KrND8zi7nt92zduO32uSfY+3XfO26+ccGblVvL///vt64okn1KBBA+XPn1+SdOnSJT388MN67733cjRAT2nbtokSE5M1efJcxcUlqGrV8po6dbRKl87bs3Hs3XlEr/Sb4nz8n0nfSpJa3B+lgaO6mBWWRx365UqxuvaNd13a6/burrJNGpgRkleULhmsWR/2V0hQgOITkvX75j1q1m6UDh+Lv/nGFmfX89uuedvxe02y7/G2a952/ZxnmQk94GZxGIZhuLvx3r17tWPHDklSjRo1VLly5VsIZfctbGtdO5Psmff0XXl/msbMfNR5mtkhmCLl8FizQ4AX2fV7rXpgVbNDgBfZ93P+gNkhZKr827+Ytu9DL/zLq/tzq+ddkqZPn653331Xe/bskSRVqVJFgwYN0lNPPZVjwQEAAAD4H7eK91deeUXvvvuu+vfvrwYNrgw7WLt2rQYPHqyDBw9q3LhxORokAAAAcF32GTXjXvE+ZcoUTZs2TV26/G+M1UMPPaSIiAj179+f4h0AAADwALeK97S0NEVFRWVor1evni5fvnzLQQEAAABZZdjoglW35nnv1q2bpkyZkqF96tSp6tq16y0HBQAAACCjW7pgddmyZbr77rslSevWrdORI0fUvXt3DRkyxLnexIkTbz1KAAAA4Hoc9ul5d6t43759u+644w5J0r59+yRJJUqUUIkSJbR9+3bneg4bvZEAAACAp7lVvC9fvjyn4wAAAABwE24PmwEAAAByBS5YBQAAAJDb0PMOAAAAa7NPxzs97wAAAIBVULwDAAAAFsGwGQAAAFiaj426o22UKgAAAGBt9LwDAADA0ux0X1B63gEAAACLoOcdAAAAlkbPOwAAAIBch+IdAAAAsAiGzQAAAMDSHDYaN0PPOwAAAOAFU6ZMUUREhIoWLaqiRYuqQYMG+uGHH7L1GvS8AwAAwNKs0vFepkwZvfnmm6pcubIk6bPPPtPDDz+smJgY1axZM0uvQfEOAAAAeMGDDz7o8vj111/XlClTtG7dOop3AAAAILdKS0vT119/rXPnzqlBgwZZ3o7iHQAAAJZm5rCZ1NRUpaamurT5+/vL398/0/W3bdumBg0a6MKFCypSpIgWLlyoGjVqZHl/DsMwjFuKOIfsTPre7BBMUT2wqtkhAB5XsNxos0MwxeatXc0OAV7E9znsIXd+zqt8ssq0fXc98YvGjh3r0jZ69GiNGTMm0/UvXryow4cPKykpSd98840+/fRTrVy5MssFPMW7yfiyhx1QvMMO+D6HPeTOz3nVaeYV79u6189Wz/u1WrZsqUqVKumTTz7J0voMmwEAAADclJ1CPTOGYWQo/m+E4h0AAADwgpdeeklt2rRR2bJl9ddff2nu3LlasWKFli5dmuXXoHgHAACApVllnvdTp07p8ccf14kTJ1SsWDFFRERo6dKlatWqVZZfg+IdAAAA8ILp06ff8mtQvAMAAMDSfCzS854TfMwOAAAAAEDW0PMOAAAAS7PKmPecQM87AAAAYBEU7wAAAIBFMGwGAAAAlsawGQAAAAC5Dj3vAAAAsDSHjbre6XkHAAAALILiHQAAALAIhs0AAADA0hw26o62UaoAAACAtdHzDgAAAEuz0fWq9LwDAAAAVkHPOwAAACzNTj3vbhXvkZGRmc6n6XA4VKBAAVWuXFk9evRQixYtbjlAAAAAAFe4NWzmvvvu0/79+1W4cGG1aNFCzZs3V5EiRbRv3z7deeedOnHihFq2bKn//ve/OR0vAAAAYFtu9bzHx8fr+eef1yuvvOLSPm7cOB06dEjLli3T6NGj9dprr+nhhx/OkUABAACAzNhp2IxbPe9fffWVunTpkqH90Ucf1VdffSVJ6tKli3bt2nVr0QEAAABwcqt4L1CggNasWZOhfc2aNSpQoIAkKT09Xf7+/rcWnQfFxuzTuOenq+f9Y9Wu/vNat3Kb2SF5zezZi/Wvf/VS7dod1KHDIG3cGGt2SF5B3vbIe+Tgjko5PMdlObBxitlheYVdv9fsmrdkv/P7KvK2V95Z4eMwb/F6ru5s1L9/fz3zzDMaOHCgvvjiC82ePVsDBw5U3759NWDAAEnS//3f/ykyMjJHg81JF1IuKrxKKfUZ2t7sULxqyZJfFR39qfr2fUSLFr2nevVqqnfvMTp+PM7s0DyKvO2Vd+yuI6pQ7xnncue9w8wOySvs+r1m17zten6Tt73yRkZuFe8vv/yypk2bpt9//10DBgxQ//799fvvv2vatGkaOXKkJOmZZ57Rd999l6PB5qR6Daur6zNt1KBFhNmheNWMGYvUsWMrde7cWpUqldXIkb0VFlZcc+b8YHZoHkXe9sr78uU0nTp91rnEJ/xldkheYdfvNbvmbdfzm7ztlTcycvsmTV27dtXatWuVkJCghIQErV27Vo899pjz+YIFCzqH0CB3uHjxkmJj96pxY9e/iDRqFKmYmJ0mReV55G2vvCWpcniY9m+YrJ2/vadZH/ZXhXKhZocE5Ci7nt/kba+8s8PhMG/xtlu6SdPFixcVFxen9PR0l/Zy5crdcLvU1FSlpqa6vlbqJfn557+VcHATiYnJSktLV0hIoEt78eKBOn06yZSYvIG8A13a83reG2L26qnBU7Rn/wmFliimF/u31/IFY1Wv5QtKSPrb7PCAHGHX85u8A13a83reyJxbPe979uxRkyZNVLBgQZUvX17h4eEKDw9XhQoVFB4eftPto6OjVaxYMZdl6rtfuxMK3HDtDbYMw7DFFEvkfUVez3vZii1a9MPvit11RMt/2672PcZLkrp1ampyZEDOs9v5fRV5X2GXvLOCnveb6NGjh/Lly6fvv/9eJUuWzPRuqzcyYsQIDRkyxKXtQMrP7oSCbAgKKipfXx/Fxye6tJ85c1bFiweaE5QXkLe98r7W+ZRUxe46okrhYWaHAuQYu57f5G2vvJE5t3re//jjD33yySdq06aN6tatqzp16rgsN+Pv76+iRYu6LAyZ8Tw/v/yqWbOyVq+OcWlfs+YPRUZWNykqzyNve+V9LT+/fKpWuZROxiWZHQqQY+x6fpO3vfLODoePw7TF29zqea9Ro4bi4+NzOhavSjmfqhNH/5dD3PEE7d99TAFFC6lEWJCJkXlWz57tNGzYRNWqVUWRkdU0b95SnThxWo8+2sbs0DyKvO2Td/TIrlr802YdOR6v0JCiGj6gvQKKFNTs+avMDs3j7Pq9Zte87Xh+S+Rtt7yRkVvF+1tvvaVhw4bpjTfeUO3atZU/v2uvedGiRXMkOE/au/OIXun3vxu3/GfSt5KkFvdHaeCojHePzSvatm2ixMRkTZ48V3FxCapatbymTh2t0qXz9mwc5G2fvEuXDNasD/srJChA8QnJ+n3zHjVrN0qHj1m7wyEr7Pq9Zte87Xh+S+Rtt7yRkcMwDCO7G/n4/G+0zT/Hu1+5cMKhtLS0bAeyM+n7bG+TF1QPrGp2CIDHFSw32uwQTLF5a1ezQ4AX8X0Oe8idn/O7vv7NtH3/3rmxV/fnVs/78uXLczoOAAAAADfh1gWrzZo1k4+Pj6ZNm6YXX3xRlStXVrNmzXT48GH5+vrmdIwAAADAddlpqki3ivdvvvlGrVu3VsGCBRUTE+O84dJff/2lN954I0cDBAAAAHCFW8X7uHHj9PHHH2vatGkuF6s2bNhQmzdvzrHgAAAAAPyPW2Ped+3apaZNM96tsGjRokpKSrrVmAAAAIAss9OdZt3qeS9ZsqT27t2bof23335TxYoVbzkoAAAAABm51fP+9NNPa+DAgfrPf/4jh8Oh48ePa+3atRo6dKhGjRqV0zECAAAA12XCjU5N41bxPmzYMJ09e1YtWrTQhQsX1LRpU/n7+2vo0KF67rnncjpGAAAAAHKzeJek119/XSNHjtSOHTuUnp6uGjVqqEiRIjkZGwAAAHBTdhrz7nbxLkmFChVSVFRUTsUCAAAA4AbcumAVAAAAgPfdUs87AAAAYDaHjbqjbZQqAAAAYG30vAMAAMDS7HTBKj3vAAAAgEVQvAMAAAAWwbAZAAAAWJrDRuNm6HkHAAAALIKedwAAAFiajTre6XkHAAAArIKedwAAAFgaPe8AAAAAch2KdwAAAMAiGDYDAAAAS2PYDAAAAIBch553AB63eWtXs0MwxR0Rs80OwRR2Pd4AzONDzzsAAACA3IbiHQAAALAIhs0AAADA0hg2AwAAACDXoecdAAAAlubjMMwOwWvoeQcAAAAsgp53AAAAWBpj3gEAAADkOhTvAAAAgEUwbAYAAACWZqfeaDvlCgAAAFgaPe8AAACwNKaKBAAAAJDrULwDAAAAFsGwGQAAAFga87wDAAAAyHXoeQcAAICl2ak32k65AgAAAJZG8Q4AAABYBMNmAAAAYGl2umDVreI9PDxcDsf136X9+/e7HRAAAACAzLlVvA8aNMjl8aVLlxQTE6OlS5fqhRdeyIm4AAAAgCxx2OgOq24V7wMHDsy0/aOPPtLGjRtvKSAAAAAAmcvRC1bbtGmjb775JidfEgAAALghH4d5i9dzzckXmz9/voKDg3PyJT0mNmafxj0/XT3vH6t29Z/XupXbzA7Ja2bPXqx//auXatfuoA4dBmnjxlizQ/IK8rZP3nY8v0cO7qiUw3NclgMbp5gdllfY8XhfZcfzWyJvu+UNV24V75GRkbrjjjucS2RkpEqWLKmXXnpJL730Uk7H6BEXUi4qvEop9Rna3uxQvGrJkl8VHf2p+vZ9RIsWvad69Wqqd+8xOn48zuzQPIq87ZW3Xc/v2F1HVKHeM87lznuHmR2SV9j1eNv1/CZve+WNjNwa896uXTuXxz4+PipRooSaN2+uatWq5URcHlevYXXVa1jd7DC8bsaMRerYsZU6d24tSRo5srd++22z5sz5Qc8//4TJ0XkOedsrb7ue35cvp+nU6bNmh+F1dj3edj2/ydteeWeVnW5c5FbxPnr06JyOA15w8eIlxcbuVZ8+nVzaGzWKVEzMTpOi8jzytlfedlY5PEz7N0xWauolbfhjr0aNn6eDh+mVy4vsen6Tt73yRubc/kVl3759evnll9WlSxfFxV354bB06VLFxjL+KrdKTExWWlq6QkICXdqLFw/U6dNJpsTkDeQd6NKe1/O2qw0xe/XU4Cl6sFu0+r04TbeVCNTyBWMVHFjE7NDgAXY9v8k70KU9r+edHT4Ow7TF67m6s9HKlStVu3ZtrV+/XgsWLNDff/8tSdq6dWuWeuVTU1OVnJzsslxMveROKHDDtTfYMgxDN7jnVp5B3lfYJW+7WbZiixb98Ltidx3R8t+2q32P8ZKkbp2amhwZPMmu5zd5X2GXvOHKreL9xRdf1Lhx4/Tjjz/Kz8/P2d6iRQutXbv2pttHR0erWLFiLsvUd792JxRkQ1BQUfn6+ig+PtGl/cyZsypePNCcoLyAvO2VN644n5Kq2F1HVCk8zOxQ4AF2Pb/J2155I3NuFe/btm1T+/YZr+ovUaKEzpw5c9PtR4wYobNnz7osfQZ3dicUZIOfX37VrFlZq1fHuLSvWfOHIiPz7sVe5G2vvHGFn18+VatcSifjkswOBR5g1/ObvO2Vd3bYaZ53ty5YDQwM1IkTJxQeHu7SHhMTo9KlS990e39/f/n7+7u0+aXndycUt6WcT9WJo/HOx3HHE7R/9zEFFC2kEmFBXo3Fm3r2bKdhwyaqVq0qioyspnnzlurEidN69NE2ZofmUeRtr7zteH5Hj+yqxT9t1pHj8QoNKarhA9oroEhBzZ6/yuzQPM6Ox1uy7/lN3vbKGxm5Vbw/9thjGj58uL7++ms5HA6lp6dr9erVGjp0qLp3757TMXrE3p1H9Eq//93A5D+TvpUktbg/SgNHdTErLI9r27aJEhOTNXnyXMXFJahq1fKaOnW0SpcONTs0jyJve+Vtx/O7dMlgzfqwv0KCAhSfkKzfN+9Rs3ajdPhY/M03tjg7Hm/Jvuc3edsr76yy01SRDsMwsn2Z7KVLl9SjRw/NnTtXhmEoX758unz5srp27aqZM2fK19c324HsTPo+29vkBdUDq5odAuBxO5N2mx2CKe6ImG12CKbYvLWr2SGYgu9z2EPu/Jx3X7nStH3PatbMq/tzq+c9f/78mj17tl577TVt3rxZ6enpioyMVJUqVXI6PgAAAOCGzBh7bpYsF+9Dhgy54fPr1q1z/n/ixInuRwQAAAAgU1ku3mNiXK9w3rRpk9LS0nT77bdLknbv3i1fX1/Vq1cvZyMEAAAAICkbxfvy5cud/584caICAgL02WefKSjoypX8iYmJ6tmzp5o0aZLzUQIAAADXYcadTs3i1sW5EyZMUHR0tLNwl6SgoCCNGzdOEyZMyLHgAAAAAPyPW8V7cnKyTp06laE9Li5Of/311y0HBQAAAGSVnW7S5Fbx3r59e/Xs2VPz58/X0aNHdfToUc2fP1+9evVShw4dcjpGAAAAAHJzqsiPP/5YQ4cOVbdu3XTp0qUrL5Qvn3r16qW33347RwMEAAAAcIVbxXuhQoU0efJkvf3229q3b58Mw1DlypVVuHDhnI4PAAAAuCE73WHVreL9qsKFCysiIiKnYgEAAABwA7dUvAMAAABmY6pIAAAAALkOPe8AAACwNDOmbDQLPe8AAACARVC8AwAAABbBsBkAAABYGsNmAAAAAOQ69LwDAADA0uzUG22nXAEAAABLo3gHAAAALIJhMwAAALA07rAKAAAAIEdFR0frzjvvVEBAgEJDQ9WuXTvt2rUrW69B8Q4AAABL83GYt2THypUr9eyzz2rdunX68ccfdfnyZd177706d+5cll+DYTMAAACAFyxdutTl8YwZMxQaGqpNmzapadOmWXoNincAAABYmlWHkpw9e1aSFBwcnOVtKN4BAAAAN6Wmpio1NdWlzd/fX/7+/jfczjAMDRkyRI0bN1atWrWyvD+Kd5PtTNptdggAPGTz1q5mh2CKOyJmmx2CKVIOjzU7BAAmiI6O1tixruf/6NGjNWbMmBtu99xzz2nr1q367bffsrU/incAAABYWnYvHM1JI0aM0JAhQ1zabtbr3r9/f3377bdatWqVypQpk639UbwDAAAAbsrKEJmrDMNQ//79tXDhQq1YsULh4eHZ3h/FOwAAACzNYZGbND377LP68ssv9d///lcBAQE6efKkJKlYsWIqWLBgll7DqhfnAgAAAJYyZcoUnT17Vs2bN1fJkiWdy7x587L8GvS8AwAAAF5gGLf+FwKKdwAAAFiamResehvDZgAAAACLoOcdAAAAlman3mg75QoAAABYGj3vAAAAsDQfi0wVmRPoeQcAAAAsguIdAAAAsAiGzQAAAMDSmCoSAAAAQK5DzzsAAAAsjZ53AAAAALkOxTsAAABgEQybAQAAgKX5mh2AF9HzDgAAAFgEPe8AAACwNO6wCgAAACDXoecdAAAAlmanqSKzXLxv3bo1yy8aERHhVjAAAAAAri/LxXvdunXlcDhkGIYcjhv/epOWlnbLgQEAAABwleXi/cCBA87/x8TEaOjQoXrhhRfUoEEDSdLatWs1YcIEjR8/Puej9IDYmH1a+MUK7fvzqBLjk/Xi+B66u1lts8PyOPImb/LOu+yY98jBHfXy4E4ubSfjkhQe1dekiLxr9uzFmj59gU6fTlSVKuX00ku9FRVV0+ywPI687ZV3Vthp2EyWL1gtX768c3njjTf0/vvv6+mnn1ZERIQiIiL09NNPa9KkSXrttdc8GW+OuZByUeFVSqnP0PZmh+JV5E3edkDe9so7dtcRVaj3jHO5895hZofkFUuW/Kro6E/Vt+8jWrToPdWrV1O9e4/R8eNxZofmUeRtr7yRkVsXrG7btk3h4eEZ2sPDw7Vjx45bDsob6jWsrnoNq5sdhteRt72Qt73YNe/Ll9N06vRZs8PwuhkzFqljx1bq3Lm1JGnkyN767bfNmjPnBz3//BMmR+c55G2vvLPKl573G6tevbrGjRunCxcuONtSU1M1btw4Va9uvx8cAADzVA4P0/4Nk7Xzt/c068P+qlAu1OyQPO7ixUuKjd2rxo0jXdobNYpUTMxOk6LyPPK2V97InFs97x9//LEefPBBlS1bVnXq1JEkbdmyRQ6HQ99//32OBggAwPVsiNmrpwZP0Z79JxRaophe7N9eyxeMVb2WLygh6W+zw/OYxMRkpaWlKyQk0KW9ePFAnT6dZEpM3kDegS7teT1vZM6t4v2uu+7SgQMH9MUXX+jPP/+UYRj697//rccee0yFCxe+6fapqalKTU11abuYekl+/vndCQcAYFPLVmxx/j921xGt37RHsb9OUrdOTfX+p0tMjMw7rp397cqMcCYF40XkfYVd8s4KO12w6vZNmgoVKqQ+ffq4tW10dLTGjh3r0tZveBc99+Jj7oYDAIDOp6QqdtcRVQoPMzsUjwoKKipfXx/Fxye6tJ85c1bFiweaE5QXkLe98kbmsly8f/vtt1l+0YceeuiGz48YMUJDhgxxaTuQ8nOWXx8AgMz4+eVTtcqltPr3P80OxaP8/PKrZs3KWr06Rq1aNXC2r1nzh+65p76JkXkWedsr7+zwcRhmh+A1WS7e27Vrl6X1HA7HTW/S5O/vL39/f5c2v3TvDplJOZ+qE0fjnY/jjido/+5jCihaSCXCgrwaizeR9xXkTd55kR3zjh7ZVYt/2qwjx+MVGlJUwwe0V0CRgpo9f5XZoXlcz57tNGzYRNWqVUWRkdU0b95SnThxWo8+2sbs0DyKvO2VNzJyGIaRK35V2Znk3Qtdt23aq1f6TcnQ3uL+KA0c1cWrsXgTebsi77yJvF15O+87ImZ7bV+zPuyvxvWrKyQoQPEJyfp98x6NnfC1/txzzGsxXJVyeOzNV8phV2/aExeXoKpVy2vEiKd05521vB6Ht5G3mXlX9fL+sua92GWm7XtgzXu9uj+3i/eff/5ZP//8s+Li4pSenv6/F3Q4NH369Gy/nreLdwCAZ3izeM9NzCjeAe/LncX7BzvMK9771/Bu8e7WBatjx47Vq6++qqioKJUsWTLD1c8AAAAAcp7b87zPnDlTjz/+eE7HAwAAAGSLr9kBeJFbd1i9ePGiGjZsmNOxAAAAALgBt4r3p556Sl9++WVOxwIAAABkm4/DvMXb3Bo2c+HCBU2dOlU//fSTIiIilD+/6zSPEydOzJHgAAAAAPyPW8X71q1bVbduXUnS9u3bXZ7j4lUAAADAM9wq3pcvX57TcQAAAABusdMdVt0a8w4AAADA+9zqeQcAAAByC18bjdqm5x0AAACwCIp3AAAAwCIYNgMAAABLM2O+dbPQ8w4AAABYBD3vAAAAsDR63gEAAADkOvS8AwAAwNLoeQcAAACQ61C8AwAAABbBsBkAAABYmq/DMDsEr6HnHQAAALAIet4BAABgaXbqjbZTrgAAAIClUbwDAAAAFsGwGQAAAFga87wDAAAAyHXoeTdZ9cCqZocAADkq5fBYs0MwRcFyo80OwRR2Pd7IXeh5BwAAAJDr0PMOAAAAS+MmTQAAAAByHYp3AAAAwCIYNgMAAABL44JVAAAAALkOPe8AAACwNHreAQAAAOQ6FO8AAACARTBsBgAAAJbGsBkAAAAAuQ497wAAALA0X3reAQAAAOQ29LwDAADA0nwchtkheA097wAAAIBFULwDAAAAFsGwGQAAAFianXqj7ZQrAAAAYGn0vAMAAMDSuEkTAAAAgFyH4h0AAACwCIbNAAAAwNK4wyoAAACAXCfLPe9bt27N8otGRES4FQwAAACQXXa6w2qWi/e6devK4XDIMAw5HDf+20RaWtotB+ZpsTH7tPCLFdr351ElxifrxfE9dHez2maH5RWzZy/W9OkLdPp0oqpUKaeXXuqtqKiaZoflceRN3uSdd9kt75GDO+rlwZ1c2k7GJSk8qq9JEXmX3Y73VXbNG66yPGzmwIED2r9/vw4cOKBvvvlG4eHhmjx5smJiYhQTE6PJkyerUqVK+uabbzwZb465kHJR4VVKqc/Q9maH4lVLlvyq6OhP1bfvI1q06D3Vq1dTvXuP0fHjcWaH5lHkTd7knXfZNe/YXUdUod4zzuXOe4eZHZJX2PV42zXvrPJxmLd4Pdesrli+fHnn8sYbb+j999/X008/rYiICEVEROjpp5/WpEmT9Nprr3ky3hxTr2F1dX2mjRq0sNcQnxkzFqljx1bq3Lm1KlUqq5EjeyssrLjmzPnB7NA8irzJm7zzLrvmfflymk6dPutc4hP+Mjskr7Dr8bZr3sjIrQtWt23bpvDw8Azt4eHh2rFjxy0HBc+4ePGSYmP3qnHjSJf2Ro0iFROz06SoPI+8yVsi77zKrnlLUuXwMO3fMFk7f3tPsz7srwrlQs0OyePserztmjcy51bxXr16dY0bN04XLlxwtqWmpmrcuHGqXr16jgWHnJWYmKy0tHSFhAS6tBcvHqjTp5NMickbyDvQpZ288ybyDnRpz+t5b4jZq6cGT9GD3aLV78Vpuq1EoJYvGKvgwCJmh+ZRdj3eds07O+w0bMated4//vhjPfjggypbtqzq1KkjSdqyZYscDoe+//77m26fmpqq1NRUl7aLqZfk55/fnXCQTddecHzlImSTgvEi8r6CvPM28r4ir+e9bMUW5/9jdx3R+k17FPvrJHXr1FTvf7rExMi8w27H+yq75g1XbvW833XXXTpw4IBef/11RUREqHbt2nrjjTd04MAB3XXXXTfdPjo6WsWKFXNZpr77tTuhIBuCgorK19dH8fGJLu1nzpxV8eKB5gTlBeRN3hJ551V2zfta51NSFbvriCqFh5kdikfZ9XjbNe/s8DFx8Ta391moUCH16dNHEydO1LvvvqvevXurcOHCWdp2xIgROnv2rMvSZ3Bnd0NBFvn55VfNmpW1enWMS/uaNX8oMjLvDncib/KWyDuvsmve1/Lzy6dqlUvpZFyS2aF4lF2Pt13zRubcGjYjSbt379aKFSsUFxen9PR0l+dGjRp1w239/f3l7+/v0uaX7t0hMynnU3XiaLzzcdzxBO3ffUwBRQupRFiQV2Pxpp4922nYsImqVauKIiOrad68pTpx4rQefbSN2aF5FHmTN3nnXXbMO3pkVy3+abOOHI9XaEhRDR/QXgFFCmr2/FVmh+Zxdjzekn3zRkZuFe/Tpk1T3759Vbx4cYWFhbmMwXI4HDct3nODvTuP6JV+U5yP/zPpW0lSi/ujNHBUF7PC8ri2bZsoMTFZkyfPVVxcgqpWLa+pU0erdOm8PUsBeZM3eedddsy7dMlgzfqwv0KCAhSfkKzfN+9Rs3ajdPhY/M03tjg7Hm/JvnlnlZ3G/jsMw8j2/WTLly+vfv36afjw4TkWyM6km1/omhdVD6xqdggAgBxQsNxos0MwRcrhsWaHAK/KnXXL76cXm7bvu0rc79X9udXznpiYqM6dGaMOAAAA89mo4929C1Y7d+6sZcuW5XQsAAAAAG7ArZ73ypUr65VXXtG6detUu3Zt5c/verHpgAEDciQ4AAAA4GbsNObdreJ96tSpKlKkiFauXKmVK1e6POdwOCjeAQAAAA9wq3g/cOBATscBAAAA4CayXLwPGTJEr732mgoXLqwhQ4Zcdz2Hw6EJEybkSHAAAADAzZhxp1OzZLl4j4mJ0aVLl5z/vx6HnQYdAQAAAF6U5eJ9+fLlmf4fAAAAMJPDke3bFlmWnf7KAAAAAFgaxTsAAABgEW7NNgMAAADkFna64pKedwAAAMAi6HkHAACApdlpskN63gEAAACLoHgHAAAALIJhMwAAALA0G42aoecdAAAAsAp63gEAAGBpPjbqeqfnHQAAALAIet4BAABgaTbqeKfnHQAAALAKincAAADAIijeAQAAYGkOh3lLdq1atUoPPvigSpUqJYfDoUWLFmVre4p3AAAAwEvOnTunOnXq6MMPP3Rrey5YBQAAgKVZ6YLVNm3aqE2bNm5vT/EOAAAAuCk1NVWpqakubf7+/vL39/fI/nJN8V49sKrZIQAA4LaUw2PNDsEUBcuNNjsEU9j1eCOj6OhojR3r+nkYPXq0xowZ45H95ZriHQAAAHCHmcNmRowYoSFDhri0earXXaJ4BwAAANzmySEymaF4BwAAgKX5WOmK1VtE8Q4AAAB4yd9//629e/c6Hx84cEB//PGHgoODVa5cuZtuT/EOAAAAS7NSx/vGjRvVokUL5+Or4+WfeOIJzZw586bbU7wDAAAAXtK8eXMZhuH29txhFQAAALAIet4BAABgaQ6H+z3ZVkPPOwAAAGAR9LwDAADA0qx0weqtoucdAAAAsAiKdwAAAMAiGDYDAAAAS3PYaNwMPe8AAACARdDzDgAAAEuzU2+0nXIFAAAALI2edwAAAFgaY94BAAAA5DoU7wAAAIBFMGwGAAAAlmajUTP0vAMAAABWQc87AAAALI0LVgEAAADkOhTvAAAAgEW4NWxm9+7dWrFiheLi4pSenu7y3KhRo3IkMG+YPXuxpk9foNOnE1WlSjm99FJvRUXVNDssjyNv8ibvvIu8yTsv5z1ycEe9PLiTS9vJuCSFR/U1KSLvstvxzg4bjZrJfs/7tGnTVKNGDY0aNUrz58/XwoULncuiRYs8EKJnLFnyq6KjP1Xfvo9o0aL3VK9eTfXuPUbHj8eZHZpHkTd5k3feRd7kbYe8Y3cdUYV6zziXO+8dZnZIXmHX442Msl28jxs3Tq+//rpOnjypP/74QzExMc5l8+bNnojRI2bMWKSOHVupc+fWqlSprEaO7K2wsOKaM+cHs0PzKPImb/LOu8ibvO2Q9+XLaTp1+qxziU/4y+yQvMKuxzurfBzmLV7PNbsbJCYmqnPnzp6IxWsuXryk2Ni9atw40qW9UaNIxcTsNCkqzyNv8pbIO68ib/KW8n7eklQ5PEz7N0zWzt/e06wP+6tCuVCzQ/I4Ox9vZJTt4r1z585atmyZJ2LxmsTEZKWlpSskJNClvXjxQJ0+nWRKTN5A3oEu7eSdN5F3oEs7eedNds17Q8xePTV4ih7sFq1+L07TbSUCtXzBWAUHFjE7NI+y6/HODoeJi7dl+4LVypUr65VXXtG6detUu3Zt5c+f3+X5AQMG3PQ1UlNTlZqa6tLm739R/v5+2Q3nljiumRTUMAxbzBNK3leQd95G3leQd95mt7yXrdji/H/sriNav2mPYn+dpG6dmur9T5eYGJl32O14I3PZLt6nTp2qIkWKaOXKlVq5cqXLcw6HI0vFe3R0tMaOHevSNnr0cxozpn92w3FLUFBR+fr6KD4+0aX9zJmzKl480CsxmIG8yVsi77yKvMlbyvt5X+t8Sqpidx1RpfAws0PxKI43/inbw2YOHDhw3WX//v1Zeo0RI0bo7NmzLsuIEU9nO3h3+fnlV82albV6dYxL+5o1fygysrrX4vA28iZvibzzKvImbynv530tP798qla5lE7GJZkdikdxvG/O4TBMW7zNrXneb5W/v7/8/f2vafXukJmePdtp2LCJqlWriiIjq2nevKU6ceK0Hn20jVfj8DbyJm/yzrvIm7zzet7RI7tq8U+bdeR4vEJDimr4gPYKKFJQs+evMjs0j7Pj8UbmslS8DxkyRK+99poKFy6sIUOG3HDdiRMn5khgnta2bRMlJiZr8uS5iotLUNWq5TV16miVLp23r1onb/Im77yLvMk7r+ddumSwZn3YXyFBAYpPSNbvm/eoWbtROnws3uzQPM6Oxzs77DT032EYxk37+4ODg7V7924VL15cLVq0uP6LORz65Zdf3Axlt5vbAQAAsxQsN9rsEEyRcnjszVfKk6qaHUCmTqV8a9q+byv4kFf3l6We96SkJKWnp0uSDh06pA0bNigkJMSjgQEAAABwlaULVoOCgnTgwAFJ0sGDB52FPAAAAGA2h8O8xduy1PPesWNHNWvWTCVLlpTD4VBUVJR8fX0zXTerM84AAAAAyJ4sFe9Tp05Vhw4dtHfvXg0YMEC9e/dWQECAp2MDAAAAbspOF6xmearI++67T5K0adMmDRw4kOIdAAAA8LJsz/M+Y8YMT8QBAAAAuCXbdx21MDvlCgAAAFgaxTsAAABgEdkeNgMAAADkJmZM2WgWet4BAAAAi6DnHQAAABZnn653et4BAAAAi6B4BwAAACyCYTMAAACwNAfDZgAAAADkNvS8AwAAwNIcDvv0R9snUwAAAMDi6HkHAACAxTHmHQAAAEAuQ/EOAAAAWATDZgAAAGBpTBUJAAAAINeh5x0AAAAWR887AAAAgFyG4h0AAACwCIbNAAAAwNLsdIdVinfAi3Ym7TY7BFNUD6xqdggAPCTl8FizQzBFwXKjzQ7BFCmH55gdgu1RvAMAAMDiuGAVAAAAQC5D8Q4AAABYBMNmAAAAYGncYRUAAABArkPPOwAAACyNnncAAAAAuQ497wAAALA4+/RH2ydTAAAAwOIo3gEAAACLYNgMAAAALM3h4IJVAAAAALkMPe8AAACwOHreAQAAAOQyFO8AAACARTBsBgAAAJbGHVYBAAAA5Dr0vAMAAMDi7NMfbZ9MAQAAAIuj5x0AAACWxph3AAAAALmOWz3v4eHhN7wN7f79+90OCAAAAEDm3CreBw0a5PL40qVLiomJ0dKlS/XCCy/kRFwAAABAltyoUzmvcat4HzhwYKbtH330kTZu3HhLAQEAAADIXI6OeW/Tpo2++eabnHxJj5o9e7H+9a9eql27gzp0GKSNG2PNDskryNs+ecfG7NO456er5/1j1a7+81q3cpvZIXmNHY+3RN7kTd550cjBHZVyeI7LcmDjFLPDymUcJi7elaPF+/z58xUcHJyTL+kxS5b8qujoT9W37yNatOg91atXU717j9Hx43Fmh+ZR5G2vvC+kXFR4lVLqM7S92aF4lV2PN3mTN3nnXbG7jqhCvWecy533DjM7JJjEreI9MjJSd9xxh3OJjIxUyZIl9dJLL+mll17K6Rg9YsaMRerYsZU6d26tSpXKauTI3goLK645c34wOzSPIm975V2vYXV1faaNGrSIMDsUr7Lr8SZv8ibvvOvy5TSdOn3WucQn/GV2SDCJW2Pe27Vr5/LYx8dHJUqUUPPmzVWtWrWciMujLl68pNjYverTp5NLe6NGkYqJ2WlSVJ5H3vbK267serzJm7wl8s7LKoeHaf+GyUpNvaQNf+zVqPHzdPBw3v5rQ3Y4bDT7uVvF++jRo29pp6mpqUpNTXVp8/e/KH9/v1t63axKTExWWlq6QkICXdqLFw/U6dNJXonBDOQd6NKe1/O2K7seb/IOdGkn77zJrnlviNmrpwZP0Z79JxRaophe7N9eyxeMVb2WLygh6W+zw4OX3fKvKSkpKUpOTnZZbiY6OlrFihVzWaKjP7nVULLt2mmFDMOQHWYaIu8r7JK3Xdn1eJP3FeSdt9kt72UrtmjRD78rdtcRLf9tu9r3GC9J6tapqcmR5Sb2uWDVrZ73c+fOafjw4frqq6905syZDM+npaXdcPsRI0ZoyJAhLm3+/ofdCcUtQUFF5evro/j4RJf2M2fOqnjxQK/F4W3kba+87cqux5u8yVsib7s4n5Kq2F1HVCk8zOxQYAK3et6HDRumX375RZMnT5a/v78+/fRTjR07VqVKldKsWbNuur2/v7+KFi3qsnhryIwk+fnlV82albV6dYxL+5o1fygysrrX4vA28rZX3nZl1+NN3uQtkbdd+PnlU7XKpXQyLsnsUHINh8Nh2uJtbvW8f/fdd5o1a5aaN2+uJ598Uk2aNFHlypVVvnx5zZ49W127ds3pOHNcz57tNGzYRNWqVUWRkdU0b95SnThxWo8+2sbs0DyKvO2Vd8r5VJ04Gu98HHc8Qft3H1NA0UIqERZkYmSeZdfjTd7kTd55U/TIrlr802YdOR6v0JCiGj6gvQKKFNTs+avMDg0mcKt4T0hIUHh4uCSpaNGiSkhIkCQ1btxYffv2zbnoPKht2yZKTEzW5MlzFReXoKpVy2vq1NEqXTrU7NA8irztlffenUf0Sr//3cjjP5O+lSS1uD9KA0d1MSssj7Pr8SZv8ibvvKl0yWDN+rC/QoICFJ+QrN8371GzdqN0+Fj8zTdGnuMwDMPI7kYRERH64IMP1KxZM917772KiIjQO++8o/fff1/jx4/X0aNH3QhltxvbANayM8men/PqgVXNDgEAclTBcrc2855VpRyeY3YImbqYvsm0ffv51PPq/twa896zZ09t2bJF0pWLT6+OfR88eLBeeOGFHA0QAAAAwBVuDZsZPHiw8/8tWrTQn3/+qY0bN6pSpUqqU6dOjgUHAAAA3Aw3acqCn3/+WT///LPi4uKUnp7u8tx//vOfWw4MAAAAgCu3ivexY8fq1VdfVVRUlEqWLGnKNDkAAACA3bhVvH/88ceaOXOmHn/88ZyOBwAAAMgm+3QkuzVA6OLFi2rYsGFOxwIAAADgBtwq3p966il9+eWXOR0LAAAAkG0OE/95W5aHzQwZMsT5//T0dE2dOlU//fSTIiIilD9/fpd1J06cmHMRAgAAAJCUjeI9JibG5XHdunUlSdu3b3dp5+JVAAAAeJOd6s8sF+/Lly/3ZBwAAAAAbsI+M9oDAAAAFuf2TZoAAACA3ME+/dH2yRQAAACwOHreAQAAYGlmTNloFnreAQAAAIugeAcAAAAsgmEzAAAAsDiGzQAAAADIZeh5BwAAgKXZ6Q6r9LwDAAAAFkHPOwAAACzOPv3R9skUAAAAyAUmT56s8PBwFShQQPXq1dOvv/6a5W0p3gEAAAAvmTdvngYNGqSRI0cqJiZGTZo0UZs2bXT48OEsbU/xDgAAAEtzmPgvuyZOnKhevXrpqaeeUvXq1TVp0iSVLVtWU6ZMydL2FO8AAACAm1JTU5WcnOyypKamZrruxYsXtWnTJt17770u7ffee6/WrFmTtR0aNnfhwgVj9OjRxoULF8wOxavIm7ztgLzJ2w7Im7xhrtGjRxuSXJbRo0dnuu6xY8cMScbq1atd2l9//XWjatWqWdqfwzAM4xZ+2bC85ORkFStWTGfPnlXRokXNDsdryJu87YC8ydsOyJu8Ya7U1NQMPe3+/v7y9/fPsO7x48dVunRprVmzRg0aNHC2v/766/r888/1559/3nR/TBUJAAAAuOl6hXpmihcvLl9fX508edKlPS4uTrfddluWXoMx7wAAAIAX+Pn5qV69evrxxx9d2n/88Uc1bNgwS69BzzsAAADgJUOGDNHjjz+uqKgoNWjQQFOnTtXhw4f1zDPPZGl72xfv/v7+Gj16dJb/3JFXkDd52wF5k7cdkDd5w1r+/e9/68yZM3r11Vd14sQJ1apVS0uWLFH58uWztL3tL1gFAAAArIIx7wAAAIBFULwDAAAAFkHxDgAAAFiELYr35s2ba9CgQWaH4VWGYahPnz4KDg6Ww+HQH3/8YXZIAHKYHb/brsfhcGjRokXXff7gwYOW/C681WNs1byvuvZnWWBgYJ78zHMuIztsMdvMggULlD9/fklShQoVNGjQoDx/kixdulQzZ87UihUrVLFiRRUvXtzskAAA2fTPn192dO3PMh8fHxUsWNDssABT2aJ4Dw4ONjsEr9u3b59Klix53Qn/L168KD8/Py9HhdwuLS1NDodDPj62+KMckOvZ8efXP93sZxlgR7b4CX31z1HNmzfXoUOHNHjwYDkcDjkcDknSmTNn1KVLF5UpU0aFChVS7dq1NWfOHJOjdl+PHj3Uv39/HT58WA6HQxUqVFDz5s313HPPaciQISpevLhatWolSZo4caJq166twoULq2zZsurXr5/+/vtvkzPIvvnz56t27doqWLCgQkJC1LJlS507d049evRQu3btNHbsWIWGhqpo0aJ6+umndfHiRee2S5cuVePGjRUYGKiQkBA98MAD2rdvn4nZZN3V4/rcc88543/55Zd1dQbYxMREde/eXUFBQSpUqJDatGmjPXv2OLefOXOmAgMD9f3336tGjRry9/fXoUOHzEonSwzD0Pjx41WxYkUVLFhQderU0fz58yVJK1askMPh0M8//6yoqCgVKlRIDRs21K5du1xeY9y4cQoNDVVAQICeeuopvfjii6pbt64J2WTduXPn1L17dxUpUkQlS5bUhAkTXJ6/ePGihg0bptKlS6tw4cKqX7++VqxY4Xx+zJgxGXKcNGmSKlSo4Pngc0Dz5s01YMAADRs2TMHBwQoLC9OYMWOuu/7vv/+uyMhIFShQQFFRUYqJifFesDnon8MpKlSooDfeeENPPvmkAgICVK5cOU2dOtVl/bySt3T9n2X//Mt5Vt4Tq0hPT7/u5/tmP6utfn4je2xRvF+1YMEClSlTxjkp/okTJyRJFy5cUL169fT9999r+/bt6tOnjx5//HGtX7/e5Ijd89577+nVV19VmTJldOLECW3YsEGS9NlnnylfvnxavXq1PvnkE0mSj4+P3n//fW3fvl2fffaZfvnlFw0bNszM8LPtxIkT6tKli5588knt3LlTK1asUIcOHZwF7M8//6ydO3dq+fLlmjNnjhYuXKixY8c6tz937pyGDBmiDRs26Oeff5aPj4/at2+v9PR0s1LKlqvHdf369Xr//ff17rvv6tNPP5V05Yffxo0b9e2332rt2rUyDENt27bVpUuXnNufP39e0dHR+vTTTxUbG6vQ0FCzUsmSl19+WTNmzNCUKVMUGxurwYMHq1u3blq5cqVznZEjR2rChAnauHGj8uXLpyeffNL53OzZs/X666/rrbfe0qZNm1SuXDlNmTLFjFSy5YUXXtDy5cu1cOFCLVu2TCtWrNCmTZucz/fs2VOrV6/W3LlztXXrVnXu3Fn33Xefyy9rVvfZZ5+pcOHCWr9+vcaPH69XX301wy3GpSvn9AMPPKDbb79dmzZt0pgxYzR06FATIs55EyZMcBbl/fr1U9++ffXnn39Kynt5X+9n2bVu9J5YyY0+33nhZzVykGEDzZo1MwYOHGgYhmGUL1/eePfdd2+6Tdu2bY3nn3/es4F50LvvvmuUL1/e+bhZs2ZG3bp1b7rdV199ZYSEhHgwspy3adMmQ5Jx8ODBDM898cQTRnBwsHHu3Dln25QpU4wiRYoYaWlpmb5eXFycIcnYtm2bx2LOKc2aNTOqV69upKenO9uGDx9uVK9e3di9e7chyVi9erXzufj4eKNgwYLGV199ZRiGYcyYMcOQZPzxxx9ej90df//9t1GgQAFjzZo1Lu29evUyunTpYixfvtyQZPz000/O5xYvXmxIMlJSUgzDMIz69esbzz77rMv2jRo1MurUqePx+N31119/GX5+fsbcuXOdbWfOnDEKFixoDBw40Ni7d6/hcDiMY8eOuWx3zz33GCNGjDAMwzBGjx6dIcdrvydys2bNmhmNGzd2abvzzjuN4cOHG4ZhGJKMhQsXGoZhGJ988kmm570kIyYmxlsh54hrf35169bN+Vx6eroRGhpqTJkyxTCMvJX3VZn9LLv6fhjGzd8Tq7jZ5/ta1/6stvr5jeyxVc/79aSlpen1119XRESEQkJCVKRIES1btkyHDx82O7QcFRUVlaFt+fLlatWqlUqXLq2AgAB1795dZ86c0blz50yI0D116tTRPffco9q1a6tz586aNm2aEhMTXZ4vVKiQ83GDBg30999/68iRI5KujKl87LHHVLFiRRUtWlTh4eGSZJnjf/fddzuHgElX8tuzZ4927NihfPnyqX79+s7nQkJCdPvtt2vnzp3ONj8/P0VERHg1Znft2LFDFy5cUKtWrVSkSBHnMmvWLJehTv/Mp2TJkpKkuLg4SdKuXbt01113ubzutY9zm3379unixYtq0KCBsy04OFi33367JGnz5s0yDENVq1Z1eV9WrlxpmSFgWXHt57RkyZLO4/pPO3fuzPS8zwv++R44HA6FhYU534O8nPeN3Og9sZIbfb7zws9q5BxbXLB6MxMmTNC7776rSZMmOceUDRo0yGVcdF5QuHBhl8eHDh1S27Zt9cwzz+i1115TcHCwfvvtN/Xq1ctlWEVu5+vrqx9//FFr1qzRsmXL9MEHH2jkyJE3HfZ0teB98MEHVbZsWU2bNk2lSpVSenq6atWqleeO/1WGYbgU+wULFnR5nJtdHcq0ePFilS5d2uU5f39/Z6H6z9k5rub2z2FQ1+Zr/P8hVrnVzeJLT0+Xr6+vNm3aJF9fX5fnihQpIunKn92vfR0rneeSMsy64nA4Mh3eltuP56240XuQl/O+kax+LnK76+WRlZ/VeeH8RtbZrufdz89PaWlpLm2//vqrHn74YXXr1k116tRRxYoV89Q40evZuHGjLl++rAkTJujuu+9W1apVdfz4cbPDcovD4VCjRo00duxYxcTEyM/PTwsXLpQkbdmyRSkpKc51161bpyJFiqhMmTI6c+aMdu7cqZdffln33HOPqlev7tJrbwXr1q3L8LhKlSqqUaOGLl++7PJLzJkzZ7R7925Vr17d22HmiKsX1R4+fFiVK1d2WcqWLZul17j99tv1+++/u7Rt3LjRE+HmmMqVKyt//vwuxzoxMVG7d++WJEVGRiotLU1xcXEZ3pewsDBJUokSJXTy5EmXH/BWnfv7ZmrUqJHpeZ/X2TXvvC4rP6vtdH7DhsV7hQoVtGrVKh07dkzx8fGSrvxgvNpzu3PnTj399NM6efKkyZF6XqVKlXT58mV98MEH2r9/vz7//HN9/PHHZoeVbevXr9cbb7yhjRs36vDhw1qwYIFOnz7tLFAvXryoXr16aceOHfrhhx80evRoPffcc/Lx8VFQUJBCQkI0depU7d27V7/88ouGDBlickbZc+TIEQ0ZMkS7du3SnDlz9MEHH2jgwIGqUqWKHn74YfXu3Vu//fabtmzZom7duql06dJ6+OGHzQ7bLQEBARo6dKgGDx6szz77TPv27VNMTIw++ugjffbZZ1l6jf79+2v69On67LPPtGfPHo0bN05bt27N1X99KFKkiHr16qUXXnhBP//8s7Zv364ePXo4p/SsWrWqunbtqu7du2vBggU6cOCANmzYoLfeektLliyRdGXWktOnT2v8+PHat2+fPvroI/3www9mpuUxjz32mHx8fJzn/ZIlS/TOO++YHZbH2TXvvC4rP6vtdH7DhsX7q6++qoMHD6pSpUoqUaKEJOmVV17RHXfcodatW6t58+YKCwtTu3btzA3UC+rWrauJEyfqrbfeUq1atTR79mxFR0ebHVa2FS1aVKtWrVLbtm1VtWpVvfzyy5owYYLatGkjSbrnnntUpUoVNW3aVI888ogefPBB5xRcPj4+mjt3rjZt2qRatWpp8ODBevvtt03MJvu6d++ulJQU3XXXXXr22WfVv39/9enTR5I0Y8YM1atXTw888IAaNGggwzC0ZMkSS9/05bXXXtOoUaMUHR2t6tWrq3Xr1vruu++c1yrcTNeuXTVixAgNHTpUd9xxhw4cOKAePXqoQIECHo781rz99ttq2rSpHnroIbVs2VKNGzdWvXr1nM/PmDFD3bt31/PPP6/bb79dDz30kNavX+/8i0T16tU1efJkffTRR6pTp45+//13S89EciNFihTRd999px07digyMlIjR47UW2+9ZXZYHmfXvPO6rPysttP5Dclh2HWQHGyhR48eSkpKuuFt062sefPmqlu3riZNmmR2KJbWqlUrhYWF6fPPPzc7FAAAbogLVgHYyvnz5/Xxxx+rdevW8vX11Zw5c/TTTz9lOl84AAC5DcU7AFtxOBxasmSJxo0bp9TUVN1+++365ptv1LJlS7NDAwDgphg2AwAAAFiE7S5YBQAAAKyK4h0AAACwCIp3AAAAwCIo3gEAAACLoHgHAAAALILiHQAAALAIincAAADAIijeAQAAAIugeAcAAAAs4v8BM0IPiPUF0XsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(overlap_df, annot=True, cmap=\"YlGnBu\", fmt=\"d\")\n",
    "plt.title(\"Overlap of Top 5 Words Between Languages\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c184c98",
   "metadata": {},
   "source": [
    "In the heat-map we find without any surprise that between each language and itself a 5. Next French and Spanish meet with 3 words and then Portugese and Spanish.\n",
    "\n",
    "When focusing on English and Finnish, we see more. Finnish has absolutly no correlation in its top 5 words with any other language while English still has some, 1 word each, with some other languages. This explains why Finnish has such a high accuracy but why not higher than English?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b05563e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italian:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count in Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>di</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>il</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>la</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>del</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  Count in Dataset\n",
       "0   di               787\n",
       "1   il               646\n",
       "2   la               657\n",
       "3   in               563\n",
       "4  del               501"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count in Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>la</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>le</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>et</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  Count in Dataset\n",
       "0   de               939\n",
       "1   la               780\n",
       "2   le               732\n",
       "3   en               665\n",
       "4   et               717"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count in Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>la</td>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>el</td>\n",
       "      <td>783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>que</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  Count in Dataset\n",
       "0   de               940\n",
       "1   la               850\n",
       "2   en               801\n",
       "3   el               783\n",
       "4  que               533"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portuguese:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count in Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>em</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>do</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>que</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>da</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  Count in Dataset\n",
       "0   de               877\n",
       "1   em               632\n",
       "2   do               561\n",
       "3  que               495\n",
       "4   da               566"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count in Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  Count in Dataset\n",
       "0  the               939\n",
       "1   of               793\n",
       "2   in               808\n",
       "3  and               818\n",
       "4   to               584"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count in Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>der</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>die</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>und</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>von</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  Count in Dataset\n",
       "0  der               790\n",
       "1  die               686\n",
       "2  und               713\n",
       "3   in               622\n",
       "4  von               480"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dutch:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count in Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>van</td>\n",
       "      <td>813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>het</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>een</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  Count in Dataset\n",
       "0   de               922\n",
       "1  van               813\n",
       "2   in               793\n",
       "3  het               732\n",
       "4  een               730"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indonesian:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count in Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yang</td>\n",
       "      <td>724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dan</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>di</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pada</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dari</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word  Count in Dataset\n",
       "0  yang               724\n",
       "1   dan               750\n",
       "2    di               564\n",
       "3  pada               490\n",
       "4  dari               503"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finnish:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count in Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ja</td>\n",
       "      <td>782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>on</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oli</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>han</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vuonna</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Word  Count in Dataset\n",
       "0      ja               782\n",
       "1      on               484\n",
       "2     oli               296\n",
       "3     han               212\n",
       "4  vuonna               235"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hausa:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count in Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>da</td>\n",
       "      <td>877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ta</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ya</td>\n",
       "      <td>518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>na</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ne</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  Count in Dataset\n",
       "0   da               877\n",
       "1   ta               591\n",
       "2   ya               518\n",
       "3   na               587\n",
       "4   ne               595"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyzer = vectorizer.build_analyzer()\n",
    "\n",
    "def count_top_words_in_lang_samples(X, y, top_words_count):\n",
    "    results = []\n",
    "    for i, lang in enumerate(lang_codes):\n",
    "        lang_samples = X[y == lang]\n",
    "        word_counts = []\n",
    "\n",
    "        for word in top_words_list[i]:\n",
    "            count = sum(word in analyzer(text) for text in lang_samples)\n",
    "            word_counts.append(count)\n",
    "\n",
    "        results.append(word_counts)\n",
    "    return results\n",
    "\n",
    "def MNB_words_table(top_words, top_words_count):\n",
    "    for i, lang in enumerate(langs):\n",
    "        print(lang + \":\")\n",
    "        df = pd.DataFrame({\n",
    "            \"Word\": top_words[i],\n",
    "            \"Count in Dataset\": top_words_count[i]\n",
    "        })\n",
    "        display(df)\n",
    "\n",
    "top_words = top_words_per_lang(model, vectorizer, 5)\n",
    "top_counts = count_top_words_in_lang_samples(X, y, top_words)\n",
    "\n",
    "MNB_words_table(top_words, top_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e160212f",
   "metadata": {},
   "source": [
    "Here we see something that would explain things more a bit. We notice that English has a high count overall of the top 5 words in the samples we have. Perhaps not the highest, but the higher ones are found in more than one language, like 'de'. While 'the' is slightly less in count but is only found in English.\n",
    "\n",
    "This gives a very good idea on why English has the highest accuracy, not only does it have a relatively high count of indicative words by the MNB, but also these words are special and are not found in other languages.\n",
    "\n",
    "Furhtermore, while Finnish as we saw in the heatmap has no correlation with any other language in our dataset, its top 5 indicative words by the MNB are way less than English, which explains why it performs worse than English even though English has correlation in indicative words with other languages.\n",
    "\n",
    "Finally, we see that while not the lowest, Portuguese is on the lower end in terms of the frequency of those special words. Combined with the fact that its words correlate with multiple other languages like Spanish and Dutch explains why it has such a low accuracy.\n",
    "\n",
    "Dutch's top 5 words meets all other languages in the heat-map except for 3. But with a high frequency of those words in the text samples it still performs relatively well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dae2f94",
   "metadata": {},
   "source": [
    "### K-Fold\n",
    "Since our accuracy is high, we will perform k-folds on the dataset using MNB to see how well our model generalizes on unseen data. We choose the optimal number of folds of 5 since it has a balance of testing the model but not being too heavy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f966d3e-57e4-4b15-9897-32ca8d142f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model_kfold = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=17)\n",
    "\n",
    "all_preds = []\n",
    "all_true = []\n",
    "\n",
    "X_train_kfold = X_train.copy()\n",
    "X_test_kfold = X_test.copy()\n",
    "y_train_kfold = y_train.copy()\n",
    "y_test_kfold = y_test.copy()\n",
    "\n",
    "k_folds_accuracies = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "    X_train_kfold, X_test_kfold = X[train_index], X[test_index]\n",
    "    y_train_kfold, y_test_kfold = y[train_index], y[test_index]\n",
    "\n",
    "    model_kfold.fit(X_train_kfold.flatten(), y_train_kfold.flatten())\n",
    "    y_pred_kfold = model_kfold.predict(X_test_kfold.flatten())\n",
    "\n",
    "    fold_accuracy = accuracy_score(y_test_kfold, y_pred_kfold)\n",
    "    k_folds_accuracies.append(fold_accuracy)\n",
    "\n",
    "    all_preds.extend(y_pred_kfold)\n",
    "    all_true.extend(y_test_kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c828e604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results (Accuracy):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kfold</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.9825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.9840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Kfold  Accuracy\n",
       "0      1    0.9825\n",
       "1      2    0.9830\n",
       "2      3    0.9825\n",
       "3      4    0.9860\n",
       "4      5    0.9840"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Kfolds Mean Accuracy: 98.36%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Accuracy of MNB/language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italian</td>\n",
       "      <td>0.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>French</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Portuguese</td>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>German</td>\n",
       "      <td>0.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dutch</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indonesian</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Finnish</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hausa</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Language  Accuracy of MNB/language\n",
       "0     Italian                     0.985\n",
       "1      French                     0.993\n",
       "2     Spanish                     0.980\n",
       "3  Portuguese                     0.949\n",
       "4     English                     0.998\n",
       "5      German                     0.982\n",
       "6       Dutch                     0.980\n",
       "7  Indonesian                     0.978\n",
       "8     Finnish                     0.996\n",
       "9       Hausa                     0.995"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_kfold_accuracy = pd.DataFrame({\n",
    "    'Kfold': [1, 2, 3, 4, 5],\n",
    "    'Accuracy': k_folds_accuracies\n",
    "})\n",
    "\n",
    "\n",
    "print(\"Cross-Validation Results (Accuracy):\")\n",
    "\n",
    "display(df_kfold_accuracy)\n",
    "\n",
    "print(f'\\nOverall Kfolds Mean Accuracy: {cross_val_score(model_kfold, X.flatten(), y.flatten(), cv=kf).mean() * 100:}%')\n",
    "\n",
    "def get_lang_accuracies(y_true, y_pred):\n",
    "    df = pd.DataFrame({'language': y_true, 'pred': y_pred})\n",
    "    accuracies = []\n",
    "\n",
    "    for lang in lang_codes:\n",
    "        lang_group = df[df['language'] == lang]\n",
    "        if len(lang_group) > 0:\n",
    "            acc = accuracy_score(lang_group['language'], lang_group['pred'])\n",
    "        else:\n",
    "            acc = 0\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    return accuracies\n",
    "\n",
    "df_lang_accuracy = pd.DataFrame({\n",
    "    'Language': langs,\n",
    "    'Accuracy of MNB/language': get_lang_accuracies(np.array(all_true), np.array(all_preds))\n",
    "})\n",
    "\n",
    "display(df_lang_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfe4309",
   "metadata": {},
   "source": [
    "We see from the results from the K-folds that the accuracy is still consistent which indicates to use that the model is quite robust. The accuracies are also consistent for the languages.\n",
    "\n",
    "Due to these results we will assume that the top 5 words indicative for MNB will be similar to what we found previously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7764fb5c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd0bbb3",
   "metadata": {},
   "source": [
    "### MNB Conclusions\n",
    "While we haven't anticipated this high of an accuracy for our MNB, intuitively it makes sense. There are certain words that are only found in certain languages and they appear quite often in most sentences, like articles in English. And while some other languages have correlation when it comes to the indicative words their count and combination with other unique words in the language makes it possible for the MNB to classify the language accuratly.\n",
    "\n",
    "Thus, MNB performs quite well when given decently sized texts from languages to train on, like paragraphs. This gives it the ability to record the most common words in that language and the unique words that exist in the language.\n",
    "\n",
    "When testing, if given a valid sentence, it will be able to accuratly classify it sense for example, a simple sentence in English no matter how short will contain articles, verbs, or adjectives.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f69be588",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_addtl = np.array([\n",
    "    # Italian\n",
    "    \"Bambini ridevano mentre guardavano fuochi sopra ponte vecchio.\",\n",
    "    \"Neve fresca copriva tetto rustico durante alba tranquilla.\",\n",
    "\n",
    "    # French\n",
    "    \"Clé cassée resta coincée sous meuble ancien.\",\n",
    "    \"Lumière faible éclairait couloir désert chaque nuit.\",\n",
    "\n",
    "    # Spanish\n",
    "    \"Guitarra sonaba cerca ventana rota durante fiesta secreta.\",\n",
    "    \"Sombras largas cruzaban pasillo viejo sin sonido alguno.\",\n",
    "\n",
    "    # Portuguese\n",
    "    \"Barco afundou devagar próximo cais silencioso.\",\n",
    "    \"Fumaça subia após explosão repentina dentro fábrica antiga.\",\n",
    "\n",
    "    # English\n",
    "    \"Impetus convive.\",\n",
    "    # \"afjlkasdf\",\n",
    "    \"Galvanized Acumen.\",\n",
    "\n",
    "    # German\n",
    "    \"Regen fiel schnell gegen Bäume kahlen draußen.\",\n",
    "    \"Kerze flackerte still auf Tisch zerkratzt alt.\",\n",
    "\n",
    "    # Dutch\n",
    "    \"Stilte hing rond toren verlaten zonder mensen.\",\n",
    "    \"Kleine boot dreef langzaam over meer breed.\",\n",
    "\n",
    "    # Indonesian\n",
    "    \"Topi merah jatuh ke lantai tanpa suara.\",\n",
    "    \"Malam gelap membawa angin kencang lewat bukit.\",\n",
    "\n",
    "    # Finnish\n",
    "    \"Hiljainen järvi heijasti kuun valoa yössä.\",\n",
    "    \"Vanha mies kulki polkua pitkin varhain aamulla.\",\n",
    "\n",
    "    # Hausa\n",
    "    \"Gashi nata ya bushe daga iska mai sanyi.\",\n",
    "    \"Kwalliya ta fadi kan kasa lokacin dare ya zo.\"\n",
    "])\n",
    "\n",
    "y_test_addtl = np.array(['ita', 'ita', 'fra', 'fra', 'spa', 'spa', 'por', 'por',\n",
    "                        'eng', 'eng', 'deu', 'deu', 'nld', 'nld', 'ind', 'ind',\n",
    "                        'fin', 'fin', 'hau', 'hau'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb4de1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy of MNB: 90.0%\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(strip_accents='unicode')\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)  # Fit only on training\n",
    "X_test_addtl_vect = vectorizer.transform(X_test_addtl)\n",
    "\n",
    "y_pred_addtl = model.predict(X_test_addtl_vect)\n",
    "accuracy_addtl = accuracy_score(y_test_addtl, y_pred_addtl)\n",
    "print(\"Overall accuracy of MNB: \" + str(accuracy_addtl * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f79c4e1-1e47-4eff-b6a2-27c7504733bd",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f77a657",
   "metadata": {},
   "source": [
    "We decided to do a Neural Network to give us some exposure into this rich topic. Feed Forward specifically are simpler to train and apply than other types of neural networks.\n",
    "\n",
    "In this model we basically have two shown layers, input and output, where the data goes in and out. In between, there can be multiple hidden layers that would help in the training. We have the freedom in choosing the amount of layers and the amount of neurons in each layer.\n",
    "\n",
    "This gives us simplicity but more abilities than MNB. In MNB where we feed it vectorized data, statistics about the words and their frequencies in each sample, it relies only on those statistics and disregards grammar and word positioning. When we feed the FFNN model the strings of text converted to Unicode and normalized, it enables the neural network to have data with vectors where each value doesn't only represent what character, but also where it occurs in the word using its position in the vector. An example of this would be the suffix \"tion\", which appears as the last 4 values in an array representing a word, thus allowing the neural network to learn that pattern.\n",
    "\n",
    "This should enable us to have a better model when it comes to generalizing on new data since it learns more patterns than just frequency and words, like positioning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f2e637",
   "metadata": {},
   "source": [
    "### Data Pre-processing\n",
    "FFNN (Feed Forward Neural Network) needs a numerical set of labels as opposed to MNB due to the need for the FFNN to use the class labels in its internal mathematical operations, like matrix multipications and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "81a93297-6dd5-4cb8-af86-0ff9a0616fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganizing data for Feed Forward Neural Network input\n",
    "\n",
    "# 1) convert string labels into integer labels\n",
    "#      and make func to convert back\n",
    "\n",
    "\n",
    "def str_labels_to_int_labels(labelArr, string_labels):\n",
    "    rtn = np.empty(labelArr.shape, dtype=int)\n",
    "    for i, v in enumerate(string_labels):\n",
    "        rtn[labelArr == v] = i\n",
    "    return rtn\n",
    "\n",
    "def int_labels_to_str_labels(labelArr, string_labels):\n",
    "    rtn = np.empty(labelArr.shape, dtype='object')\n",
    "    for i, v in enumerate(string_labels):\n",
    "        rtn[labelArr == i] = v\n",
    "    return rtn\n",
    "\n",
    "# print(y_test[0:5])\n",
    "# y1 = str_labels_to_int_labels(y_test, all_str_labels)\n",
    "# print(y1[0:5])\n",
    "# y2 = int_labels_to_str_labels(y1, all_str_labels)\n",
    "# print(y2[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5401c0",
   "metadata": {},
   "source": [
    "When it comes to pre-processing the text samples themselves we had multiple choices. We could use CountVectorizer like MNB, or turn the characters into unicode values, pad the vectors to be of equal length, then normalize them before feeding them to the model.\n",
    "\n",
    "The reason we chose the second method over CountVectorizer is because when using CountVectorizer all the positioning part of our dataset would removed and we would left with words in each language and their frequency, thus our neural network would act like the MNB using those statistics to predict the class. When doing our method of data processing however, we retain the the positioning aspect of the dataset on top of the vocabulary and frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1be68002-eb66-461c-94b4-7fa37cc9e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) convert data into multi-column matrix of characters\n",
    "#      and make func to convert back\n",
    "\n",
    "def str_vec_to_float_matrix(strVec, longest_str_len):\n",
    "    # Pad strings to all be equal length\n",
    "    padded_strVec = np.char.ljust(strVec, longest_str_len, fillchar=' ')\n",
    "\n",
    "    # turn vector of strings into matrix of characters\n",
    "    stacked_char_matrix = np.vstack([np.array(list(s)) for s in padded_strVec])\n",
    "\n",
    "    # turn char matrix into int matrix\n",
    "    char_matrix_to_int_matrix = np.vectorize(ord)\n",
    "    int_matrix = char_matrix_to_int_matrix(stacked_char_matrix)\n",
    "\n",
    "    #normalize and scale so each value is a float between 0 and 1\n",
    "    matrix_max = np.max(int_matrix)\n",
    "    matrix_min = np.min(int_matrix)\n",
    "    min_subtracted_matrix = int_matrix - matrix_min\n",
    "    normalized_matrix = (min_subtracted_matrix / (matrix_max - matrix_min))\n",
    "    return normalized_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "58228e9e-a643-4b73-a51a-ba3366793109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done converting data into FFNN format\n"
     ]
    }
   ],
   "source": [
    "# 3) use them both\n",
    "\n",
    "def convert_to_FFNN_format(Xr, Xe, yr, ye):\n",
    "    max_str_len_1 = np.max(np.char.str_len(Xr))\n",
    "    max_str_len_2 = np.max(np.char.str_len(Xe))\n",
    "    max_str_len = max(max_str_len_1, max_str_len_2)\n",
    "    Xr_rtn = str_vec_to_float_matrix(Xr, max_str_len)\n",
    "    Xe_rtn = str_vec_to_float_matrix(Xe, max_str_len)\n",
    "    return (Xr_rtn, \n",
    "            Xe_rtn,\n",
    "            str_labels_to_int_labels(yr, lang_codes), \n",
    "            str_labels_to_int_labels(ye, lang_codes))\n",
    "\n",
    "(X_tr_nn, X_te_nn, y_tr_nn, y_te_nn) = convert_to_FFNN_format(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"Done converting data into FFNN format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7301f111",
   "metadata": {},
   "source": [
    "Now that our labels are numerically encoded and our samples are changed into their unicode values and normalized we can feed them into the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c436646e-e772-42a2-9b08-ba6d866aaecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 5577)\n",
      "(3000, 5577)\n"
     ]
    }
   ],
   "source": [
    "# print(X_tr_nn[0])\n",
    "# print(X_tr_nn[1])\n",
    "print(X_tr_nn.shape)\n",
    "print(X_te_nn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27d528d",
   "metadata": {},
   "source": [
    "7000/3000 showing our data split for training and testing samples, with 5577 features representing the amount of character. 5577 was the max character count in our samples so the rest are padded with empty spaces to make them equal length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4bc41b",
   "metadata": {},
   "source": [
    "### Tensorflow Feed Forward Neural Network\n",
    "TensorFlow’s FFNN takes input data, passes it through hidden layers to learn patterns, and outputs class probabilities. You control its behavior with hyperparameters like number of layers, neurons, activations, and optimizers. All in one framework.\n",
    "\n",
    "We chose Tensorflow because of the many resources online that has explains how it works and provides tutorials on how to implement and use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07b30fd7-52e8-4fec-8803-69c7e421ef36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done importing Tensorflow Stuff\n"
     ]
    }
   ],
   "source": [
    "# Applying properly structured data to a basic FFNN\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.metrics import SparseCategoricalAccuracy\n",
    "\n",
    "print(\"Done importing Tensorflow Stuff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e13900",
   "metadata": {},
   "source": [
    "#### FFNN Layers\n",
    "We use sequential to create the layers of our neural network.\n",
    "\n",
    "It has the hyperparameters of:\n",
    "- Dense(unit): unit is the number of neurons in the level.\n",
    "- input_shape: the length of the input data, in our case 5577\n",
    "- Activation Function: 'Relu' a popular function for internal neurons to deep learn and 'softmax' for the output function to turn raw outputs into vector of probailities\n",
    "\n",
    "When compliling the model we use the hyperparameters:\n",
    "- Optimizer: the algorithm to update the weights, we use Adam() since it good for most problems without much tuning\n",
    "- Loss Function: A function to measure the error we use SparseCategoricalAccuracy to measure how far they are from the correct classes\n",
    "- Metrics: We use SparseCategoricalAccuracy since it enables us to calculate how often the model classifies data correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f025e6da-c3bf-47bb-a146-ab488730faf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make FFNN\n",
    "\n",
    "sample_length = X_tr_nn[0].shape[0]\n",
    "\n",
    "FFNN_model = Sequential([\n",
    "    Input((sample_length,)),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "FFNN_model.compile(optimizer=Adam(),\n",
    "                   loss=SparseCategoricalCrossentropy(), \n",
    "                   metrics=[SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd1bc23",
   "metadata": {},
   "source": [
    "Here we run the model for as many as FFNN_epochs times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0f14b7-7541-4e8c-af62-cfb93a3dbe48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - loss: 2.3030 - sparse_categorical_accuracy: 0.1058\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.2953 - sparse_categorical_accuracy: 0.1076\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - loss: 2.2961 - sparse_categorical_accuracy: 0.1170\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 2.2804 - sparse_categorical_accuracy: 0.1292\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 2.2565 - sparse_categorical_accuracy: 0.1406\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - loss: 2.2298 - sparse_categorical_accuracy: 0.1633\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - loss: 2.1946 - sparse_categorical_accuracy: 0.1795\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.0774 - sparse_categorical_accuracy: 0.1224\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 2.1673 - sparse_categorical_accuracy: 0.2003\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - loss: 2.1317 - sparse_categorical_accuracy: 0.2182\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - loss: 2.0904 - sparse_categorical_accuracy: 0.2338\n",
      "\u001b[1m200/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.0721 - sparse_categorical_accuracy: 0.2404"
     ]
    }
   ],
   "source": [
    "FFNN_epochs = 10\n",
    "for i in range(FFNN_epochs):\n",
    "    FFNN_model.fit(X_tr_nn, y_tr_nn)\n",
    "    if (i%5 == 0):\n",
    "        # print(\"\\n\", i, \": \")\n",
    "        test_loss, test_acc = FFNN_model.evaluate(X_te_nn, y_te_nn)\n",
    "        # print(f'\\nTest accuracy: {test_acc}', \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afdda00",
   "metadata": {},
   "source": [
    "Above we see that the model we see that the model trains for 10 epochs with 219 training batches. The training accuracy is improving beginning at around 10% all the way to 35%, the testing accuracy however remains quite low, indicating that our model isn't generalizing well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25d6587-7706-4191-ad79-b6d21b15d836",
   "metadata": {},
   "source": [
    "The accuracy of this result is unexpectedly low. An accuracy of around 10% given that there are 10 labels implies that the model isn't making any accurate predictions at all. \n",
    "There are a few things we decided to try to boost its accuracy. First we decided to change how we normalized the data. The way the data is currently normalized converts each string into a row of characters, each character into an integer, and each integer into a floating point number between 0 and 1, based on the highest and lowest integer value for all the characters. This creates an uneven distribution of floating point numbers between 0 and 1, with most characters being represented as very low floaing point numbers (e.g. less than 0.01) and some being quite high (e.g. about 0.6). This is because most characters are simply the ascii values of the latin alphabet, which ranges from about 0 to 200, whereas some special characters are represented by numbers in the thousands when considering unicode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880cc54e-ce43-4463-8855-8f31e2faec39",
   "metadata": {},
   "source": [
    "To get around this uneven distribution, we will assign each character its own unique integer value, and divide by the total number of unique characters in all sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4a15f4-19fd-4c76-95ed-12fb790de8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_vec_to_char_matrix(strVec, longest_str_len):\n",
    "    # Pad strings to all be equal length\n",
    "    padded_strVec = np.char.ljust(strVec, longest_str_len, fillchar=' ')\n",
    "\n",
    "    # turn vector of strings into matrix of characters\n",
    "    stacked_char_matrix = np.vstack([np.array(list(s)) for s in padded_strVec])\n",
    "    return stacked_char_matrix\n",
    "\n",
    "# This func takes a vector of strings and returns a vector of unique characters found in those string\n",
    "def alph_from_str_vec(strVec):\n",
    "    l = list(strVec)\n",
    "    bigString = \"\".join(l)\n",
    "    setOfChars = set(bigString)\n",
    "    return np.array(sorted(list(setOfChars)))\n",
    "\n",
    "# I tried without dictionaries before and it was way too slow\n",
    "def map_char_to_value(c_key, alph_dict):\n",
    "    return alph_dict[c_key]\n",
    "\n",
    "def str_vec_to_float_matrix__even_distribution(strVec, longest_str_len, alph_dict):\n",
    "    char_matrix =  str_vec_to_char_matrix(strVec, longest_str_len)\n",
    "\n",
    "    def map_char_to_value_vectorizable(c):\n",
    "        return map_char_to_value(c, alph_dict)\n",
    "        \n",
    "    map_chars_vectorized = np.vectorize(map_char_to_value_vectorizable)\n",
    "    rtn = map_chars_vectorized(char_matrix)\n",
    "\n",
    "    return rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5cd1b9-3c7a-4acc-bfe3-8bb152af8379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done reconverting the data into FFNN format\n"
     ]
    }
   ],
   "source": [
    "def convert_to_FFNN_format__even_distribution(Xr, Xe, yr, ye):\n",
    "    # Creating the right alphabet dictionary for data organization\n",
    "    alph_tr = set(alph_from_str_vec(Xr))\n",
    "    alph_te = set(alph_from_str_vec(Xe))\n",
    "    alph = np.array(sorted(list(alph_tr.union(alph_te))))\n",
    "    alphVals = np.arange(alph.shape[0]) / alph.shape[0]\n",
    "    alph_dict = {char: val for char, val in zip(alph, alphVals)}\n",
    "\n",
    "    # Max str len\n",
    "    max_str_len_1 = np.max(np.char.str_len(Xr))\n",
    "    max_str_len_2 = np.max(np.char.str_len(Xe))\n",
    "    max_str_len = max(max_str_len_1, max_str_len_2)\n",
    "\n",
    "    \n",
    "    Xr_rtn = str_vec_to_float_matrix__even_distribution(Xr, max_str_len, alph_dict)\n",
    "    Xe_rtn = str_vec_to_float_matrix__even_distribution(Xe, max_str_len, alph_dict)\n",
    "    return (Xr_rtn, \n",
    "            Xe_rtn,\n",
    "            str_labels_to_int_labels(yr, lang_codes), \n",
    "            str_labels_to_int_labels(ye, lang_codes))\n",
    "\n",
    "(X_tr_nn, X_te_nn, y_tr_nn, y_te_nn) = convert_to_FFNN_format__even_distribution(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"Done reconverting the data into FFNN format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb70aeac-659f-47d3-839a-d4b68d5b0859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-compile same model\n",
    "\n",
    "sample_length = X_tr_nn[0].shape[0]\n",
    "\n",
    "FFNN_model = Sequential([\n",
    "    Input((sample_length,)),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "FFNN_model.compile(optimizer=Adam(),\n",
    "                   loss=SparseCategoricalCrossentropy(), \n",
    "                   metrics=[SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77eab10-4019-47a1-b840-c8379180c060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/219 [================>.............] - ETA: 1s - loss: 2.3069 - sparse_categorical_accuracy: 0.1048  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Test same model\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m51\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mFFNN_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr_nn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr_nn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs345CondaEnv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs345CondaEnv\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs345CondaEnv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs345CondaEnv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs345CondaEnv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs345CondaEnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs345CondaEnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs345CondaEnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs345CondaEnv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test same model\n",
    "\n",
    "for i in range(3):\n",
    "    FFNN_model.fit(X_tr_nn, y_tr_nn)\n",
    "    if (i%5 == 0):\n",
    "        print(\"\\n\", i, \": \")\n",
    "        test_loss, test_acc = FFNN_model.evaluate(X_te_nn, y_te_nn)\n",
    "        print(f'\\nTest accuracy: {test_acc}', \"\\n\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784bde02-bf27-49dd-8e01-a9b66642a74a",
   "metadata": {},
   "source": [
    "This change did result in a visible improvement, but it still isn't very good, and it required quite a few epochs to improve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d2d1be-e4d8-4205-bd05-7d3076e946a3",
   "metadata": {},
   "source": [
    "## Testing lots of hyperparameters for FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00393a1-f721-4da8-8037-dfd3e8887cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  3  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 2.3022 - sparse_categorical_accuracy: 0.1143\n",
      "\n",
      "Test accuracy: 0.11433333158493042 \n",
      "\n",
      "1  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  3  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 2s 24ms/step - loss: 2.2997 - sparse_categorical_accuracy: 0.1177\n",
      "\n",
      "Test accuracy: 0.11766666918992996 \n",
      "\n",
      "2  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  3  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.3097 - sparse_categorical_accuracy: 0.1080\n",
      "\n",
      "Test accuracy: 0.1080000028014183 \n",
      "\n",
      "3  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  3  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 2.2993 - sparse_categorical_accuracy: 0.1143\n",
      "\n",
      "Test accuracy: 0.11433333158493042 \n",
      "\n",
      "4  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  3  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 2.3005 - sparse_categorical_accuracy: 0.1133\n",
      "\n",
      "Test accuracy: 0.1133333370089531 \n",
      "\n",
      "5  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  3  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 2.2947 - sparse_categorical_accuracy: 0.1257\n",
      "\n",
      "Test accuracy: 0.12566666305065155 \n",
      "\n",
      "6  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  3  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 2.3047 - sparse_categorical_accuracy: 0.1163\n",
      "\n",
      "Test accuracy: 0.11633333563804626 \n",
      "\n",
      "7  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  3  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 2.3028 - sparse_categorical_accuracy: 0.1197\n",
      "\n",
      "Test accuracy: 0.11966666579246521 \n",
      "\n",
      "8  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  3  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 2.3000 - sparse_categorical_accuracy: 0.1240\n",
      "\n",
      "Test accuracy: 0.12399999797344208 \n",
      "\n",
      "9  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  3  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.3031 - sparse_categorical_accuracy: 0.1120 \n",
      "\n",
      "Test accuracy: 0.1120000034570694 \n",
      "\n",
      "10  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  3  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 2.3014 - sparse_categorical_accuracy: 0.1300\n",
      "\n",
      "Test accuracy: 0.12999999523162842 \n",
      "\n",
      "11  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  3  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 2.2995 - sparse_categorical_accuracy: 0.1067\n",
      "\n",
      "Test accuracy: 0.1066666692495346 \n",
      "\n",
      "12  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  6  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 3s 27ms/step - loss: 2.2889 - sparse_categorical_accuracy: 0.1347\n",
      "\n",
      "Test accuracy: 0.13466666638851166 \n",
      "\n",
      "13  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  6  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 2.2897 - sparse_categorical_accuracy: 0.1390\n",
      "\n",
      "Test accuracy: 0.13899999856948853 \n",
      "\n",
      "14  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  6  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.2899 - sparse_categorical_accuracy: 0.1533\n",
      "\n",
      "Test accuracy: 0.15333333611488342 \n",
      "\n",
      "15  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  6  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 2s 9ms/step - loss: 2.2880 - sparse_categorical_accuracy: 0.1383\n",
      "\n",
      "Test accuracy: 0.13833333551883698 \n",
      "\n",
      "16  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  6  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 1s 5ms/step - loss: 2.2806 - sparse_categorical_accuracy: 0.1527\n",
      "\n",
      "Test accuracy: 0.15266667306423187 \n",
      "\n",
      "17  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  6  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 2.2730 - sparse_categorical_accuracy: 0.1693\n",
      "\n",
      "Test accuracy: 0.1693333387374878 \n",
      "\n",
      "18  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  6  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 2.2940 - sparse_categorical_accuracy: 0.1503\n",
      "\n",
      "Test accuracy: 0.15033333003520966 \n",
      "\n",
      "19  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  6  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 2s 16ms/step - loss: 2.2912 - sparse_categorical_accuracy: 0.1343\n",
      "\n",
      "Test accuracy: 0.13433332741260529 \n",
      "\n",
      "20  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  6  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 2.2915 - sparse_categorical_accuracy: 0.1670\n",
      "\n",
      "Test accuracy: 0.16699999570846558 \n",
      "\n",
      "21  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  6  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 2.3013 - sparse_categorical_accuracy: 0.1303\n",
      "\n",
      "Test accuracy: 0.1303333342075348 \n",
      "\n",
      "22  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  6  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 2.2765 - sparse_categorical_accuracy: 0.1453\n",
      "\n",
      "Test accuracy: 0.14533333480358124 \n",
      "\n",
      "23  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  6  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 2.3006 - sparse_categorical_accuracy: 0.1757\n",
      "\n",
      "Test accuracy: 0.1756666600704193 \n",
      "\n",
      "24  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  9  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 2s 19ms/step - loss: 2.2958 - sparse_categorical_accuracy: 0.1373\n",
      "\n",
      "Test accuracy: 0.13733333349227905 \n",
      "\n",
      "25  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  9  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 2s 21ms/step - loss: 2.2855 - sparse_categorical_accuracy: 0.1300\n",
      "\n",
      "Test accuracy: 0.12999999523162842 \n",
      "\n",
      "26  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  9  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.3125 - sparse_categorical_accuracy: 0.1440\n",
      "\n",
      "Test accuracy: 0.14399999380111694 \n",
      "\n",
      "27  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  9  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 2s 17ms/step - loss: 2.2903 - sparse_categorical_accuracy: 0.1580\n",
      "\n",
      "Test accuracy: 0.15800000727176666 \n",
      "\n",
      "28  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  9  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 3s 27ms/step - loss: 2.2896 - sparse_categorical_accuracy: 0.1447\n",
      "\n",
      "Test accuracy: 0.1446666717529297 \n",
      "\n",
      "29  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  9  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 2.3194 - sparse_categorical_accuracy: 0.1787\n",
      "\n",
      "Test accuracy: 0.17866666615009308 \n",
      "\n",
      "30  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  9  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 2.2920 - sparse_categorical_accuracy: 0.1570\n",
      "\n",
      "Test accuracy: 0.15700000524520874 \n",
      "\n",
      "31  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  9  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 2.3079 - sparse_categorical_accuracy: 0.1790\n",
      "\n",
      "Test accuracy: 0.17900000512599945 \n",
      "\n",
      "32  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  9  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 2.3387 - sparse_categorical_accuracy: 0.1713\n",
      "\n",
      "Test accuracy: 0.17133332788944244 \n",
      "\n",
      "33  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  9  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 2.3080 - sparse_categorical_accuracy: 0.1443\n",
      "\n",
      "Test accuracy: 0.14433333277702332 \n",
      "\n",
      "34  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  9  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 2.3219 - sparse_categorical_accuracy: 0.1733\n",
      "\n",
      "Test accuracy: 0.1733333319425583 \n",
      "\n",
      "35  out of  36  hyperparameter combinations done!\n",
      "Fitting model over  9  epochs...\n",
      "Model done fitting.\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.3743 - sparse_categorical_accuracy: 0.1877\n",
      "\n",
      "Test accuracy: 0.18766666948795319 \n",
      "\n",
      "[0.11433333 0.11766667 0.108      0.11433333 0.11333334 0.12566666\n",
      " 0.11633334 0.11966667 0.124      0.112      0.13       0.10666667\n",
      " 0.13466667 0.139      0.15333334 0.13833334 0.15266667 0.16933334\n",
      " 0.15033333 0.13433333 0.167      0.13033333 0.14533333 0.17566666\n",
      " 0.13733333 0.13       0.14399999 0.15800001 0.14466667 0.17866667\n",
      " 0.15700001 0.17900001 0.17133333 0.14433333 0.17333333 0.18766667]\n",
      "[[1, 3, (32,)], [1, 3, (64,)], [1, 3, (256,)], [2, 3, (32, 32)], [2, 3, (32, 64)], [2, 3, (32, 256)], [2, 3, (64, 32)], [2, 3, (64, 64)], [2, 3, (64, 256)], [2, 3, (256, 32)], [2, 3, (256, 64)], [2, 3, (256, 256)], [1, 6, (32,)], [1, 6, (64,)], [1, 6, (256,)], [2, 6, (32, 32)], [2, 6, (32, 64)], [2, 6, (32, 256)], [2, 6, (64, 32)], [2, 6, (64, 64)], [2, 6, (64, 256)], [2, 6, (256, 32)], [2, 6, (256, 64)], [2, 6, (256, 256)], [1, 9, (32,)], [1, 9, (64,)], [1, 9, (256,)], [2, 9, (32, 32)], [2, 9, (32, 64)], [2, 9, (32, 256)], [2, 9, (64, 32)], [2, 9, (64, 64)], [2, 9, (64, 256)], [2, 9, (256, 32)], [2, 9, (256, 64)], [2, 9, (256, 256)]]\n"
     ]
    }
   ],
   "source": [
    "sample_length = X_tr_nn[0].shape[0]\n",
    "\n",
    "def get_model(l_numNodes, numRelu, input_size, output_size):\n",
    "    totalNumLayers = numRelu\n",
    "    \n",
    "    if (len(l_numNodes) != totalNumLayers):\n",
    "        return\n",
    "        \n",
    "    rtn_model = Sequential()\n",
    "    rtn_model.add(Input((input_size,)))\n",
    "\n",
    "    for i in range(numRelu):\n",
    "        rtn_model.add(Dense(l_numNodes[i], activation='relu'))\n",
    "        \n",
    "    rtn_model.add(Dense(output_size, activation='softmax'))\n",
    "\n",
    "    \n",
    "    rtn_model.compile(optimizer=Adam(),\n",
    "                   loss=SparseCategoricalCrossentropy(), \n",
    "                   metrics=[SparseCategoricalAccuracy()])\n",
    "    return rtn_model\n",
    "\n",
    "def run_model_and_test(model, e, x_tr, x_te, y_tr, y_te):\n",
    "    print(\"Fitting model over \", e, \" epochs...\")\n",
    "    model.fit(x_tr, y_tr, epochs=e, verbose=0);\n",
    "    print(\"Model done fitting.\")\n",
    "    test_loss, test_acc = model.evaluate(x_te, y_te, verbose=0)\n",
    "    print(f'\\nTest accuracy: {test_acc}', \"\\n\")\n",
    "    return test_loss, test_acc\n",
    "\n",
    "import math\n",
    "def nChooseKPerm(n, k):\n",
    "    if k < 0 or k > n:\n",
    "        return 0 \n",
    "    return math.factorial(n) // math.factorial(n - k)\n",
    "\n",
    "from itertools import product\n",
    "def hypertest_FFNN(Xr, Xe, yr, ye, l_nEpochs, l_nLayers, l_nodeCounts, input_size, output_size):\n",
    "    hyperCombo_list = list()\n",
    "    accuracy_list = np.array([])\n",
    "    epochs_layers = product(l_nEpochs, l_nLayers)\n",
    "    count = 0\n",
    "    total_combos = len(l_nEpochs) * len(l_nLayers) * (nChooseKPerm(len(l_nodeCounts), len(l_nLayers)))\n",
    "    for i_epochs, i_layers in epochs_layers:\n",
    "        per_layer_neuron_counts = product(l_nodeCounts, repeat=i_layers) \n",
    "        for l_layer_sizes in  per_layer_neuron_counts:\n",
    "            print(count, \" out of \", total_combos, \" hyperparameter combinations done!\")\n",
    "            m = get_model(l_layer_sizes, i_layers, input_size, output_size)\n",
    "            trash, accuracy = run_model_and_test(m, i_epochs, Xr, Xe, yr, ye)\n",
    "            accuracy_list = np.concatenate((accuracy_list, np.array([accuracy])))\n",
    "            hyperCombo_list.append(list([i_layers, i_epochs, l_layer_sizes]))\n",
    "            count += 1\n",
    "    return hyperCombo_list, accuracy_list\n",
    "\n",
    "\n",
    "numEpochs = [3, 6, 9]\n",
    "numLayers = [1, 2]\n",
    "layerSizes = [32, 64, 256]\n",
    "\n",
    "\n",
    "\n",
    "hyperCombo_list, accuracy_list = hypertest_FFNN(X_tr_nn, X_te_nn, y_tr_nn, y_te_nn, numEpochs, numLayers, layerSizes, sample_length, 10)\n",
    "\n",
    "print(accuracy_list)\n",
    "print(hyperCombo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b565d1-c355-4e0a-b959-b15873e31084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Hyperparamters (num of layers, epochs, layer sizes)': hyperCombo_list,\n",
    "    'Accuracies of hyperparameter': accuracy_list\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
