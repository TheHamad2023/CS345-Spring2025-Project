{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4315aa3e",
   "metadata": {},
   "source": [
    "# CS345 Project\n",
    "\n",
    "## Team Members\n",
    "1. Hamad Alyami\n",
    "2. Benito Encarnacion\n",
    "\n",
    "## Dataset\n",
    "Our dataset was from Kaggle by a user called Mexwell. The data is paragraphs scraped from wikipedia in 2018 in 235 languages.\n",
    "\n",
    "The dataset contains 235,000 datasets with balance between language proportions and a test and train split provided.\n",
    "\n",
    "The downloaded folder from Kaggle contains:\n",
    "- labels.csv: A file containing the language name, 2-3 letter code, German name, and language family of all the languages present in the dataset.\n",
    "- README.txt: A file explaining the folder contents.\n",
    "- urls.txt: A file containing the urls of where the paragraphs were found.\n",
    "- x_test.txt: The testing data samples, paragraphs in multiple languages.\n",
    "- x_train.txt: The training data samples, paragraphs in multiple langauges\n",
    "- y_test.txt: The labels for the testing dataset, using the 2-3 letter codes found in labels.csv.\n",
    "- y_train.txt: The labels for the training dataset, using the 2-3 letter codes found in labels.csv\n",
    "\n",
    "\n",
    "## Project\n",
    "Our project is to train and compare two ML models on the Latin Alphabet languages present in the dataset and compare their performance.\n",
    "\n",
    "## Motivation\n",
    "We decided to do this project because it allows us to explore practical applications of natural language processing and machine learning by working with real-world multilingual data. Language identification is an important task in many systems and applications like search engines, translation tools, and content moderation. Working with such a dataset gives us the opportunity to apply classification techniques in a meaningful way. By focusing on languages that use the Latin alphabet, we avoid complications from different writing systems while still working with a variety of languages.\n",
    "\n",
    "## Models\n",
    "The models we decided to work with in this project are:\n",
    "- Multinomial Naive-Bayes (MNB): Uses word frequencies in each class, langauges in our case, to guess the most likely class for text it has not seen.\n",
    "\n",
    "- Feed Forward Neural Network (FNN): An artificial Neural Network where information moves from input to output without looping back. It uses neurons, connected nodes, to learn patterns and make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1704ce66",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "We will begin by reading the data from the files then:\n",
    "1. Remove Null Values\n",
    "2. Filter to keep texts of languages we want using the 2-3 letter codes\n",
    "3. Return both samples from x_test and x_train and labels from y_test and y_train stacked into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7602a789-a084-4f24-b977-47df8039c2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/x_train.txt: Read!\n",
      "Data/y_train.txt: Read!\n",
      "Data/x_test.txt: Read!\n",
      "Data/y_test.txt: Read!\n",
      "(5000,) (5000,)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Understanding the data set\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "            #Italina, French, Spanish, Portugese, English, German, Dutch, Indonesian, Finnish, Hausa\n",
    "lang_codes = ['ita', 'fra', 'spa', 'eng', 'ind']\n",
    "langs = ['Italian', 'French', 'Spanish', 'English', 'Indonesian']\n",
    "\n",
    "def file_to_np_array(path, label):\n",
    "    try:\n",
    "        df = pd.read_csv(path, sep='<NonExistenceSeparator>', header=None, engine='python')\n",
    "        print(f\"{label}: Read!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the {label} file: {e}\")\n",
    "        return None\n",
    "    return df.to_numpy()\n",
    "\n",
    "\n",
    "def clean_np_data(X, y):\n",
    "    stacked = np.hstack((y, X)) # Stack y and X side by side\n",
    "    # print(stacked.shape)\n",
    "    clean_stacked = stacked[~np.any(pd.isna(stacked), axis=1), :] # Remove empty values\n",
    "    # print(clean_stacked.shape)\n",
    "    true_clean = clean_stacked[np.isin(clean_stacked[:,0], lang_codes),:] # Remove all rows that aren't our target languages\n",
    "    # print(true_clean.shape)\n",
    "    return true_clean[:,1], true_clean[:,0] # Return cleaned as X and y split again\n",
    "\n",
    "def clean_filter_and_stack(X_train_file, y_train_file, X_test_file, y_test_file):\n",
    "    X_train_clean, y_train_clean = clean_np_data(file_to_np_array(X_train_file, X_train_file), \n",
    "                                       file_to_np_array(y_train_file, y_train_file))\n",
    "    X_test_clean, y_test_clean = clean_np_data(file_to_np_array(X_test_file, X_test_file), \n",
    "                                       file_to_np_array(y_test_file, y_test_file))\n",
    "    return np.hstack((X_train_clean, X_test_clean)).astype(str), np.hstack((y_train_clean, y_test_clean)).astype(str)\n",
    "\n",
    "X, y = clean_filter_and_stack(\"Data/x_train.txt\", \n",
    "                                      \"Data/y_train.txt\", \n",
    "                                      \"Data/x_test.txt\", \n",
    "                                      \"Data/y_test.txt\")\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b5f87e",
   "metadata": {},
   "source": [
    "#### Data Discovery\n",
    "This code is to find what is the sample distribution between languages and average word count of each sample of each language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d27cb38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Percent of Dataset (%)</th>\n",
       "      <th>Average Word Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italian</td>\n",
       "      <td>20.0</td>\n",
       "      <td>68.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>French</td>\n",
       "      <td>20.0</td>\n",
       "      <td>67.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>20.0</td>\n",
       "      <td>67.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>English</td>\n",
       "      <td>20.0</td>\n",
       "      <td>70.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indonesian</td>\n",
       "      <td>20.0</td>\n",
       "      <td>57.147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Language  Percent of Dataset (%)  Average Word Count\n",
       "0     Italian                    20.0              68.192\n",
       "1      French                    20.0              67.707\n",
       "2     Spanish                    20.0              67.295\n",
       "3     English                    20.0              70.455\n",
       "4  Indonesian                    20.0              57.147"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def avg_words(filtered_X):\n",
    "    total = 0\n",
    "    for text in filtered_X:\n",
    "        words = str(text).split()\n",
    "        total += len(words)\n",
    "\n",
    "    return total / len(filtered_X)\n",
    "\n",
    "def word_count_perlang(X, y):\n",
    "    avg_word_count = []\n",
    "    for lang in lang_codes:\n",
    "        filtered_X = X[y == lang]\n",
    "        avg_word_count.append(avg_words(filtered_X))\n",
    "    \n",
    "    return avg_word_count\n",
    "\n",
    "def lang_perc(y):\n",
    "    lang_perc = []\n",
    "    total = len(y)\n",
    "    for lang in lang_codes:\n",
    "        count = (y == lang).sum()\n",
    "        percent = (count / total) * 100\n",
    "        lang_perc.append(percent)\n",
    "    return lang_perc\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Language': langs,\n",
    "    'Percent of Dataset (%)': lang_perc(y),\n",
    "    'Average Word Count': word_count_perlang(X, y)\n",
    "})\n",
    "\n",
    "display(df)\n",
    "\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# model = MultinomialNB()\n",
    "# model.fit(X_train_vectors, y_train)\n",
    "# print(\"Done training MNB\")\n",
    "\n",
    "# y_pred = model.predict(X_test_vectors)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Overall accuracy of MNB: \" + str(accuracy * 100) + \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a7d528",
   "metadata": {},
   "source": [
    "#### Data Split\n",
    "Here we use Sklearn train_test_split to split our data into 70/30 train and test splits, respectively, after shuffling them randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60b758fc-1a04-4cc4-8c94-9c6034e4ca00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500,) (3500,)\n",
      "(1500,) (1500,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=17)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad363514",
   "metadata": {},
   "source": [
    "And then vectorize our dataset for the MNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5925257-f51e-452b-be5b-7a4dede72735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done vectorizing\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(strip_accents='unicode')\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "X_test_vectors = vectorizer.transform(X_test)\n",
    "print(\"Done vectorizing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7602be5a",
   "metadata": {},
   "source": [
    "We train our MNB using the MultinomialNB() function from sklearn on X_train which is 70% of our dataset.\n",
    "\n",
    "### MNB\n",
    "The sklearn MNB implementation has two main hyperparameters, alpha and fit_prior.\n",
    "\n",
    "- alpha is used to smooth the data, so the model doesn’t get confused if a word doesn’t appear in some languages. This helps prevent errors, especially when some words are rare. The default value alpha=1.0 usually works well for text data like ours.\n",
    "\n",
    "- fit_prior decides whether the model should learn how common each language is from the training data. Since all our language samples are balanced (equal amounts), the default setting (True) works fine.\n",
    "\n",
    "So, for our language detection project, we don’t need to change these settings — the defaults are already a good fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb703257-141d-403f-a819-31553f0ccde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training MNB\n",
      "Overall accuracy of MNB: 98.93333333333332%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vectors, y_train)\n",
    "print(\"Done training MNB\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test_vectors)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Overall accuracy of MNB: \" + str(accuracy * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9e0933",
   "metadata": {},
   "source": [
    "Considering our MNB accuracy is unexpectadly hard, we decided to add 5 more languages; Hausa, Portugese, Finnish, German, and Dutch. This is to introduce more languages that are similar like German and Dutch and Spanish and Portugese but at the same time some that are different like Hausa from all the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d83ac461",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_codes = ['ita', 'fra', 'spa', 'por', 'eng', 'deu', 'nld', 'ind', 'fin', 'hau']\n",
    "langs = ['Italian', 'French', 'Spanish', 'Portuguese', 'English', 'German', 'Dutch', 'Indonesian', 'Finnish', 'Hausa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d85a5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/x_train.txt: Read!\n",
      "Data/y_train.txt: Read!\n",
      "Data/x_test.txt: Read!\n",
      "Data/y_test.txt: Read!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Percent of Dataset (%)</th>\n",
       "      <th>Average Word Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italian</td>\n",
       "      <td>10.0</td>\n",
       "      <td>68.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>French</td>\n",
       "      <td>10.0</td>\n",
       "      <td>67.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>10.0</td>\n",
       "      <td>67.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Portuguese</td>\n",
       "      <td>10.0</td>\n",
       "      <td>66.184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>German</td>\n",
       "      <td>10.0</td>\n",
       "      <td>59.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dutch</td>\n",
       "      <td>10.0</td>\n",
       "      <td>55.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indonesian</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Finnish</td>\n",
       "      <td>10.0</td>\n",
       "      <td>48.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hausa</td>\n",
       "      <td>10.0</td>\n",
       "      <td>75.802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Language  Percent of Dataset (%)  Average Word Count\n",
       "0     Italian                    10.0              68.192\n",
       "1      French                    10.0              67.707\n",
       "2     Spanish                    10.0              67.295\n",
       "3  Portuguese                    10.0              66.184\n",
       "4     English                    10.0              70.455\n",
       "5      German                    10.0              59.762\n",
       "6       Dutch                    10.0              55.657\n",
       "7  Indonesian                    10.0              57.147\n",
       "8     Finnish                    10.0              48.431\n",
       "9       Hausa                    10.0              75.802"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = clean_filter_and_stack(\"Data/x_train.txt\", \n",
    "                                      \"Data/y_train.txt\", \n",
    "                                      \"Data/x_test.txt\", \n",
    "                                      \"Data/y_test.txt\")\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Language': langs,\n",
    "    'Percent of Dataset (%)': lang_perc(y),\n",
    "    'Average Word Count': word_count_perlang(X, y)\n",
    "})\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d7cc54",
   "metadata": {},
   "source": [
    "We can still see that the data is still equally distributed, with each language being 10% of the data set. We do see a discrepency however in the average word count of the samples for each langugae, with overall average being around 65. We see that Finnish has an average of 48 words, the lowest, and Haussa has the highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8c72ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000,) (7000,)\n",
      "(3000,) (3000,)\n",
      "Done vectorizing\n",
      "Done training MNB\n",
      "Overall accuracy of MNB: 98.1%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=17)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "vectorizer = CountVectorizer(strip_accents='unicode')\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "X_test_vectors = vectorizer.transform(X_test)\n",
    "print(\"Done vectorizing\")\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vectors, y_train)\n",
    "print(\"Done training MNB\")\n",
    "\n",
    "y_pred = model.predict(X_test_vectors)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Overall accuracy of MNB: \" + str(accuracy * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29400367",
   "metadata": {},
   "source": [
    "The overall accuracy is still really good, much more than what we anticipated or expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6603099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Accuracy of MNB/language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italian</td>\n",
       "      <td>96.855346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>French</td>\n",
       "      <td>99.335548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>97.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Portuguese</td>\n",
       "      <td>93.728223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>German</td>\n",
       "      <td>97.569444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dutch</td>\n",
       "      <td>98.275862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indonesian</td>\n",
       "      <td>98.615917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Finnish</td>\n",
       "      <td>99.315068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hausa</td>\n",
       "      <td>99.662162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Language  Accuracy of MNB/language\n",
       "0     Italian                 96.855346\n",
       "1      French                 99.335548\n",
       "2     Spanish                 97.647059\n",
       "3  Portuguese                 93.728223\n",
       "4     English                100.000000\n",
       "5      German                 97.569444\n",
       "6       Dutch                 98.275862\n",
       "7  Indonesian                 98.615917\n",
       "8     Finnish                 99.315068\n",
       "9       Hausa                 99.662162"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_lang_accuracies(y_true, y_pred):\n",
    "    df = pd.DataFrame({'language': y_true, 'pred': y_pred})\n",
    "    accuracies = []\n",
    "\n",
    "    for lang in lang_codes:\n",
    "        lang_group = df[df['language'] == lang]\n",
    "        if len(lang_group) > 0:\n",
    "            acc = accuracy_score(lang_group['language'], lang_group['pred'])\n",
    "        else:\n",
    "            acc = 0\n",
    "        accuracies.append(acc)\n",
    "    \n",
    "    percent_accuracies = [x * 100 for x in accuracies]\n",
    "    df = None\n",
    "    return percent_accuracies\n",
    "\n",
    "df_MNB_lang = pd.DataFrame({\n",
    "    'Language': langs,\n",
    "    'Accuracy of MNB/language': get_lang_accuracies(y_test, y_pred)\n",
    "})\n",
    "\n",
    "display(df_MNB_lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3a03ac",
   "metadata": {},
   "source": [
    "#### Accuracy\n",
    "We see that the over all accuracy is 98.1 which is still very high and didn't expect. More so, we see that English has a 100% accuracy. We would like to also note how Portugese is the lowest withh 93.7% and Finnish is the second best with an almost perfect accuracy of 99.3%.\n",
    "\n",
    "We will attempt to explore the model more and theorize why we ended up with such results down below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b894d5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Top words per lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italian</td>\n",
       "      <td>[di, il, la, in, del]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>French</td>\n",
       "      <td>[de, la, le, en, et]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>[de, la, en, el, que]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Portuguese</td>\n",
       "      <td>[de, em, do, que, da]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English</td>\n",
       "      <td>[the, of, in, and, to]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>German</td>\n",
       "      <td>[der, die, und, in, von]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dutch</td>\n",
       "      <td>[de, van, in, het, een]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indonesian</td>\n",
       "      <td>[yang, dan, di, pada, dari]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Finnish</td>\n",
       "      <td>[ja, on, oli, han, vuonna]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hausa</td>\n",
       "      <td>[da, ta, ya, na, ne]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Language           Top words per lang\n",
       "0     Italian        [di, il, la, in, del]\n",
       "1      French         [de, la, le, en, et]\n",
       "2     Spanish        [de, la, en, el, que]\n",
       "3  Portuguese        [de, em, do, que, da]\n",
       "4     English       [the, of, in, and, to]\n",
       "5      German     [der, die, und, in, von]\n",
       "6       Dutch      [de, van, in, het, een]\n",
       "7  Indonesian  [yang, dan, di, pada, dari]\n",
       "8     Finnish   [ja, on, oli, han, vuonna]\n",
       "9       Hausa         [da, ta, ya, na, ne]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def top_words_per_lang(model, vectorizer, top_n=5):\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    log_probs = model.feature_log_prob_\n",
    "    class_indices = {label: i for i, label in enumerate(model.classes_)}\n",
    "    \n",
    "    return [\n",
    "        [feature_names[i] for i in log_probs[class_indices[lang]].argsort()[::-1][:top_n]]\n",
    "        for lang in lang_codes\n",
    "    ]\n",
    "\n",
    "df_top_words_MNB = pd.DataFrame({\n",
    "    'Language': langs,\n",
    "    'Top words per lang' :top_words_per_lang(model, vectorizer, 5)\n",
    "})\n",
    "\n",
    "pd.set_option('display.max_colwidth', None) \n",
    "\n",
    "display(df_top_words_MNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3514c2b2",
   "metadata": {},
   "source": [
    "We used this function to identify what are the top 5 words that the model, MultinomialNB(), found to be the most indicative of a class. To do this, we used MultinomialNB()'s **feature_log_prob_ variable**, which stores the log-probability of each word (feature) given each class (language). This means it tells us how strongly each word is associated with each language according to the model.\n",
    "\n",
    "The shape of this variable is **(n_classes, n_features)**, where n_classes is the number of languages and n_features is the number of unique words in the vocabulary. Each row shows the log-probabilities for one class, and each column represents a word. The higher the value, the more important that word is for predicting that class.\n",
    "\n",
    "We collected the top 5 because it provides a good balance between being explanatory and concise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36c9597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overlap_matrix(top_words_list):\n",
    "    n = len(lang_codes)\n",
    "    matrix = []\n",
    "\n",
    "    for i in range(n):\n",
    "        row = []\n",
    "        for j in range(n):\n",
    "            overlap = len(set(top_words_list[i]).intersection(top_words_list[j]))\n",
    "            row.append(overlap)\n",
    "        matrix.append(row)\n",
    "\n",
    "    return pd.DataFrame(matrix, index=lang_codes, columns=lang_codes)\n",
    "\n",
    "top_words_list = top_words_per_lang(model, vectorizer, 5)\n",
    "overlap_df = compute_overlap_matrix(top_words_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9879ab0c",
   "metadata": {},
   "source": [
    "#### Top Words in all Languages\n",
    "In the cell below we find the top 5 words that appear in all languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "807ac56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words appearing in more than one language, top 5: ['di', 'la', 'in', 'de', 'en', 'que', 'da']\n"
     ]
    }
   ],
   "source": [
    "def find_shared_words(word_lists):\n",
    "    word_counts = {}\n",
    "    \n",
    "    for word_list in word_lists:\n",
    "        for word in word_list:\n",
    "            if word in word_counts:\n",
    "                word_counts[word] += 1\n",
    "            else:\n",
    "                word_counts[word] = 1\n",
    "\n",
    "    shared = []\n",
    "    for word, count in word_counts.items():\n",
    "        if count > 1:\n",
    "            shared.append(word)\n",
    "\n",
    "    return shared\n",
    "\n",
    "shared_words = find_shared_words(top_words_list)\n",
    "print(\"Words appearing in more than one language, top 5:\", shared_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6962847a",
   "metadata": {},
   "source": [
    "#### Heat-map of Words Correlation between Languages\n",
    "Here we use a matplot to give a colored heat-map of how many words of our top 5 from each language meet between each language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "446fe6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(overlap_df, annot=True, cmap=\"YlGnBu\", fmt=\"d\")\n",
    "plt.title(\"Overlap of Top 5 Words Between Languages\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c184c98",
   "metadata": {},
   "source": [
    "In the heat-map we find without any surprise that between each language and itself a 5. Next French and Spanish meet with 3 words and then Portugese and Spanish.\n",
    "\n",
    "When focusing on English and Finnish, we see more. Finnish has absolutly no correlation in its top 5 words with any other language while English still has some, 1 word each, with some other languages. This explains why Finnish has such a high accuracy but why not higher than English?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05563e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italian:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count in Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>di</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>il</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>la</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>del</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  Count in Dataset\n",
       "0   di               786\n",
       "1   il               596\n",
       "2   la               599\n",
       "3   in               520\n",
       "4  del               500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count in Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>la</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>le</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>et</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  Count in Dataset\n",
       "0   de               934\n",
       "1   la               741\n",
       "2   le               650\n",
       "3   en               568\n",
       "4   et               713"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count in Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>la</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>el</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>que</td>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  Count in Dataset\n",
       "0   de               939\n",
       "1   la               827\n",
       "2   en               766\n",
       "3   el               740\n",
       "4  que               527"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portuguese:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count in Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>em</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>do</td>\n",
       "      <td>558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>que</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>da</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  Count in Dataset\n",
       "0   de               875\n",
       "1   em               542\n",
       "2   do               558\n",
       "3  que               488\n",
       "4   da               560"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count in Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  Count in Dataset\n",
       "0  the               913\n",
       "1   of               790\n",
       "2   in               760\n",
       "3  and               814\n",
       "4   to               580"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count in Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>der</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>die</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>und</td>\n",
       "      <td>712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>von</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  Count in Dataset\n",
       "0  der               760\n",
       "1  die               587\n",
       "2  und               712\n",
       "3   in               581\n",
       "4  von               465"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dutch:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count in Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>van</td>\n",
       "      <td>806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in</td>\n",
       "      <td>742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>het</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>een</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  Count in Dataset\n",
       "0   de               892\n",
       "1  van               806\n",
       "2   in               742\n",
       "3  het               694\n",
       "4  een               707"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indonesian:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count in Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yang</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dan</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>di</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pada</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dari</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word  Count in Dataset\n",
       "0  yang               720\n",
       "1   dan               747\n",
       "2    di               546\n",
       "3  pada               444\n",
       "4  dari               487"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finnish:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count in Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ja</td>\n",
       "      <td>781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>on</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oli</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>han</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vuonna</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Word  Count in Dataset\n",
       "0      ja               781\n",
       "1      on               477\n",
       "2     oli               296\n",
       "3     han                 0\n",
       "4  vuonna               187"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hausa:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count in Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>da</td>\n",
       "      <td>874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ta</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ya</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>na</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ne</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  Count in Dataset\n",
       "0   da               874\n",
       "1   ta               585\n",
       "2   ya               473\n",
       "3   na               582\n",
       "4   ne               496"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyzer = vectorizer.build_analyzer()\n",
    "\n",
    "def count_top_words_in_lang_samples(X, y, top_words_count):\n",
    "    results = []\n",
    "    for i, lang in enumerate(lang_codes):\n",
    "        lang_samples = X[y == lang]\n",
    "        word_counts = []\n",
    "\n",
    "        for word in top_words_list[i]:\n",
    "            count = sum(word in analyzer(text) for text in lang_samples)\n",
    "            word_counts.append(count)\n",
    "\n",
    "        results.append(word_counts)\n",
    "    return results\n",
    "\n",
    "def MNB_words_table(top_words, top_words_count):\n",
    "    for i, lang in enumerate(langs):\n",
    "        print(lang + \":\")\n",
    "        df = pd.DataFrame({\n",
    "            \"Word\": top_words[i],\n",
    "            \"Count in Dataset\": top_words_count[i]\n",
    "        })\n",
    "        display(df)\n",
    "\n",
    "top_words = top_words_per_lang(model, vectorizer, 5)\n",
    "top_counts = count_top_words_in_lang_samples(X, y, top_words)\n",
    "\n",
    "MNB_words_table(top_words, top_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e160212f",
   "metadata": {},
   "source": [
    "Here we see something that would explain things more a bit. We notice that English has a high count overall of the top 5 words in the samples we have. Perhaps not the highest, but the higher ones are found in more than one language, like 'de'. While 'the' is slightly less in count but is only found in English.\n",
    "\n",
    "This gives a very good idea on why English has the highest accuracy, not only does it have a relatively high count of indicative words by the MNB, but also these words are special and are not found in other languages.\n",
    "\n",
    "Furhtermore, while Finnish as we saw in the heatmap has no correlation with any other language in our dataset, its top 5 indicative words by the MNB are way less than English, which explains why it performs worse than English even though English has correlation in indicative words with other languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dae2f94",
   "metadata": {},
   "source": [
    "### K-Fold\n",
    "Since our accuracy is high, we will perform k-folds on the dataset using MNB to see how well our model generalizes on unseen data. We choose the optimal number of folds of 5 since it has a balance of testing the model but not being too heavy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f966d3e-57e4-4b15-9897-32ca8d142f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model_kfold = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=17)\n",
    "\n",
    "all_preds = []\n",
    "all_true = []\n",
    "\n",
    "X_train_kfold = X_train.copy()\n",
    "X_test_kfold = X_test.copy()\n",
    "y_train_kfold = y_train.copy()\n",
    "y_test_kfold = y_test.copy()\n",
    "\n",
    "k_folds_accuracies = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "    X_train_kfold, X_test_kfold = X[train_index], X[test_index]\n",
    "    y_train_kfold, y_test_kfold = y[train_index], y[test_index]\n",
    "\n",
    "    model_kfold.fit(X_train_kfold.flatten(), y_train_kfold.flatten())\n",
    "    y_pred_kfold = model_kfold.predict(X_test_kfold.flatten())\n",
    "\n",
    "    fold_accuracy = accuracy_score(y_test_kfold, y_pred_kfold)\n",
    "    k_folds_accuracies.append(fold_accuracy)\n",
    "\n",
    "    all_preds.extend(y_pred_kfold)\n",
    "    all_true.extend(y_test_kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c828e604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results (Accuracy):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kfold</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.9825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.9840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Kfold  Accuracy\n",
       "0      1    0.9825\n",
       "1      2    0.9830\n",
       "2      3    0.9825\n",
       "3      4    0.9860\n",
       "4      5    0.9840"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Kfolds Mean Accuracy: 98.36%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Accuracy of MNB/language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italian</td>\n",
       "      <td>0.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>French</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Portuguese</td>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>German</td>\n",
       "      <td>0.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dutch</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indonesian</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Finnish</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hausa</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Language  Accuracy of MNB/language\n",
       "0     Italian                     0.985\n",
       "1      French                     0.993\n",
       "2     Spanish                     0.980\n",
       "3  Portuguese                     0.949\n",
       "4     English                     0.998\n",
       "5      German                     0.982\n",
       "6       Dutch                     0.980\n",
       "7  Indonesian                     0.978\n",
       "8     Finnish                     0.996\n",
       "9       Hausa                     0.995"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_kfold_accuracy = pd.DataFrame({\n",
    "    'Kfold': [1, 2, 3, 4, 5],\n",
    "    'Accuracy': k_folds_accuracies\n",
    "})\n",
    "\n",
    "\n",
    "print(\"Cross-Validation Results (Accuracy):\")\n",
    "\n",
    "display(df_kfold_accuracy)\n",
    "\n",
    "print(f'\\nOverall Kfolds Mean Accuracy: {cross_val_score(model_kfold, X.flatten(), y.flatten(), cv=kf).mean() * 100:}%')\n",
    "\n",
    "def get_lang_accuracies(y_true, y_pred):\n",
    "    df = pd.DataFrame({'language': y_true, 'pred': y_pred})\n",
    "    accuracies = []\n",
    "\n",
    "    for lang in lang_codes:\n",
    "        lang_group = df[df['language'] == lang]\n",
    "        if len(lang_group) > 0:\n",
    "            acc = accuracy_score(lang_group['language'], lang_group['pred'])\n",
    "        else:\n",
    "            acc = 0\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    return accuracies\n",
    "\n",
    "df_lang_accuracy = pd.DataFrame({\n",
    "    'Language': langs,\n",
    "    'Accuracy of MNB/language': get_lang_accuracies(np.array(all_true), np.array(all_preds))\n",
    "})\n",
    "\n",
    "display(df_lang_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfe4309",
   "metadata": {},
   "source": [
    "We see from the results from the K-folds that the accuracy is still consistent which indicates to use that the model is quite robust. The accuracies are also consistent for the languages.\n",
    "\n",
    "Due to these results we will assume that the top 5 words indicative for MNB will be similar to what we found previously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7764fb5c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd0bbb3",
   "metadata": {},
   "source": [
    "### MNB Conclusions\n",
    "While we haven't anticipated this high of an accuracy for our MNB, intuitively it makes sense. There are certain words that are only found in certain languages and they appear quite often in most sentences, like articles in English. And while some other languages have correlation when it comes to the indicative words their count and combination with other unique words in the language makes it possible for the MNB to classify the language accuratly.\n",
    "\n",
    "Thus, MNB performs quite well when given decently sized texts from languages to train on, like paragraphs. This gives it the ability to record the most common words in that language and the unique words that exist in the language.\n",
    "\n",
    "When testing, if given a valid sentence, it will be able to accuratly classify it sense for example, a simple sentence in English no matter how short will contain articles, verbs, or adjectives.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f69be588",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_addtl = np.array([\n",
    "    # Italian\n",
    "    \"Bambini ridevano mentre guardavano fuochi sopra ponte vecchio.\",\n",
    "    \"Neve fresca copriva tetto rustico durante alba tranquilla.\",\n",
    "\n",
    "    # French\n",
    "    \"Clé cassée resta coincée sous meuble ancien.\",\n",
    "    \"Lumière faible éclairait couloir désert chaque nuit.\",\n",
    "\n",
    "    # Spanish\n",
    "    \"Guitarra sonaba cerca ventana rota durante fiesta secreta.\",\n",
    "    \"Sombras largas cruzaban pasillo viejo sin sonido alguno.\",\n",
    "\n",
    "    # Portuguese\n",
    "    \"Barco afundou devagar próximo cais silencioso.\",\n",
    "    \"Fumaça subia após explosão repentina dentro fábrica antiga.\",\n",
    "\n",
    "    # English\n",
    "    \"Impetus convive.\",\n",
    "    # \"afjlkasdf\",\n",
    "    \"Galvanized Acumen.\",\n",
    "\n",
    "    # German\n",
    "    \"Regen fiel schnell gegen Bäume kahlen draußen.\",\n",
    "    \"Kerze flackerte still auf Tisch zerkratzt alt.\",\n",
    "\n",
    "    # Dutch\n",
    "    \"Stilte hing rond toren verlaten zonder mensen.\",\n",
    "    \"Kleine boot dreef langzaam over meer breed.\",\n",
    "\n",
    "    # Indonesian\n",
    "    \"Topi merah jatuh ke lantai tanpa suara.\",\n",
    "    \"Malam gelap membawa angin kencang lewat bukit.\",\n",
    "\n",
    "    # Finnish\n",
    "    \"Hiljainen järvi heijasti kuun valoa yössä.\",\n",
    "    \"Vanha mies kulki polkua pitkin varhain aamulla.\",\n",
    "\n",
    "    # Hausa\n",
    "    \"Gashi nata ya bushe daga iska mai sanyi.\",\n",
    "    \"Kwalliya ta fadi kan kasa lokacin dare ya zo.\"\n",
    "])\n",
    "\n",
    "y_test_addtl = np.array(['ita', 'ita', 'fra', 'fra', 'spa', 'spa', 'por', 'por',\n",
    "                        'eng', 'eng', 'deu', 'deu', 'nld', 'nld', 'ind', 'ind',\n",
    "                        'fin', 'fin', 'hau', 'hau'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb4de1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy of MNB: 90.0%\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(strip_accents='unicode')\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)  # Fit only on training\n",
    "X_test_addtl_vect = vectorizer.transform(X_test_addtl)\n",
    "\n",
    "y_pred_addtl = model.predict(X_test_addtl_vect)\n",
    "accuracy_addtl = accuracy_score(y_test_addtl, y_pred_addtl)\n",
    "print(\"Overall accuracy of MNB: \" + str(accuracy_addtl * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f79c4e1-1e47-4eff-b6a2-27c7504733bd",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81a93297-6dd5-4cb8-af86-0ff9a0616fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganizing data for Feed Forward Neural Network input\n",
    "\n",
    "# 1) convert string labels into integer labels\n",
    "#      and make func to convert back\n",
    "\n",
    "\n",
    "def str_labels_to_int_labels(labelArr, string_labels):\n",
    "    rtn = np.empty(labelArr.shape, dtype=int)\n",
    "    for i, v in enumerate(string_labels):\n",
    "        rtn[labelArr == v] = i\n",
    "    return rtn\n",
    "\n",
    "def int_labels_to_str_labels(labelArr, string_labels):\n",
    "    rtn = np.empty(labelArr.shape, dtype='object')\n",
    "    for i, v in enumerate(string_labels):\n",
    "        rtn[labelArr == i] = v\n",
    "    return rtn\n",
    "\n",
    "# print(y_test[0:5])\n",
    "# y1 = str_labels_to_int_labels(y_test, all_str_labels)\n",
    "# print(y1[0:5])\n",
    "# y2 = int_labels_to_str_labels(y1, all_str_labels)\n",
    "# print(y2[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1be68002-eb66-461c-94b4-7fa37cc9e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) convert data into multi-column matrix of characters\n",
    "#      and make func to convert back\n",
    "\n",
    "def str_vec_to_float_matrix(strVec, longest_str_len):\n",
    "    # Pad strings to all be equal length\n",
    "    padded_strVec = np.char.ljust(strVec, longest_str_len, fillchar=' ')\n",
    "\n",
    "    # turn vector of strings into matrix of characters\n",
    "    stacked_char_matrix = np.vstack([np.array(list(s)) for s in padded_strVec])\n",
    "\n",
    "    # turn char matrix into int matrix\n",
    "    char_matrix_to_int_matrix = np.vectorize(ord)\n",
    "    int_matrix = char_matrix_to_int_matrix(stacked_char_matrix)\n",
    "\n",
    "    #normalize and scale so each value is a float between 0 and 1\n",
    "    matrix_max = np.max(int_matrix)\n",
    "    matrix_min = np.min(int_matrix)\n",
    "    min_subtracted_matrix = int_matrix - matrix_min\n",
    "    normalized_matrix = (min_subtracted_matrix / (matrix_max - matrix_min))\n",
    "    return normalized_matrix\n",
    "\n",
    "# Don't need to convert matrices back into rows of text because the neural network isn't designed to generate anything, just classify\n",
    "# def int_matrix_to_str_vec(intMatrix):\n",
    "#     int_matrix_to_char_matrix = np.vectorize(chr)\n",
    "#     char_matrix = int_matrix_to_char_matrix(intMatrix)\n",
    "#     padded_strVec = np.array([\"\".join(r) for r in char_matrix])\n",
    "#     return np.char.rstrip(padded_strVec)\n",
    "\n",
    "# print(X_test[0])\n",
    "# X_x = str_vec_to_int_matrix(X_test.astype(str))\n",
    "# print(X_x[0])\n",
    "# X_y = int_matrix_to_str_vec(X_x)\n",
    "# print(X_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58228e9e-a643-4b73-a51a-ba3366793109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done converting data into FFNN format\n"
     ]
    }
   ],
   "source": [
    "# 3) use them both\n",
    "\n",
    "def convert_to_FFNN_format(Xr, Xe, yr, ye):\n",
    "    max_str_len_1 = np.max(np.char.str_len(Xr))\n",
    "    max_str_len_2 = np.max(np.char.str_len(Xe))\n",
    "    max_str_len = max(max_str_len_1, max_str_len_2)\n",
    "    Xr_rtn = str_vec_to_float_matrix(Xr, max_str_len)\n",
    "    Xe_rtn = str_vec_to_float_matrix(Xe, max_str_len)\n",
    "    return (Xr_rtn, \n",
    "            Xe_rtn,\n",
    "            str_labels_to_int_labels(yr, lang_codes), \n",
    "            str_labels_to_int_labels(ye, lang_codes))\n",
    "\n",
    "(X_tr_nn, X_te_nn, y_tr_nn, y_te_nn) = convert_to_FFNN_format(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"Done converting data into FFNN format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c436646e-e772-42a2-9b08-ba6d866aaecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 5577)\n",
      "(3000, 5577)\n"
     ]
    }
   ],
   "source": [
    "# print(X_tr_nn[0])\n",
    "# print(X_tr_nn[1])\n",
    "print(X_tr_nn.shape)\n",
    "print(X_te_nn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07b30fd7-52e8-4fec-8803-69c7e421ef36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 18:12:57.147556: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done importing Tensorflow Stuff\n"
     ]
    }
   ],
   "source": [
    "# Applying properly structured data to a basic FFNN\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.metrics import SparseCategoricalAccuracy\n",
    "\n",
    "print(\"Done importing Tensorflow Stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f025e6da-c3bf-47bb-a146-ab488730faf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make FFNN\n",
    "\n",
    "sample_length = X_tr_nn[0].shape[0]\n",
    "\n",
    "FFNN_model = Sequential([\n",
    "    Input((sample_length,)),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "FFNN_model.compile(optimizer=Adam(),\n",
    "                   loss=SparseCategoricalCrossentropy(), \n",
    "                   metrics=[SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a0f14b7-7541-4e8c-af62-cfb93a3dbe48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - loss: 2.3030 - sparse_categorical_accuracy: 0.0978\n",
      "\n",
      " 0 : \n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 2.3029 - sparse_categorical_accuracy: 0.1021\n",
      "\n",
      "Test accuracy: 0.0976666659116745 \n",
      "\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 2.3000 - sparse_categorical_accuracy: 0.1114\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 2.2829 - sparse_categorical_accuracy: 0.1372\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 2.2551 - sparse_categorical_accuracy: 0.1556\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 2.2272 - sparse_categorical_accuracy: 0.1620\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 2.1808 - sparse_categorical_accuracy: 0.1859\n",
      "\n",
      " 5 : \n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.9094 - sparse_categorical_accuracy: 0.1056\n",
      "\n",
      "Test accuracy: 0.09966666996479034 \n",
      "\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 2.1611 - sparse_categorical_accuracy: 0.1991\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 2.1110 - sparse_categorical_accuracy: 0.2171\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 2.0902 - sparse_categorical_accuracy: 0.2382\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 2.0500 - sparse_categorical_accuracy: 0.2589\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - loss: 2.0285 - sparse_categorical_accuracy: 0.2690\n",
      "\n",
      " 10 : \n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.6581 - sparse_categorical_accuracy: 0.1093\n",
      "\n",
      "Test accuracy: 0.10466666519641876 \n",
      "\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 2.0036 - sparse_categorical_accuracy: 0.2624\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 1.9840 - sparse_categorical_accuracy: 0.2805\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 1.9568 - sparse_categorical_accuracy: 0.2853\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 1.9356 - sparse_categorical_accuracy: 0.2995\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - loss: 1.9068 - sparse_categorical_accuracy: 0.3068\n",
      "\n",
      " 15 : \n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 7.3665 - sparse_categorical_accuracy: 0.1123\n",
      "\n",
      "Test accuracy: 0.10466666519641876 \n",
      "\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 1.8820 - sparse_categorical_accuracy: 0.3146\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 1.8589 - sparse_categorical_accuracy: 0.3261\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 1.8368 - sparse_categorical_accuracy: 0.3381\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - loss: 1.8027 - sparse_categorical_accuracy: 0.3524\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 1.7891 - sparse_categorical_accuracy: 0.3534\n",
      "\n",
      " 20 : \n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 10.2885 - sparse_categorical_accuracy: 0.1126\n",
      "\n",
      "Test accuracy: 0.10599999874830246 \n",
      "\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 1.7654 - sparse_categorical_accuracy: 0.3630\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 1.7507 - sparse_categorical_accuracy: 0.3702\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 1.7130 - sparse_categorical_accuracy: 0.3843\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 1.7098 - sparse_categorical_accuracy: 0.3788\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 1.6897 - sparse_categorical_accuracy: 0.3862\n",
      "\n",
      " 25 : \n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 14.6821 - sparse_categorical_accuracy: 0.1075\n",
      "\n",
      "Test accuracy: 0.10199999809265137 \n",
      "\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 1.6873 - sparse_categorical_accuracy: 0.3911\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 1.6563 - sparse_categorical_accuracy: 0.4120\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 1.6536 - sparse_categorical_accuracy: 0.3976\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 1.6207 - sparse_categorical_accuracy: 0.4014\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 1.6302 - sparse_categorical_accuracy: 0.4118\n",
      "\n",
      " 30 : \n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 17.9929 - sparse_categorical_accuracy: 0.1074\n",
      "\n",
      "Test accuracy: 0.10133333504199982 \n",
      "\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 1.5950 - sparse_categorical_accuracy: 0.4214\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 1.6013 - sparse_categorical_accuracy: 0.4176\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 1.5768 - sparse_categorical_accuracy: 0.4302\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 1.5228 - sparse_categorical_accuracy: 0.4579\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 1.5410 - sparse_categorical_accuracy: 0.4480\n",
      "\n",
      " 35 : \n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 21.0185 - sparse_categorical_accuracy: 0.1090\n",
      "\n",
      "Test accuracy: 0.10199999809265137 \n",
      "\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 1.5283 - sparse_categorical_accuracy: 0.4574\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - loss: 1.5363 - sparse_categorical_accuracy: 0.4462\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 1.5005 - sparse_categorical_accuracy: 0.4567\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 1.4800 - sparse_categorical_accuracy: 0.4709\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 1.4847 - sparse_categorical_accuracy: 0.4655\n",
      "\n",
      " 40 : \n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 22.5633 - sparse_categorical_accuracy: 0.1085\n",
      "\n",
      "Test accuracy: 0.10100000351667404 \n",
      "\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 1.4595 - sparse_categorical_accuracy: 0.4866\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 1.4786 - sparse_categorical_accuracy: 0.4722\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 1.4341 - sparse_categorical_accuracy: 0.4794\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 1.4575 - sparse_categorical_accuracy: 0.4784\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 1.4490 - sparse_categorical_accuracy: 0.4750\n",
      "\n",
      " 45 : \n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 26.7414 - sparse_categorical_accuracy: 0.1075\n",
      "\n",
      "Test accuracy: 0.10066666454076767 \n",
      "\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 1.4578 - sparse_categorical_accuracy: 0.4714\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 1.4288 - sparse_categorical_accuracy: 0.4952\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 1.4174 - sparse_categorical_accuracy: 0.5043\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 1.4225 - sparse_categorical_accuracy: 0.4811\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 1.3827 - sparse_categorical_accuracy: 0.5145\n",
      "\n",
      " 50 : \n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 29.4258 - sparse_categorical_accuracy: 0.1080\n",
      "\n",
      "Test accuracy: 0.1003333330154419 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(51):\n",
    "    FFNN_model.fit(X_tr_nn, y_tr_nn)\n",
    "    if (i%5 == 0):\n",
    "        print(\"\\n\", i, \": \")\n",
    "        test_loss, test_acc = FFNN_model.evaluate(X_te_nn, y_te_nn)\n",
    "        print(f'\\nTest accuracy: {test_acc}', \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25d6587-7706-4191-ad79-b6d21b15d836",
   "metadata": {},
   "source": [
    "The accuracy of this result is unexpectedly low. An accuracy of around 10% given that there are 10 labels implies that the model isn't making any accurate predictions at all. \n",
    "There are a few things we decided to try to boost its accuracy. First we decided to change how we normalized the data. The way the data is currently normalized converts each string into a row of characters, each character into an integer, and each integer into a floating point number between 0 and 1, based on the highest and lowest integer value for all the characters. This creates an uneven distribution of floating point numbers between 0 and 1, with most characters being represented as very low floaing point numbers (e.g. less than 0.01) and some being quite high (e.g. about 0.6). This is because most characters are simply the ascii values of the latin alphabet, which ranges from about 0 to 200, whereas some special characters are represented by numbers in the thousands when considering unicode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880cc54e-ce43-4463-8855-8f31e2faec39",
   "metadata": {},
   "source": [
    "To get around this uneven distribution, we will assign each character its own unique integer value, and divide by the total number of unique characters in all sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f4a15f4-19fd-4c76-95ed-12fb790de8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_vec_to_char_matrix(strVec, longest_str_len):\n",
    "    # Pad strings to all be equal length\n",
    "    padded_strVec = np.char.ljust(strVec, longest_str_len, fillchar=' ')\n",
    "\n",
    "    # turn vector of strings into matrix of characters\n",
    "    stacked_char_matrix = np.vstack([np.array(list(s)) for s in padded_strVec])\n",
    "    return stacked_char_matrix\n",
    "\n",
    "# This func takes a vector of strings and returns a vector of unique characters found in those string\n",
    "def alph_from_str_vec(strVec):\n",
    "    l = list(strVec)\n",
    "    bigString = \"\".join(l)\n",
    "    setOfChars = set(bigString)\n",
    "    return np.array(sorted(list(setOfChars)))\n",
    "\n",
    "# I tried without dictionaries before and it was way too slow\n",
    "def map_char_to_value(c_key, alph_dict):\n",
    "    return alph_dict[c_key]\n",
    "\n",
    "def str_vec_to_float_matrix__even_distribution(strVec, longest_str_len, alph_dict):\n",
    "    char_matrix =  str_vec_to_char_matrix(strVec, longest_str_len)\n",
    "\n",
    "    def map_char_to_value_vectorizable(c):\n",
    "        return map_char_to_value(c, alph_dict)\n",
    "        \n",
    "    map_chars_vectorized = np.vectorize(map_char_to_value_vectorizable)\n",
    "    rtn = map_chars_vectorized(char_matrix)\n",
    "\n",
    "    return rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d5cd1b9-3c7a-4acc-bfe3-8bb152af8379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_FFNN_format__even_distribution(Xr, Xe, yr, ye):\n",
    "    # Creating the right alphabet dictionary for data organization\n",
    "    alph_tr = set(alph_from_str_vec(Xr))\n",
    "    alph_te = set(alph_from_str_vec(Xe))\n",
    "    alph = np.array(sorted(list(alph_tr.union(alph_te))))\n",
    "    alphVals = np.arange(alph.shape[0]) / alph.shape[0]\n",
    "    alph_dict = {char: val for char, val in zip(alph, alphVals)}\n",
    "\n",
    "    # Max str len\n",
    "    max_str_len_1 = np.max(np.char.str_len(Xr))\n",
    "    max_str_len_2 = np.max(np.char.str_len(Xe))\n",
    "    max_str_len = max(max_str_len_1, max_str_len_2)\n",
    "\n",
    "    \n",
    "    Xr_rtn = str_vec_to_float_matrix__even_distribution(Xr, max_str_len, alph_dict)\n",
    "    Xe_rtn = str_vec_to_float_matrix__even_distribution(Xe, max_str_len, alph_dict)\n",
    "    return (Xr_rtn, \n",
    "            Xe_rtn,\n",
    "            str_labels_to_int_labels(yr, lang_codes), \n",
    "            str_labels_to_int_labels(ye, lang_codes))\n",
    "\n",
    "(X_tr_nn, X_te_nn, y_tr_nn, y_te_nn) = convert_to_FFNN_format__even_distribution(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb70aeac-659f-47d3-839a-d4b68d5b0859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-compile same model\n",
    "\n",
    "sample_length = X_tr_nn[0].shape[0]\n",
    "\n",
    "FFNN_model = Sequential([\n",
    "    Input((sample_length,)),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "FFNN_model.compile(optimizer=Adam(),\n",
    "                   loss=SparseCategoricalCrossentropy(), \n",
    "                   metrics=[SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f77eab10-4019-47a1-b840-c8379180c060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - loss: 2.3085 - sparse_categorical_accuracy: 0.1052\n",
      "\n",
      " 0 : \n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.3052 - sparse_categorical_accuracy: 0.1172\n",
      "\n",
      "Test accuracy: 0.11833333224058151 \n",
      "\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 2.2929 - sparse_categorical_accuracy: 0.1235\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 2.2913 - sparse_categorical_accuracy: 0.1207\n",
      "\u001b[1m146/219\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 2.2750 - sparse_categorical_accuracy: 0.1403"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Test same model\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m51\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     FFNN_model\u001b[38;5;241m.\u001b[39mfit(X_tr_nn, y_tr_nn)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/development/python/tools/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/development/python/tools/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/development/python/tools/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/development/python/tools/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/development/python/tools/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/development/python/tools/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/development/python/tools/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/development/python/tools/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/development/python/tools/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/development/python/tools/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1684\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1685\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1686\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1687\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1688\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1689\u001b[0m   )\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m~/development/python/tools/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test same model\n",
    "\n",
    "for i in range(51):\n",
    "    FFNN_model.fit(X_tr_nn, y_tr_nn)\n",
    "    if (i%5 == 0):\n",
    "        print(\"\\n\", i, \": \")\n",
    "        test_loss, test_acc = FFNN_model.evaluate(X_te_nn, y_te_nn)\n",
    "        print(f'\\nTest accuracy: {test_acc}', \"\\n\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784bde02-bf27-49dd-8e01-a9b66642a74a",
   "metadata": {},
   "source": [
    "This change did result in a visible improvement, but it still isn't very good, and it required quite a few epochs to improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155e831e-7932-461a-a221-e6714ae1f0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/x_train.txt: Read!\n",
      "Data/y_train.txt: Read!\n",
      "Data/x_test.txt: Read!\n",
      "Data/y_test.txt: Read!\n"
     ]
    }
   ],
   "source": [
    "# also testing the data with only 5 languages again\n",
    "lang_codes = ['ita', 'fra', 'spa', 'eng', 'ind']\n",
    "langs = ['Italian', 'French', 'Spanish', 'English', 'Indonesian']\n",
    "\n",
    "\n",
    "X, y = clean_filter_and_stack(\"Data/x_train.txt\", \n",
    "                                      \"Data/y_train.txt\", \n",
    "                                      \"Data/x_test.txt\", \n",
    "                                      \"Data/y_test.txt\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=17)\n",
    "\n",
    "(X_tr_nn, X_te_nn, y_tr_nn, y_te_nn) = convert_to_FFNN_format__even_distribution(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2204db93-01d4-4fa6-957a-c0de6d1a4024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-compile same model\n",
    "\n",
    "sample_length = X_tr_nn[0].shape[0]\n",
    "\n",
    "FFNN_model = Sequential([\n",
    "    Input((sample_length,)),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "FFNN_model.compile(optimizer=Adam(),\n",
    "                   loss=SparseCategoricalCrossentropy(), \n",
    "                   metrics=[SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3ee08b-a62e-407b-bb17-40b2b2d8ce57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 2s 13ms/step - loss: 1.6749 - sparse_categorical_accuracy: 0.2191\n",
      "\n",
      " 0 : \n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.6733 - sparse_categorical_accuracy: 0.2340\n",
      "\n",
      "Test accuracy: 0.23399999737739563 \n",
      "\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 1.6000 - sparse_categorical_accuracy: 0.2494\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 1.5696 - sparse_categorical_accuracy: 0.2823\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 1.5337 - sparse_categorical_accuracy: 0.3220\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 1.4702 - sparse_categorical_accuracy: 0.3571\n",
      "110/110 [==============================] - 1s 13ms/step - loss: 1.4172 - sparse_categorical_accuracy: 0.4037\n",
      "\n",
      " 5 : \n",
      "47/47 [==============================] - 0s 8ms/step - loss: 1.6647 - sparse_categorical_accuracy: 0.2567\n",
      "\n",
      "Test accuracy: 0.2566666603088379 \n",
      "\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 1.3562 - sparse_categorical_accuracy: 0.4294\n",
      "110/110 [==============================] - 2s 16ms/step - loss: 1.2836 - sparse_categorical_accuracy: 0.4714\n",
      "110/110 [==============================] - 2s 16ms/step - loss: 1.2746 - sparse_categorical_accuracy: 0.4666\n",
      "110/110 [==============================] - 2s 19ms/step - loss: 1.1965 - sparse_categorical_accuracy: 0.5186\n",
      "110/110 [==============================] - 1s 13ms/step - loss: 1.1637 - sparse_categorical_accuracy: 0.5283\n",
      "\n",
      " 10 : \n",
      "47/47 [==============================] - 0s 7ms/step - loss: 1.8804 - sparse_categorical_accuracy: 0.2693\n",
      "\n",
      "Test accuracy: 0.2693333327770233 \n",
      "\n",
      "110/110 [==============================] - 2s 14ms/step - loss: 1.1315 - sparse_categorical_accuracy: 0.5417\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 1.0836 - sparse_categorical_accuracy: 0.5709\n",
      "110/110 [==============================] - 1s 13ms/step - loss: 1.0432 - sparse_categorical_accuracy: 0.5914\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 1.0200 - sparse_categorical_accuracy: 0.5943\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 0.9738 - sparse_categorical_accuracy: 0.6237\n",
      "\n",
      " 15 : \n",
      "47/47 [==============================] - 0s 9ms/step - loss: 2.1114 - sparse_categorical_accuracy: 0.2787\n",
      "\n",
      "Test accuracy: 0.2786666750907898 \n",
      "\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 0.9177 - sparse_categorical_accuracy: 0.6471\n",
      "110/110 [==============================] - 2s 16ms/step - loss: 0.8957 - sparse_categorical_accuracy: 0.6586\n",
      "110/110 [==============================] - 2s 18ms/step - loss: 0.8418 - sparse_categorical_accuracy: 0.6769\n",
      "110/110 [==============================] - 2s 16ms/step - loss: 0.8140 - sparse_categorical_accuracy: 0.6786\n",
      "110/110 [==============================] - 1s 14ms/step - loss: 0.7574 - sparse_categorical_accuracy: 0.7160\n",
      "\n",
      " 20 : \n",
      "47/47 [==============================] - 0s 7ms/step - loss: 2.4945 - sparse_categorical_accuracy: 0.2627\n",
      "\n",
      "Test accuracy: 0.2626666724681854 \n",
      "\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 0.7270 - sparse_categorical_accuracy: 0.7257\n",
      "110/110 [==============================] - 2s 14ms/step - loss: 0.7031 - sparse_categorical_accuracy: 0.7334\n",
      "110/110 [==============================] - 2s 14ms/step - loss: 0.6416 - sparse_categorical_accuracy: 0.7663\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 0.6470 - sparse_categorical_accuracy: 0.7703\n",
      "110/110 [==============================] - 2s 14ms/step - loss: 0.6738 - sparse_categorical_accuracy: 0.7660\n",
      "\n",
      " 25 : \n",
      "47/47 [==============================] - 0s 8ms/step - loss: 2.8343 - sparse_categorical_accuracy: 0.2807\n",
      "\n",
      "Test accuracy: 0.28066667914390564 \n",
      "\n",
      "110/110 [==============================] - 2s 14ms/step - loss: 0.5418 - sparse_categorical_accuracy: 0.8160\n",
      "110/110 [==============================] - 2s 14ms/step - loss: 0.4681 - sparse_categorical_accuracy: 0.8446\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.4276 - sparse_categorical_accuracy: 0.8614\n",
      "110/110 [==============================] - 2s 14ms/step - loss: 0.3924 - sparse_categorical_accuracy: 0.8731\n",
      "110/110 [==============================] - 2s 14ms/step - loss: 0.3363 - sparse_categorical_accuracy: 0.8986\n",
      "\n",
      " 30 : \n",
      "47/47 [==============================] - 0s 6ms/step - loss: 3.8069 - sparse_categorical_accuracy: 0.2593\n",
      "\n",
      "Test accuracy: 0.2593333423137665 \n",
      "\n",
      " 57/110 [==============>...............] - ETA: 0s - loss: 0.2972 - sparse_categorical_accuracy: 0.9172"
     ]
    }
   ],
   "source": [
    "# Test same model\n",
    "\n",
    "for i in range(51):\n",
    "    FFNN_model.fit(X_tr_nn, y_tr_nn)\n",
    "    if (i%5 == 0):\n",
    "        print(\"\\n\", i, \": \")\n",
    "        test_loss, test_acc = FFNN_model.evaluate(X_te_nn, y_te_nn)\n",
    "        print(f'\\nTest accuracy: {test_acc}', \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9328c219-0ec2-42b5-8545-ccaac4ae53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_codes = ['ita', 'fra', 'spa', 'por', 'eng', 'deu', 'nld', 'ind', 'fin', 'hau']\n",
    "langs = ['Italian', 'French', 'Spanish', 'Portuguese', 'English', 'German', 'Dutch', 'Indonesian', 'Finnish', 'Hausa']\n",
    "\n",
    "X, y = clean_filter_and_stack(\"Data/x_train.txt\", \n",
    "                                      \"Data/y_train.txt\", \n",
    "                                      \"Data/x_test.txt\", \n",
    "                                      \"Data/y_test.txt\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=17)\n",
    "\n",
    "(X_tr_nn, X_te_nn, y_tr_nn, y_te_nn) = convert_to_FFNN_format__even_distribution(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5baf5f3-279d-4e04-ae16-0a03bff8016b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00393a1-f721-4da8-8037-dfd3e8887cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b565d1-c355-4e0a-b959-b15873e31084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
