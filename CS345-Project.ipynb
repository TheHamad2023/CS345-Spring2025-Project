{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e86e4561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: Read with tabs\n",
      "y: Read with commas\n",
      "Null found\n",
      "X: Read with tabs\n",
      "y: Read with commas\n",
      "Null found\n"
     ]
    }
   ],
   "source": [
    "#Understanding the data set\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def inspect_x_test(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"Read with commas\")\n",
    "    except pd.errors.ParserError:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, delimiter='\\t')\n",
    "            print(\"Read with tabs\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading the .txt file: {e}\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the file: {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"Data Preview:\")\n",
    "    print(f\"Number of rows (samples): {df.shape[0]}\")\n",
    "    print(f\"Number of columns (features): {df.shape[1]}\")\n",
    "    print(\"\\nColumn names:\")\n",
    "    print(df.columns.tolist())\n",
    "\n",
    "# inspect_x_test(\"Data/x_test.txt\")\n",
    "# inspect_x_test(\"Data/y_test.txt\")\n",
    "\n",
    "\n",
    "def preview_large_csv(file_path, num_lines=20, delimiter=','):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, delimiter=delimiter, nrows=num_lines)\n",
    "        print(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading preview: {e}\")\n",
    "\n",
    "# preview_large_csv(\"Data/x_test.txt\", delimiter='\\t')\n",
    "\n",
    "def check_nulls_in_data(x_file_path, y_file_path):\n",
    "    def read_file_smart(path, label):\n",
    "        try:\n",
    "            df = pd.read_csv(path)\n",
    "            print(f\"{label}: Read with commas\")\n",
    "        except pd.errors.ParserError:\n",
    "            try:\n",
    "                df = pd.read_csv(path, delimiter='\\t')\n",
    "                print(f\"{label}: Read with tabs\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading the {label} file: {e}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading the {label} file: {e}\")\n",
    "            return None\n",
    "        return df\n",
    "\n",
    "    X = read_file_smart(x_file_path, \"X\")\n",
    "    y = read_file_smart(y_file_path, \"y\")\n",
    "\n",
    "    if X is None or y is None:\n",
    "        return\n",
    "\n",
    "    if X.isnull().values.any() or y.isnull().values.any():\n",
    "        print(\"Null found\")\n",
    "    else:\n",
    "        print(\"No nulls found\")\n",
    "\n",
    "check_nulls_in_data('Data/x_test.txt', 'Data/y_test.txt')\n",
    "check_nulls_in_data('Data/x_train.txt', 'Data/y_train.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257857a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to preprocess the data\n",
    "def preprocessXandY(X, y):\n",
    "    lang_codes = ['ita', 'fra', 'eng', 'ind', 'spa'] #lang codes of what we will use Italian, French, English, Indonesian, Spanish\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7602a789-a084-4f24-b977-47df8039c2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/x_train.txt: Read each line into row\n",
      "Data/y_train.txt: Read each line into row\n",
      "(117500, 2)\n",
      "(117000, 2)\n",
      "(2500, 2)\n",
      "Data/x_test.txt: Read each line into row\n",
      "Data/y_test.txt: Read each line into row\n",
      "(117500, 2)\n",
      "(117000, 2)\n",
      "(2500, 2)\n",
      "(5000,) (5000,)\n",
      "ind\n"
     ]
    }
   ],
   "source": [
    "#Understanding the data set\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def file_to_np_array(path, label):\n",
    "    try:\n",
    "        df = pd.read_csv(path, sep='<NonExistenceSeparator>', header=None, engine='python')\n",
    "        print(f\"{label}: Read each line into row\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the {label} file: {e}\")\n",
    "        return None\n",
    "    return df.to_numpy()\n",
    "\n",
    "\n",
    "def clean_np_data(X, y):\n",
    "    stacked = np.hstack((y, X)) # Stack y and X side by side\n",
    "    print(stacked.shape)\n",
    "    clean_stacked = stacked[~np.any(pd.isna(stacked), axis=1), :] # Remove empty values\n",
    "    print(clean_stacked.shape)\n",
    "    lang_codes = ['ita', 'fra', 'eng', 'ind', 'spa']\n",
    "    true_clean = clean_stacked[np.isin(clean_stacked[:,0], lang_codes),:] # Remove all rows that aren't our target languages\n",
    "    print(true_clean.shape)\n",
    "    return true_clean[:,1], true_clean[:,0] # Return cleaned as X and y split again\n",
    "\n",
    "def clean_filter_and_stack(X1_file, y1_file, X2_file, y2_file):\n",
    "    X1_clean, y1_clean = clean_np_data(file_to_np_array(X1_file, X1_file), \n",
    "                                       file_to_np_array(y1_file, y1_file))\n",
    "    X2_clean, y2_clean = clean_np_data(file_to_np_array(X2_file, X2_file), \n",
    "                                       file_to_np_array(y2_file, y2_file))\n",
    "    return np.hstack((X1_clean, X2_clean)), np.hstack((y1_clean, y2_clean))\n",
    "\n",
    "X_all, y_all = clean_filter_and_stack(\"Data/x_train.txt\", \n",
    "                                      \"Data/y_train.txt\", \n",
    "                                      \"Data/x_test.txt\", \n",
    "                                      \"Data/y_test.txt\")\n",
    "\n",
    "print(X_all.shape, y_all.shape)\n",
    "print(y_all[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60b758fc-1a04-4cc4-8c94-9c6034e4ca00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500,) (3500,)\n",
      "(1500,) (1500,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X_all, y_all, test_size=0.3, random_state=17)\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_te.shape, y_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5925257-f51e-452b-be5b-7a4dede72735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done vectorizing\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(strip_accents='unicode')\n",
    "X_tr_vectors = vectorizer.fit_transform(X_tr)\n",
    "X_te_vectors = vectorizer.transform(X_te)\n",
    "print(\"Done vectorizing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb703257-141d-403f-a819-31553f0ccde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training MNB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_tr_vectors, y_tr)\n",
    "print(\"Done training MNB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8e9320b-e9e6-4217-8dc6-e068913a34f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9893333333333333\n",
      "['fra' 'fra' 'ind' 'ind' 'spa' 'spa' 'ita' 'eng' 'ita' 'eng']\n",
      "['Les magnolias ou magnoliers (Magnolia L., 1753) forment un genre de plantes à fleurs, de la famille des magnoliacées, qui comprend environ cent dix espèces, essentiellement des arbres et arbustes, des régions tempérées chaudes.'\n",
      " 'Honoré Beaugrand, fils de Louis Beaugrand, dit Champagne, navigateur, et de Marie-Josephte (Joséphine) Marion, est l’aîné des fils d’une famille qui comptera six enfants (3 garçons et 3 filles).'\n",
      " 'Sesudah itu, masih juga terdapat penyerangan-penyerangan, seperti ke Avignon (tahun 734), ke Lyon (tahun 743), dan pulau-pulau yang terdapat di Laut Tengah, Mallorca, Korsika, Sardegna, Kreta, Rhodos, Siprus dan sebagian dari Sisilia juga jatuh ke tangan Islam pada zaman Bani Umayyah. Gelombang kedua terbesar dari penyerbuan kaum Muslimin yang geraknya dimulai pada permulaan abad ke-8 M ini, telah menjangkau seluruh Spanyol dan melebar jauh menjangkau Perancis Tengah dan bagian-bagian penting dari Italia.'\n",
      " 'Paspor ini berisi 24 atau 48 halaman dan berlaku selama 5 tahun. Namun paspor yang diterbitkan oleh perwakilan RI di luar negeri lazimnya menerbitkan paspor dengan jangka waktu 3 tahun dan dapat diperpanjang 2 tahun setelahnya.'\n",
      " 'Estableció las bases de la historia moderna de la cultura portuguesa, que alcanzó gran proyección nacional, especialmente a través de los textos dedicados a Platón, Hegel, Husserl y especialmente, Baruch Spinoza, de quien se convirtió en un experto de renombre internacional.'\n",
      " 'Uno puede encontrar más epítetos en la alabanza de este artículo que Turguénev una vez ensambló para elogiar la lengua rusa, o Nekrásov para alabar a la madre Rusia: grande, poderoso, abundante, altamente ramificado, multiforme, de barrido amplio 58, que resumía el mundo no tanto a través de los términos exactos de sus secciones como en su extendida interpretación dialéctica.'\n",
      " 'Il 9 luglio 1998 muore Aldo Stellita: fondatore, bassista e autore della maggior parte dei testi delle canzoni del gruppo. Pochi mesi dopo anche Laura Valente e Sergio Cossu lasciano definitivamente il gruppo; queste uscite determinano la temporanea \"fine\" dei Matia Bazar dopo la scomparsa di Aldo.'\n",
      " 'Hamilton has been the primary songwriter, guitarist, and vocalist for Brothers Past, as well as co-producer for all of their recorded releases.'\n",
      " 'Ernst Theodor Amadeus Hoffmann, meglio noto come E. T. A. Hoffmann (Königsberg, 24 gennaio 1776 – Berlino, 25 giugno 1822), è stato uno scrittore, compositore, pittore e giurista tedesco, esponente del Romanticismo.'\n",
      " 'At about the same time as the AT&T Building, Johnson and Burgee completed other remarkable postmodern skyscrapers; the Bank of America Center (Formerly Republic Bank Center) in Houston (1983) and the PPG Place, the headquarters of the Pittsburgh Plate Glass company (1979–84). Both buildings combined modern materials, construction and scale with suggestions of traditional architecture. The forms of PPG Place suggested the neogothic tower of the Houses of Parliament in London, while the Bank of America Center appeared inspired, on a colossal scale, the stepped houses of Flemish Renaissance architecture.']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_te_vectors)\n",
    "accuracy = accuracy_score(y_te, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(y_pred[0:10])\n",
    "print(X_te[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f966d3e-57e4-4b15-9897-32ca8d142f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
