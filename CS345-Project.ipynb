{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e86e4561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: Read with tabs\n",
      "y: Read with commas\n",
      "Null found\n",
      "X: Read with tabs\n",
      "y: Read with commas\n",
      "Null found\n"
     ]
    }
   ],
   "source": [
    "#Understanding the data set\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def inspect_x_test(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"Read with commas\")\n",
    "    except pd.errors.ParserError:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, delimiter='\\t')\n",
    "            print(\"Read with tabs\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading the .txt file: {e}\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the file: {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"Data Preview:\")\n",
    "    print(f\"Number of rows (samples): {df.shape[0]}\")\n",
    "    print(f\"Number of columns (features): {df.shape[1]}\")\n",
    "    print(\"\\nColumn names:\")\n",
    "    print(df.columns.tolist())\n",
    "\n",
    "# inspect_x_test(\"Data/x_test.txt\")\n",
    "# inspect_x_test(\"Data/y_test.txt\")\n",
    "\n",
    "\n",
    "def preview_large_csv(file_path, num_lines=20, delimiter=','):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, delimiter=delimiter, nrows=num_lines)\n",
    "        print(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading preview: {e}\")\n",
    "\n",
    "# preview_large_csv(\"Data/x_test.txt\", delimiter='\\t')\n",
    "\n",
    "def check_nulls_in_data(x_file_path, y_file_path):\n",
    "    def read_file_smart(path, label):\n",
    "        try:\n",
    "            df = pd.read_csv(path)\n",
    "            print(f\"{label}: Read with commas\")\n",
    "        except pd.errors.ParserError:\n",
    "            try:\n",
    "                df = pd.read_csv(path, delimiter='\\t')\n",
    "                print(f\"{label}: Read with tabs\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading the {label} file: {e}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading the {label} file: {e}\")\n",
    "            return None\n",
    "        return df\n",
    "\n",
    "    X = read_file_smart(x_file_path, \"X\")\n",
    "    y = read_file_smart(y_file_path, \"y\")\n",
    "\n",
    "    if X is None or y is None:\n",
    "        return\n",
    "\n",
    "    if X.isnull().values.any() or y.isnull().values.any():\n",
    "        print(\"Null found\")\n",
    "    else:\n",
    "        print(\"No nulls found\")\n",
    "\n",
    "check_nulls_in_data('Data/x_test.txt', 'Data/y_test.txt')\n",
    "check_nulls_in_data('Data/x_train.txt', 'Data/y_train.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257857a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to preprocess the data\n",
    "def preprocessXandY(X, y):\n",
    "    lang_codes = ['ita', 'fra', 'eng', 'ind', 'spa'] #lang codes of what we will use Italian, French, English, Indonesian, Spanish\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7602a789-a084-4f24-b977-47df8039c2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/x_train.txt: Read each line into row\n",
      "Data/y_train.txt: Read each line into row\n",
      "(117500, 2)\n",
      "(117000, 2)\n",
      "(15500, 2)\n",
      "Data/x_test.txt: Read each line into row\n",
      "Data/y_test.txt: Read each line into row\n",
      "(117500, 2)\n",
      "(117000, 2)\n",
      "(15500, 2)\n"
     ]
    }
   ],
   "source": [
    "#Understanding the data set\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def file_to_np_array(path, label):\n",
    "    try:\n",
    "        df = pd.read_csv(path, sep='<NonExistenceSeparator>', header=None, engine='python')\n",
    "        print(f\"{label}: Read each line into row\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the {label} file: {e}\")\n",
    "        return None\n",
    "    return df.to_numpy()\n",
    "\n",
    "\n",
    "def clean_np_data(X, y):\n",
    "    stacked = np.hstack((y, X)) # Stack y and X side by side\n",
    "    print(stacked.shape)\n",
    "    clean_stacked = stacked[~np.any(pd.isna(stacked), axis=1), :] # Remove empty values\n",
    "    print(clean_stacked.shape)\n",
    "    lang_codes = ['ita', 'fra', 'eng', 'ind', 'spa', 'lat', 'ron', 'por', 'pol', 'swe', 'vie', 'war', 'rup','nld', \n",
    "                  'deu', 'ces', 'aze', 'cat', 'ceb', 'fin', 'hau', 'ibo', 'jbo', 'kin', 'kur', 'lug', 'nob', 'orm', 'ton'\n",
    "                  ,'tsn', 'xho']\n",
    "    true_clean = clean_stacked[np.isin(clean_stacked[:,0], lang_codes),:] # Remove all rows that aren't our target languages\n",
    "    print(true_clean.shape)\n",
    "    return true_clean[:,1], true_clean[:,0] # Return cleaned as X and y split again\n",
    "\n",
    "def clean_filter_and_stack(X1_file, y1_file, X2_file, y2_file):\n",
    "    X1_clean, y1_clean = clean_np_data(file_to_np_array(X1_file, X1_file), \n",
    "                                       file_to_np_array(y1_file, y1_file))\n",
    "    X2_clean, y2_clean = clean_np_data(file_to_np_array(X2_file, X2_file), \n",
    "                                       file_to_np_array(y2_file, y2_file))\n",
    "    # return np.hstack((X1_clean, X2_clean)), np.hstack((y1_clean, y2_clean))\n",
    "    return X1_clean, y1_clean, X2_clean, y2_clean\n",
    "\n",
    "X_train, y_train, X_test, y_test = clean_filter_and_stack(\"Data/x_train.txt\", \n",
    "                                      \"Data/y_train.txt\", \n",
    "                                      \"Data/x_test.txt\", \n",
    "                                      \"Data/y_test.txt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60b758fc-1a04-4cc4-8c94-9c6034e4ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# X_tr, X_te, y_tr, y_te = train_test_split(X_all, y_all, test_size=0.3, random_state=17)\n",
    "# print(X_tr.shape, y_tr.shape)\n",
    "# print(X_te.shape, y_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5925257-f51e-452b-be5b-7a4dede72735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done vectorizing\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(strip_accents='unicode')\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "X_test_vectors = vectorizer.transform(X_test)\n",
    "print(\"Done vectorizing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb703257-141d-403f-a819-31553f0ccde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training MNB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vectors, y_train)\n",
    "print(\"Done training MNB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e9320b-e9e6-4217-8dc6-e068913a34f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9712258064516129\n",
      "['nld' 'ind' 'eng' 'cat' 'tsn' 'fin' 'kur' 'orm' 'nob' 'spa' 'rup' 'fra'\n",
      " 'nob' 'eng' 'cat' 'ind' 'ind' 'tsn' 'rup' 'orm' 'fra' 'aze' 'lug' 'rup'\n",
      " 'cat' 'ita' 'nob' 'hau']\n",
      "['Schiedam is gelegen tussen Rotterdam en Vlaardingen, oorspronkelijk aan de Schie en later ook aan de Nieuwe Maas. Per 30 april 2017 had de gemeente 77.833 inwoners (bron: CBS). De stad is vooral bekend om haar jenever, de historische binnenstad met grachten, en de hoogste windmolens ter wereld.'\n",
      " 'Argentina adalah sebuah negara yang kaya dengan SDA, tingkat melek huruf yang tinggi, sektor pertanian yang maju serta industri yang beragam. Malangnya, sejak akhir 1980-an negara ini telah menimbun hutang luar negeri yang tinggi, inflasi sampai 200% sebulan, dan pengeluaran yang merudum. Dalam mengatasi krisis ekonomi tersebut, pemerintahan telah mengambil langkah-langkah seperti liberalisasi perdagangan, deregulasi, dan swastanisasi. Pada 1991, pemerintahan telah melaksanakan reformasi finansial yang radikal dengan mematok peso kepada dolar AS dan mencanangkan pertumbuhan keuangan untuk perlindungan moneter secara undang-undang.'\n",
      " 'The strategic leader fills the gap between the need for new possibility and the need for practicality by providing a prescriptive set of habits.'\n",
      " 'Pertany a la família dels CFC i també es pot anomenar Freon-113 o CFC-113. La seva fórmula és Cl2FC-CClF2 És el tercer clorofluorocarbur més utilitzat en el llarg de la història a més del CFC-11 i el CFC-12.'\n",
      " 'Molawana wa 1959, Extension of Universities Act of 1959, e dirile tlamelo ya pharologanyo ya diunibesiti go ya ka pharologano ya merafe. Go tlaleletsa se, dinagamagae tse di ikemetseng di filwe diunibesithi tsa tsona. Morago ga pusetso gape ya dinagamagae tse di ikemetseng, go ne go na le diunibesithi le dithekhinikhono tse di 36 mo Aforika Borwa, go le gontsi di kgaufi-kgaufi ebile di abelana ka dithuto tse di tshwanang.'\n",
      " 'Carol Oskar Eugen Lindroos (29. toukokuuta 1930 Pohja – 9. joulukuuta 2001 Helsinki) oli suomalainen kiekonheittäjä. Hän voitti kiekon Suomen mestaruuden vuosina 1953, 1954, 1955, 1957, 1958 ja 1961. Hopealla hän oli vuosina 1962 ja 1964 sekä pronssilla 1959, 1960 ja 1963.'\n",
      " 'Seyîd Evdilqadir (z. 1851 Colemêrg - m. 1925 Bedlîs) siyasetmedar û alimekî kurd bû, Kurrê Şêx Ubeydelayê Nehrî bû. Di serhildana Şêx Seîd de ew jî weke Salih Begê Hênê û 47 hevalê xwe hatiye dardekirin.'\n",
      " \"Erga Hirooshimaa fi Nagaasaakin rukutamanii booda, meeshaalen waraanaa niwuukilaaraa wayita kuma lamaa ol yaalii fi agarsiisaaf dhukaafamaniiru. Addunyaarratti biyyoota muraasa qofatu meeshaa waraanaa niwuukilaaraa kana qaba ykn qabaachuuf hawwa. Biyyoonni meeshaa kana dhukaasuun isaanii beekkamee fi qabaachuu isaani ifa baasanii beeksisan USA, Tokkummaa Sooviyeetii (ammammoo Raashiyaa), Yunaayitid Kingidem, Firaansi, Chaayinaa, Indiyaa, Paakistaan, fi Kooriyaa Kaabaati. Isiraa'eel meeshaa kana qabdi jedhamee kan amanamu yoo ta'u biyyittiin garuu qabaachuu ishii ifatti hin beeksifne. Afrikaan Kibbaa, meeshaa waraanaa niwuukilaaraa kana oomishtee kan turte yoo ta'u erga sirni appaartaayidii kufee booda meeshaa kan balleessitee jirti, itti aansunis waliigaltee meeshaalen niwuukilaaraa akka hin baballanne godhu kan 'Nuclear Non-Proliferation Treaty' jedhamu keessatti miseensa taateerti. Akka Federeeshinii saayintistoota Ameerikaa tilmaametti, walumaagalatti addunyaarra bara 2012tti meeshaalen niwuukilaaraa 17,000 ta'u kan argamu yoo ta'u kana keessaa kan 4,300 ta'an waraanaaf qophii ta'anii kan taa'anidha.\"\n",
      " 'Gârleșteanu vant en olympisk bronsemedalje i rugby union under Sommer-OL 1924 i Antwerpen. Han var med på det rumenske laget som kom på tredjeplass i rugbyturneringen bak USA og Frankrike. Det var kun tre lag som deltok og kampene ble spilt i perioden 4. til 17. mai 1924. Romania tapte begge sine kamper, 3-59 mot Frankrike og 0-39 mot USA.'\n",
      " 'La ciudad de San Cristóbal es sede del Hospital General Docente \"Comandante Pinares\". Con más de 400 camas, este moderno Hospital brinda servicios a todo el oeste de la Provincia de Artemisa.']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test_vectors)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(np.unique(y_pred))\n",
    "print(X_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f966d3e-57e4-4b15-9897-32ca8d142f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
