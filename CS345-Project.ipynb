{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4315aa3e",
   "metadata": {},
   "source": [
    "# CS345 Project\n",
    "\n",
    "## Team Members\n",
    "1. Hamad Alyami\n",
    "2. Benito Encarnacion\n",
    "\n",
    "## Dataset\n",
    "Our dataset was from Kaggle by a user called Mexwell. The data is paragraphs scraped from wikipedia in 2018 in 235 languages.\n",
    "\n",
    "The dataset contains 235,000 datasets with balance between language proportions and a test and train split provided.\n",
    "\n",
    "The downloaded folder from Kaggle contains:\n",
    "- labels.csv: A file containing the language name, 2-3 letter code, German name, and language family of all the languages present in the dataset.\n",
    "- README.txt: A file explaining the folder contents.\n",
    "- urls.txt: A file containing the urls of where the paragraphs were found.\n",
    "- x_test.txt: The testing data samples, paragraphs in multiple languages.\n",
    "- x_train.txt: The training data samples, paragraphs in multiple langauges\n",
    "- y_test.txt: The labels for the testing dataset, using the 2-3 letter codes found in labels.csv.\n",
    "- y_train.txt: The labels for the training dataset, using the 2-3 letter codes found in labels.csv\n",
    "\n",
    "\n",
    "## Project\n",
    "Our project is to train and compare two ML models on the Latin Alphabet languages present in the dataset and compare their performance.\n",
    "\n",
    "## Motivation\n",
    "We decided to do this project because it allows us to explore practical applications of natural language processing and machine learning by working with real-world multilingual data. Language identification is an important task in many systems and applications like search engines, translation tools, and content moderation. Working with such a dataset gives us the opportunity to apply classification techniques in a meaningful way. By focusing on languages that use the Latin alphabet, we avoid complications from different writing systems while still working with a variety of languages.\n",
    "\n",
    "## Models\n",
    "The models we decided to work with in this project are:\n",
    "- Multinomial Naive-Bayes (MNB): Uses word frequencies in each class, langauges in our case, to guess the most likely class for text it has not seen.\n",
    "\n",
    "- Feed Forward Neural Network (FNN): An artificial Neural Network where information moves from input to output without looping back. It uses neurons, connected nodes, to learn patterns and make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1704ce66",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "We will begin by reading the data from the files then:\n",
    "1. Remove Null Values\n",
    "2. Filter to keep texts of languages we want using the 2-3 letter codes\n",
    "3. Return both samples from x_test and x_train and labels from y_test and y_train stacked into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7602a789-a084-4f24-b977-47df8039c2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/x_train.txt: Read!\n",
      "Data/y_train.txt: Read!\n",
      "Data/x_test.txt: Read!\n",
      "Data/y_test.txt: Read!\n",
      "(5000,) (5000,)\n"
     ]
    }
   ],
   "source": [
    "#Understanding the data set\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def file_to_np_array(path, label):\n",
    "    try:\n",
    "        df = pd.read_csv(path, sep='<NonExistenceSeparator>', header=None, engine='python')\n",
    "        print(f\"{label}: Read!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the {label} file: {e}\")\n",
    "        return None\n",
    "    return df.to_numpy()\n",
    "\n",
    "\n",
    "def clean_np_data(X, y):\n",
    "    stacked = np.hstack((y, X)) # Stack y and X side by side\n",
    "    # print(stacked.shape)\n",
    "    clean_stacked = stacked[~np.any(pd.isna(stacked), axis=1), :] # Remove empty values\n",
    "    # print(clean_stacked.shape)\n",
    "    lang_codes = ['ita', 'fra', 'eng', 'ind', 'spa']\n",
    "    true_clean = clean_stacked[np.isin(clean_stacked[:,0], lang_codes),:] # Remove all rows that aren't our target languages\n",
    "    # print(true_clean.shape)\n",
    "    return true_clean[:,1], true_clean[:,0] # Return cleaned as X and y split again\n",
    "\n",
    "def clean_filter_and_stack(X_train_file, y_train_file, X_test_file, y_test_file):\n",
    "    X_train_clean, y_train_clean = clean_np_data(file_to_np_array(X_train_file, X_train_file), \n",
    "                                       file_to_np_array(y_train_file, y_train_file))\n",
    "    X_test_clean, y_test_clean = clean_np_data(file_to_np_array(X_test_file, X_test_file), \n",
    "                                       file_to_np_array(y_test_file, y_test_file))\n",
    "    return np.hstack((X_train_clean, X_test_clean)), np.hstack((y_train_clean, y_test_clean))\n",
    "\n",
    "X, y = clean_filter_and_stack(\"Data/x_train.txt\", \n",
    "                                      \"Data/y_train.txt\", \n",
    "                                      \"Data/x_test.txt\", \n",
    "                                      \"Data/y_test.txt\")\n",
    "\n",
    "print(X.shape, y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a7d528",
   "metadata": {},
   "source": [
    "#### Data Split\n",
    "Here we use Sklearn train_test_split to split our data into 70/30 train and test splits, respectively, after shuffling them randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b758fc-1a04-4cc4-8c94-9c6034e4ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=17)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5925257-f51e-452b-be5b-7a4dede72735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done vectorizing\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(strip_accents='unicode')\n",
    "X_tr_vectors = vectorizer.fit_transform(X_train)\n",
    "X_te_vectors = vectorizer.transform(X_test)\n",
    "print(\"Done vectorizing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb703257-141d-403f-a819-31553f0ccde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training MNB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_tr_vectors, y_train)\n",
    "print(\"Done training MNB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e9320b-e9e6-4217-8dc6-e068913a34f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9712258064516129\n",
      "['nld' 'ind' 'eng' 'cat' 'tsn' 'fin' 'kur' 'orm' 'nob' 'spa' 'rup' 'fra'\n",
      " 'nob' 'eng' 'cat' 'ind' 'ind' 'tsn' 'rup' 'orm' 'fra' 'aze' 'lug' 'rup'\n",
      " 'cat' 'ita' 'nob' 'hau']\n",
      "['Schiedam is gelegen tussen Rotterdam en Vlaardingen, oorspronkelijk aan de Schie en later ook aan de Nieuwe Maas. Per 30 april 2017 had de gemeente 77.833 inwoners (bron: CBS). De stad is vooral bekend om haar jenever, de historische binnenstad met grachten, en de hoogste windmolens ter wereld.'\n",
      " 'Argentina adalah sebuah negara yang kaya dengan SDA, tingkat melek huruf yang tinggi, sektor pertanian yang maju serta industri yang beragam. Malangnya, sejak akhir 1980-an negara ini telah menimbun hutang luar negeri yang tinggi, inflasi sampai 200% sebulan, dan pengeluaran yang merudum. Dalam mengatasi krisis ekonomi tersebut, pemerintahan telah mengambil langkah-langkah seperti liberalisasi perdagangan, deregulasi, dan swastanisasi. Pada 1991, pemerintahan telah melaksanakan reformasi finansial yang radikal dengan mematok peso kepada dolar AS dan mencanangkan pertumbuhan keuangan untuk perlindungan moneter secara undang-undang.'\n",
      " 'The strategic leader fills the gap between the need for new possibility and the need for practicality by providing a prescriptive set of habits.'\n",
      " 'Pertany a la família dels CFC i també es pot anomenar Freon-113 o CFC-113. La seva fórmula és Cl2FC-CClF2 És el tercer clorofluorocarbur més utilitzat en el llarg de la història a més del CFC-11 i el CFC-12.'\n",
      " 'Molawana wa 1959, Extension of Universities Act of 1959, e dirile tlamelo ya pharologanyo ya diunibesiti go ya ka pharologano ya merafe. Go tlaleletsa se, dinagamagae tse di ikemetseng di filwe diunibesithi tsa tsona. Morago ga pusetso gape ya dinagamagae tse di ikemetseng, go ne go na le diunibesithi le dithekhinikhono tse di 36 mo Aforika Borwa, go le gontsi di kgaufi-kgaufi ebile di abelana ka dithuto tse di tshwanang.'\n",
      " 'Carol Oskar Eugen Lindroos (29. toukokuuta 1930 Pohja – 9. joulukuuta 2001 Helsinki) oli suomalainen kiekonheittäjä. Hän voitti kiekon Suomen mestaruuden vuosina 1953, 1954, 1955, 1957, 1958 ja 1961. Hopealla hän oli vuosina 1962 ja 1964 sekä pronssilla 1959, 1960 ja 1963.'\n",
      " 'Seyîd Evdilqadir (z. 1851 Colemêrg - m. 1925 Bedlîs) siyasetmedar û alimekî kurd bû, Kurrê Şêx Ubeydelayê Nehrî bû. Di serhildana Şêx Seîd de ew jî weke Salih Begê Hênê û 47 hevalê xwe hatiye dardekirin.'\n",
      " \"Erga Hirooshimaa fi Nagaasaakin rukutamanii booda, meeshaalen waraanaa niwuukilaaraa wayita kuma lamaa ol yaalii fi agarsiisaaf dhukaafamaniiru. Addunyaarratti biyyoota muraasa qofatu meeshaa waraanaa niwuukilaaraa kana qaba ykn qabaachuuf hawwa. Biyyoonni meeshaa kana dhukaasuun isaanii beekkamee fi qabaachuu isaani ifa baasanii beeksisan USA, Tokkummaa Sooviyeetii (ammammoo Raashiyaa), Yunaayitid Kingidem, Firaansi, Chaayinaa, Indiyaa, Paakistaan, fi Kooriyaa Kaabaati. Isiraa'eel meeshaa kana qabdi jedhamee kan amanamu yoo ta'u biyyittiin garuu qabaachuu ishii ifatti hin beeksifne. Afrikaan Kibbaa, meeshaa waraanaa niwuukilaaraa kana oomishtee kan turte yoo ta'u erga sirni appaartaayidii kufee booda meeshaa kan balleessitee jirti, itti aansunis waliigaltee meeshaalen niwuukilaaraa akka hin baballanne godhu kan 'Nuclear Non-Proliferation Treaty' jedhamu keessatti miseensa taateerti. Akka Federeeshinii saayintistoota Ameerikaa tilmaametti, walumaagalatti addunyaarra bara 2012tti meeshaalen niwuukilaaraa 17,000 ta'u kan argamu yoo ta'u kana keessaa kan 4,300 ta'an waraanaaf qophii ta'anii kan taa'anidha.\"\n",
      " 'Gârleșteanu vant en olympisk bronsemedalje i rugby union under Sommer-OL 1924 i Antwerpen. Han var med på det rumenske laget som kom på tredjeplass i rugbyturneringen bak USA og Frankrike. Det var kun tre lag som deltok og kampene ble spilt i perioden 4. til 17. mai 1924. Romania tapte begge sine kamper, 3-59 mot Frankrike og 0-39 mot USA.'\n",
      " 'La ciudad de San Cristóbal es sede del Hospital General Docente \"Comandante Pinares\". Con más de 400 camas, este moderno Hospital brinda servicios a todo el oeste de la Provincia de Artemisa.']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_te_vectors)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(y_pred[0:10])\n",
    "print(X_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f966d3e-57e4-4b15-9897-32ca8d142f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
